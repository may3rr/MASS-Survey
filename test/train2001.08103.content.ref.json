{
    "subject": [
        "Machine Learning",
        "Image and Video Processing",
        "Machine Learning"
    ],
    "reference": [
        "[1] S. Latif, J. Qadir, S. Farooq, and M. Imran, “How 5G wireless (and concomitant technologies) will revolutionize healthcare?” Future Internet, vol. 9, no. 4, p. 93, 2017.  ",
        "[2] Z. Yan, Y. Zhan, Z. Peng, S. Liao, Y. Shinagawa, S. Zhang, D. N. Metaxas, and X. S. Zhou, “Multi-instance deep learning: Discover discriminative local anatomies for bodypart recognition,” IEEE transactions on medical imaging, vol. 35, no. 5, pp. 1332–1343, 2016.  ",
        "[3] M. Anthimopoulos, S. Christodoulidis, L. Ebner, A. Christe, and S. Mougiakakou, “Lung pattern classiﬁcation for interstitial lung diseases using a deep convolutional neural network,” IEEE transactions on medical imaging, vol. 35, no. 5, pp. 1207–1216, 2016.  ",
        "[4] W. Shen, M. Zhou, F. Yang, C. Yang, and J. Tian, “Multi-scale convolutional neural networks for lung nodule classiﬁcation,” in International Conference on Information Processing in Medical Imaging. Springer, 2015, pp. 588–599.  ",
        "[5] J. Schlemper, J. Caballero, J. V. Hajnal, A. Price, and D. Rueckert, “A deep cascade of convolutional neural networks for mr image reconstruction,” in International Conference on Information Processing in Medical Imaging. Springer, 2017, pp. 647–658.  ",
        "[6] J. Mehta and A. Majumdar, “Rodeo: robust de-aliasing autoencoder for real-time medical image reconstruction,” Pattern Recognition, vol. 63, pp. 499–510, 2017.  ",
        "[7] M. Havaei, A. Davy, D. Warde-Farley, A. Biard, A. Courville, Y. Bengio, C. Pal, P.-M. Jodoin, and H. Larochelle, “Brain tumor segmentation with deep neural networks,” Medical image analysis, vol. 35, pp. 18– 31, 2017.  ",
        "[8] K. Bourzac, “The computer will see you now,” Nature, vol. 502, no. 3, pp. S92–S94, 2013.  ",
        "[9] L. Xing, E. A. Krupinski, and J. Cai, “Artiﬁcial intelligence will soon change the landscape of medical physics research and practice,” Medical physics, vol. 45, no. 5, pp. 1791–1793, 2018.  ",
        "[10] B. E. Bejnordi, M. Veta, P. J. Van Diest, B. Van Ginneken, N. Karssemeijer, G. Litjens, J. A. Van Der Laak, M. Hermsen, Q. F. Manson, M. Balkenhol et al., “Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer,” Jama, vol. 318, no. 22, pp. 2199–2210, 2017.  ",
        "[11] P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, D. Ding, A. Bagul, C. Langlotz, K. Shpanskaya et al., “Chexnet: Radiologistlevel pneumonia detection on chest x-rays with deep learning,” arXiv preprint arXiv:1711.05225, 2017.  ",
        "[12] V. Gulshan, L. Peng, M. Coram, M. C. Stumpe, D. Wu, A. Narayanaswamy, S. Venugopalan, K. Widner, T. Madams, J. Cuadros et al., “Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs,” Jama, vol. 316, no. 22, pp. 2402–2410, 2016.  ",
        "[13] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, and S. Thrun, “Dermatologist-level classiﬁcation of skin cancer with deep neural networks,” Nature, vol. 542, no. 7639, p. 115, 2017.  ",
        "[14] S. Latif, M. Asim, M. Usman, J. Qadir, and R. Rana, “Automating motion correction in multishot mri using generative adversarial networks,” Published as Workshop Paper at 32nd Conference on Neural Information Processing Systems (NIPS 2018), 2018.  ",
        "[15] X.-W. Chen and X. Lin, “Big data deep learning: challenges and perspectives,” IEEE access, vol. 2, pp. 514–525, 2014.  ",
        "[16] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus, “Intriguing properties of neural networks,” arXiv preprint arXiv:1312.6199, 2013.  ",
        "[17] A. Shafahi, W. R. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras, and T. Goldstein, “Poison frogs! targeted clean-label poisoning attacks on neural networks,” in Advances in Neural Information Processing Systems, 2018, pp. 6103–6113.  ",
        "[18] X. Yuan, P. He, Q. Zhu, and X. Li, “Adversarial examples: Attacks and defenses for deep learning,” IEEE transactions on neural networks and learning systems, 2019.  ",
        "[19] S. G. Finlayson, J. D. Bowers, J. Ito, J. L. Zittrain, A. L. Beam, and I. S. Kohane, “Adversarial attacks on medical machine learning,” Science, vol. 363, no. 6433, pp. 1287–1289, 2019.  ",
        "[20] K. Papangelou, K. Sechidis, J. Weatherall, and G. Brown, “Toward an understanding of adversarial examples in clinical trials,” in Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 2018, pp. 35–51.  ",
        "[21] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A survey,” ACM computing surveys (CSUR), vol. 41, no. 3, p. 15, 2009.  ",
        "[22] A. K. Pandey, P. Pandey, K. Jaiswal, and A. K. Sen, “Datamining clustering techniques in the prediction of heart disease using attribute selection method,” heart disease, vol. 14, pp. 16–17, 2013.  ",
        "[23] K. Polat and S. G¨unes¸, “Prediction of hepatitis disease based on principal component analysis and artiﬁcial immune recognition system,” Applied Mathematics and computation, vol. 189, no. 2, pp. 1282–1291, 2007.  ",
        "[24] M. Alloghani, D. Al-Jumeily, J. Mustaﬁna, A. Hussain, and A. J. Aljaaf, “A systematic review on supervised and unsupervised machine learning algorithms for data science,” in Supervised and Unsupervised Learning for Data Science. Springer, 2020, pp. 3–21.  ",
        "[25] M. N. Sohail, J. Ren, and M. Uba Muhammad, “A euclidean group assessment on semi-supervised clustering for healthcare clinical implications based on real-life data,” International journal of environmental research and public health, vol. 16, no. 9, p. 1581, 2019.  ",
        "[26] A. Zahin, R. Q. Hu et al., “Sensor-based human activity recognition for smart healthcare: A semi-supervised machine learning,” in International Conference on Artiﬁcial Intelligence for Communications and Networks. Springer, 2019, pp. 450–472.  ",
        "[27] D. Mahapatra, “Semi-supervised learning and graph cuts for consensus based medical image segmentation,” Pattern recognition, vol. 63, pp. 700–709, 2017.  ",
        "[28] W. Bai, O. Oktay, M. Sinclair, H. Suzuki, M. Rajchl, G. Tarroni, B. Glocker, A. King, P. M. Matthews, and D. Rueckert, “Semisupervised learning for network-based cardiac mr image segmentation,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2017, pp. 253–260.  ",
        "[29] R. S. Sutton, A. G. Barto et al., Introduction to reinforcement learning. MIT press Cambridge, 1998, vol. 2, no. 4.  ",
        "[30] H.-C. Kao, K.-F. Tang, and E. Y. Chang, “Context-aware symptom checking for disease diagnosis using hierarchical reinforcement learning,” in Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.  ",
        "[31] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot et al., “Mastering the game of go with deep neural networks and tree search,” nature, vol. 529, no. 7587, p. 484, 2016.  ",
        "[32] A. Collins and Y. Yao, “Machine learning approaches: Data integration for disease prediction and prognosis,” in Applied Computational Genomics. Springer, 2018, pp. 137–141.  ",
        "[33] P. Afshar, A. Mohammadi, and K. N. Plataniotis, “Brain tumor type classiﬁcation via capsule networks,” in 2018 25th IEEE International Conference on Image Processing (ICIP). IEEE, 2018, pp. 3129–3133.  ",
        "[34] W. Zhu, C. Liu, W. Fan, and X. Xie, “Deeplung: Deep 3d dual path nets for automated pulmonary nodule detection and classiﬁcation,” in 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE, 2018, pp. 673–681.  ",
        "[35] P. B. Jensen, L. J. Jensen, and S. Brunak, “Mining electronic health records: towards better research applications and clinical care,” Nature Reviews Genetics, vol. 13, no. 6, p. 395, 2012.  19  ",
        "[36] Z. Wang, A. D. Shah, A. R. Tate, S. Denaxas, J. Shawe-Taylor, and H. Hemingway, “Extracting diagnoses and investigation results from unstructured text in electronic health records by semi-supervised machine learning,” PLoS One, vol. 7, no. 1, p. e30412, 2012.  ",
        "[37] T. Zheng, W. Xie, L. Xu, X. He, Y. Zhang, M. You, G. Yang, and Y. Chen, “A machine learning-based framework to identify type 2 diabetes through electronic health records,” International journal of medical informatics, vol. 97, pp. 120–127, 2017.  ",
        "[38] B. Nestor, M. McDermott, W. Boag, G. Berner, T. Naumann, M. C. Hughes, A. Goldenberg, and M. Ghassemi, “Feature robustness in non-stationary health records: caveats to deployable model performance in common clinical machine learning tasks,” arXiv preprint arXiv:1908.00690, 2019.  ",
        "[39] S. M. Anwar, M. Majid, A. Qayyum, M. Awais, M. Alnowami, and M. K. Khan, “Medical image analysis using convolutional neural networks: a review,” Journal of medical systems, vol. 42, no. 11, p. 226, 2018.  ",
        "[40] M. Lustig, D. L. Donoho, J. M. Santos, and J. M. Pauly, “Compressed sensing mri,” IEEE signal processing magazine, vol. 25, no. 2, pp. 72–82, 2008.  ",
        "[41] L. Gondara, “Medical image denoising using convolutional denoising autoencoders,” in 2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW). IEEE, 2016, pp. 241–246.  ",
        "[42] Y. Chen, Y. Xie, Z. Zhou, F. Shi, A. G. Christodoulou, and D. Li, “Brain mri super resolution using 3d deep densely connected neural networks,” in 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). IEEE, 2018, pp. 739–742.  ",
        "[43] K. Sirinukunwattana, S. e Ahmed Raza, Y.-W. Tsang, D. R. Snead, I. A. Cree, and N. M. Rajpoot, “Locality sensitive deep learning for detection and classiﬁcation of nuclei in routine colon cancer histology images.” IEEE Trans. Med. Imaging, vol. 35, no. 5, pp. 1196–1206, 2016.  ",
        "[44] H. Wang, A. C. Roa, A. N. Basavanhally, H. L. Gilmore, N. Shih, M. Feldman, J. Tomaszewski, F. Gonzalez, and A. Madabhushi, “Mitosis detection in breast cancer pathology images by combining handcrafted and convolutional neural network features,” Journal of Medical Imaging, vol. 1, no. 3, p. 034003, 2014.  ",
        "[45] Y. Yu, H. Lin, J. Meng, X. Wei, H. Guo, and Z. Zhao, “Deep transfer learning for modality classiﬁcation of medical images,” Information, vol. 8, no. 3, p. 91, 2017.  ",
        "[46] J. Antony, K. McGuinness, N. E. O’Connor, and K. Moran, “Quantifying radiographic knee osteoarthritis severity using deep convolutional neural networks,” in 2016 23rd International Conference on Pattern Recognition (ICPR). IEEE, 2016, pp. 1195–1200.  ",
        "[47] E. Kim, M. Corte-Real, and Z. Baloch, “A deep semantic mobile application for thyroid cytopathology,” in Medical Imaging 2016: PACS and Imaging Informatics: Next Generation and Innovations, vol. 9789. International Society for Optics and Photonics, 2016, p. 97890A.  ",
        "[48] M. F. Stollenga, W. Byeon, M. Liwicki, and J. Schmidhuber, “Parallel multi-dimensional lstm, with application to fast biomedical volumetric image segmentation,” in Advances in neural information processing systems, 2015, pp. 2998–3006.  ",
        "[49] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference on Medical image computing and computer-assisted intervention. Springer, 2015, pp. 234–241.  ",
        "[50] F. Milletari, N. Navab, and S.-A. Ahmadi, “V-net: Fully convolutional neural networks for volumetric medical image segmentation,” in 2016 Fourth International Conference on 3D Vision (3DV). IEEE, 2016, pp. 565–571.  ",
        "[51] M. H. Hesamian, W. Jia, X. He, and P. Kennedy, “Deep learning techniques for medical image segmentation: Achievements and challenges,” Journal of digital imaging, pp. 1–15, 2019.  ",
        "[52] H. Chen, Y. Zhang, M. K. Kalra, F. Lin, Y. Chen, P. Liao, J. Zhou, and G. Wang, “Low-dose ct with a residual encoder-decoder convolutional neural network,” IEEE transactions on medical imaging, vol. 36, no. 12, pp. 2524–2535, 2017.  ",
        "[53] M. Usman, S. Latif, M. Asim, and J. Qadir, “Motion corrected multishot mri reconstruction using generative networks with sensitivity encoding,” arXiv preprint arXiv:1902.07430, 2019.  ",
        "[54] F. E.-Z. A. El-Gamal, M. Elmogy, and A. Atwan, “Current trends in medical image registration and fusion,” Egyptian Informatics Journal, vol. 17, no. 1, pp. 99–124, 2016.  ",
        "[55] J. Ker, L. Wang, J. Rao, and T. Lim, “Deep learning applications in medical image analysis,” Ieee Access, vol. 6, pp. 9375–9389, 2017.  ",
        "[56] X. Yang, R. Kwitt, M. Styner, and M. Niethammer, “Quicksilver: Fast predictive image registration–a deep learning approach,” NeuroImage, vol. 158, pp. 378–396, 2017.  ",
        "[57] S. Miao, Z. J. Wang, and R. Liao, “A cnn regression approach for real-time 2d/3d registration,” IEEE transactions on medical imaging, vol. 35, no. 5, pp. 1352–1363, 2016.  ",
        "[58] D. Shen, G. Wu, and H.-I. Suk, “Deep learning in medical image analysis,” Annual review of biomedical engineering, vol. 19, pp. 221– 248, 2017.  ",
        "[59] A. Qayyum, S. M. Anwar, M. Awais, and M. Majid, “Medical image retrieval using deep convolutional neural network,” Neurocomputing, vol. 266, pp. 8–20, 2017.  ",
        "[60] J. Zech, M. Pain, J. Titano, M. Badgeley, J. Schefﬂein, A. Su, A. Costa, J. Bederson, J. Lehar, and E. K. Oermann, “Natural language–based machine learning models for the annotation of clinical radiology reports,” Radiology, vol. 287, no. 2, pp. 570–580, 2018.  ",
        "[61] B. Jing, P. Xie, and E. Xing, “On the automatic generation of medical imaging reports,” 56th Annual Meeting of the Association for Computational Linguistics (ACL), 2018.  ",
        "[62] X. Wang, Y. Peng, L. Lu, Z. Lu, and R. M. Summers, “Tienet: Textimage embedding network for common thorax disease classiﬁcation and reporting in chest x-rays,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 9049–9058.  ",
        "[63] Y. Xue, T. Xu, L. R. Long, Z. Xue, S. Antani, G. R. Thoma, and X. Huang, “Multimodal recurrent model with attention for automated radiology report generation,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2018, pp. 457–466.  ",
        "[64] V. Jindal, “Integrating mobile and cloud for ppg signal selection to monitor heart rate during intensive physical exercise,” in Proceedings of the International Conference on Mobile Software Engineering and Systems. ACM, 2016, pp. 36–37.  ",
        "[65] F. Attal, S. Mohammed, M. Dedabrishvili, F. Chamroukhi, L. Oukhellou, and Y. Amirat, “Physical human activity recognition using wearable sensors,” Sensors, vol. 15, no. 12, pp. 31 314–31 338, 2015.  ",
        "[66] S. F. Weng, J. Reps, J. Kai, J. M. Garibaldi, and N. Qureshi, “Can machine-learning improve cardiovascular risk prediction using routine clinical data?” PloS one, vol. 12, no. 4, p. e0174944, 2017.  ",
        "[67] M. Fatima and M. Pasha, “Survey of machine learning algorithms for disease diagnostic,” Journal of Intelligent Learning Systems and Applications, vol. 9, no. 01, p. 1, 2017.  ",
        "[68] J. A. Cruz and D. S. Wishart, “Applications of machine learning in cancer prediction and prognosis,” Cancer informatics, vol. 2, p. 117693510600200030, 2006.  ",
        "[69] H.-Y. Ma, Z. Zhou, S. Wu, Y.-L. Wan, and P.-H. Tsui, “A computeraided diagnosis scheme for detection of fatty liver in vivo based on ultrasound kurtosis imaging,” Journal of medical systems, vol. 40, no. 1, p. 33, 2016.  ",
        "[70] Z. Zhang et al., “Reinforcement learning in clinical medicine: a method to optimize dynamic treatment regime over time,” Annals of translational medicine, vol. 7, no. 14, 2019.  ",
        "[71] A. Raghu, “Reinforcement learning for sepsis treatment: Baselines and analysis,” 2019.  ",
        "[72] H. Suresh, “Clinical event prediction and understanding with deep neural networks,” Ph.D. dissertation, Massachusetts Institute of Technology, 2017.  ",
        "[73] C.-S. Rau, P.-J. Kuo, P.-C. Chien, C.-Y. Huang, H.-Y. Hsieh, and C.H. Hsieh, “Mortality prediction in patients with isolated moderate and severe traumatic brain injury using machine learning models,” PloS one, vol. 13, no. 11, p. e0207192, 2018.  ",
        "[74] H. Song, D. Rajan, J. J. Thiagarajan, and A. Spanias, “Attend and diagnose: Clinical time series analysis using attention models,” in Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.  ",
        "[75] O. Ren, A. E. Johnson, E. P. Lehman, M. Komorowski, J. Aboab, F. Tang, Z. Shahn, D. Sow, R. Mark, and L.-w. Lehman, “Predicting and understanding unexpected respiratory decompensation in critical care using sparse and heterogeneous clinical data,” in 2018 IEEE International Conference on Healthcare Informatics (ICHI). IEEE, 2018, pp. 144–151.  ",
        "[76] A. K. Jha, “The promise of electronic records: around the corner or down the road?” Jama, vol. 306, no. 8, pp. 880–881, 2011.  ",
        "[77] A. N´ev´eol, H. Dalianis, S. Velupillai, G. Savova, and P. Zweigenbaum, “Clinical natural language processing in languages other than english: opportunities and challenges,” Journal of biomedical semantics, vol. 9, no. 1, p. 12, 2018.  ",
        "[78] E. Soysal, J. Wang, M. Jiang, Y. Wu, S. Pakhomov, H. Liu, and H. Xu, “Clamp–a toolkit for efﬁciently building customized clinical natural  20  language processing pipelines,” Journal of the American Medical Informatics Association, vol. 25, no. 3, pp. 331–336, 2017.  ",
        "[79] D. S. Wallace, “The role of speech recognition in clinical documentation,” Nuance Communications, 2018, access on: 14-Dec2019. [Online]. Available: https://www.hisa.org.au/slides/hic18/wed/ SimonWallace.pdf  ",
        "[80] M. Ghassemi, J. H. Van Stan, D. D. Mehta, M. Za˜nartu, H. A. Cheyne II, R. E. Hillman, and J. V. Guttag, “Learning to detect vocal hyperfunction from ambulatory neck-surface acceleration features: Initial results for vocal fold nodules,” IEEE Transactions on Biomedical Engineering, vol. 61, no. 6, pp. 1668–1675, 2014.  ",
        "[81] C. Pou-Prom and F. Rudzicz, “Learning multiview embeddings for assessing dementia,” in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018, pp. 2812–2817.  ",
        "[82] K. C. Fraser, J. A. Meltzer, and F. Rudzicz, “Linguistic features identify alzheimers disease in narrative speech,” Journal of Alzheimer’s Disease, vol. 49, no. 2, pp. 407–422, 2016.  ",
        "[83] J. B. Andre, B. W. Bresnahan, M. Mossa-Basha, M. N. Hoff, C. P. Smith, Y. Anzai, and W. A. Cohen, “Toward quantifying the prevalence, severity, and cost associated with patient motion during clinical mr examinations,” Journal of the American College of Radiology, vol. 12, no. 7, pp. 689–695, 2015.  ",
        "[84] A. K. Manrai, G. Bhatia, J. Strymish, I. S. Kohane, and S. H. Jain, “Medicines uncomfortable relationship with math: calculating positive predictive value,” JAMA internal medicine, vol. 174, no. 6, pp. 991– 993, 2014.  ",
        "[85] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, and N. Elhadad, “Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission,” in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015, pp. 1721–1730.  ",
        "[86] X. A. Li, A. Tai, D. W. Arthur, T. A. Buchholz, S. Macdonald, L. B. Marks, J. M. Moran, L. J. Pierce, R. Rabinovitch, A. Taghian et al., “Variability of target and normal structure delineation for breast cancer radiotherapy: an rtog multi-institutional and multiobserver study,” International Journal of Radiation Oncology* Biology* Physics, vol. 73, no. 3, pp. 944–951, 2009.  ",
        "[87] F. Xia and M. Yetisgen-Yildiz, “Clinical corpus annotation: challenges and strategies,” in Proceedings of the Third Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM’2012) in conjunction with the International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey, 2012.  ",
        "[88] B. Biggio, B. Nelson, and P. Laskov, “Poisoning attacks against support vector machines,” in 29th International Conference on Machine Learning, 2012, pp. 1807–1814.  ",
        "[89] S. Alfeld, X. Zhu, and P. Barford, “Data poisoning attacks against autoregressive models,” in Thirtieth AAAI Conference on Artiﬁcial Intelligence, 2016.  ",
        "[90] N. Papernot, P. McDaniel, A. Sinha, and M. Wellman, “Towards the science of security and privacy in machine learning,” arXiv preprint arXiv:1611.03814, 2016.  ",
        "[91] T. J. Pollard, I. Chen, J. Wiens, S. Horng, D. Wong, M. Ghassemi, H. Mattie, E. Lindmeer, and T. Panch, “Turning the crank for machine learning: ease, at what expense?” The Lancet Digital Health, vol. 1, no. 5, pp. e198–e199, 2019.  ",
        "[92] M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that exploit conﬁdence information and basic countermeasures,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, 2015, pp. 1322–1333.  ",
        "[93] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” arXiv preprint arXiv:1412.6572, 2014.  ",
        "[94] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and A. Swami, “The limitations of deep learning in adversarial settings,” in 2016 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 2016, pp. 372–387.  ",
        "[95] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami, “Practical black-box attacks against machine learning,” in Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, 2017, pp. 506–519.  ",
        "[96] M. Usama, J. Qadir, A. Al-Fuqaha, and M. Hamdi, “The adversarial machine learning conundrum: Can the insecurity of ml become the achilles’ heel of cognitive networks?” arXiv preprint arXiv:1906.00679, 2019.  ",
        "[97] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. ˇSrndi´c, P. Laskov, G. Giacinto, and F. Roli, “Evasion attacks against machine learning at test time,” in Joint European conference on machine learning and knowledge discovery in databases. Springer, 2013, pp. 387–402.  ",
        "[98] M. Mozaffari-Kermani, S. Sur-Kolay, A. Raghunathan, and N. K. Jha, “Systematic poisoning attacks on and defenses for machine learning in healthcare,” IEEE journal of biomedical and health informatics, vol. 19, no. 6, pp. 1893–1905, 2014.  ",
        "[99] S. G. Finlayson, H. W. Chung, I. S. Kohane, and A. L. Beam, “Adversarial attacks against medical deep learning systems,” arXiv preprint arXiv:1804.05296, 2018.  ",
        "[100] M. Al-Rubaie and J. M. Chang, “Privacy-preserving machine learning: Threats and solutions,” IEEE Security & Privacy, vol. 17, no. 2, pp. 49–58, 2019.  ",
        "[101] J. Zhang and E. Bareinboim, “Fairness in decision-makingthe causal explanation formula,” in Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.  ",
        "[102] P. Schulam and S. Saria, “Reliable decision support using counterfactual models,” in Advances in Neural Information Processing Systems, 2017, pp. 1697–1708.  ",
        "[103] M. Ghassemi, T. Naumann, P. Schulam, A. L. Beam, and R. Ranganath, “Opportunities in machine learning for healthcare,” arXiv preprint arXiv:1806.00388, 2018.  ",
        "[104] E. Begoli, T. Bhattacharya, and D. Kusnezov, “The need for uncertainty quantiﬁcation in machine-assisted medical decision making,” Nature Machine Intelligence, vol. 1, no. 1, p. 20, 2019.  ",
        "[105] A. Khademi, S. Lee, D. Foley, and V. Honavar, “Fairness in algorithmic decision making: An excursion through the lens of causality,” in The World Wide Web Conference. ACM, 2019, pp. 2907–2914.  ",
        "[106] N. Kilbertus, M. R. Carulla, G. Parascandolo, M. Hardt, D. Janzing, and B. Sch¨olkopf, “Avoiding discrimination through causal reasoning,” in Advances in Neural Information Processing Systems, 2017, pp. 656– 666.  ",
        "[107] L. Faes, S. K. Wagner, D. J. Fu, X. Liu, E. Korot, J. R. Ledsam, T. Back, R. Chopra, N. Pontikos, C. Kern et al., “Automated deep learning design for medical image classiﬁcation by health-care professionals with no coding experience: a feasibility study,” The Lancet Digital Health, vol. 1, no. 5, pp. e232–e242, 2019.  ",
        "[108] N. u. . h. OReilly, “Challenges to AI in healthcare accessed online: 16 oct 2019.”  ",
        "[109] B. David, R. Dowsley, R. Katti, and A. C. Nascimento, “Efﬁcient unconditionally secure comparison and privacy preserving machine learning classiﬁcation protocols,” in International Conference on Provable Security. Springer, 2015, pp. 354–367.  ",
        "[110] M. Jagielski, A. Oprea, B. Biggio, C. Liu, C. Nita-Rotaru, and B. Li, “Manipulating machine learning: Poisoning attacks and countermeasures for regression learning,” in 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 2018, pp. 19–35.  ",
        "[111] M. Liu, H. Jiang, J. Chen, A. Badokhon, X. Wei, and M.-C. Huang, “A collaborative privacy-preserving deep learning system in distributed mobile environment,” in 2016 International Conference on Computational Science and Computational Intelligence (CSCI). IEEE, 2016, pp. 192–197.  ",
        "[112] D. Malathi, R. Logesh, V. Subramaniyaswamy, V. Vijayakumar, and A. K. Sangaiah, “Hybrid reasoning-based privacy-aware disease prediction support system,” Computers & Electrical Engineering, vol. 73, pp. 114–127, 2019.  ",
        "[113] H. Takabi, E. Hesamifard, and M. Ghasemi, “Privacy preserving multiparty machine learning with homomorphic encryption,” in 29th Annual Conference on Neural Information Processing Systems (NIPS), 2016.  ",
        "[114] M. Kim, Y. Song, S. Wang, Y. Xia, and X. Jiang, “Secure logistic regression based on homomorphic encryption: Design and evaluation,” JMIR medical informatics, vol. 6, no. 2, p. e19, 2018.  ",
        "[115] I. Chen, F. D. Johansson, and D. Sontag, “Why is my classiﬁer discriminatory?” in Advances in Neural Information Processing Systems, 2018, pp. 3539–3550.  ",
        "[116] M. Ghassemi, T. Naumann, P. Schulam, A. L. Beam, I. Y. Chen, and R. Ranganath, “Practical guidance on artiﬁcial intelligence for healthcare data,” The Lancet Digital Health, vol. 1, no. 4, pp. e157–e159, 2019.  ",
        "[117] T. Panch, H. Mattie, and L. A. Celi, “The inconvenient truth about ai in healthcare,” Npj Digital Medicine, vol. 2, no. 1, pp. 1–3, 2019.  ",
        "[118] C. S. Perone, P. Ballester, R. C. Barros, and J. Cohen-Adad, “Unsupervised domain adaptation for medical imaging segmentation with self-ensembling,” NeuroImage, vol. 194, pp. 1–11, 2019.  ",
        "[119] A. Narayanan and V. Shmatikov, “Robust de-anonymization of large datasets (how to break anonymity of the netﬂix prize dataset),” University of Texas at Austin, 2008.  ",
        "[120] P. Mohassel and Y. Zhang, “Secureml: A system for scalable privacypreserving machine learning,” in 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 2017, pp. 19–38.  21  ",
        "[121] R. Bost, R. A. Popa, S. Tu, and S. Goldwasser, “Machine learning classiﬁcation over encrypted data.” in NDSS, vol. 4324, 2015, p. 4325.  ",
        "[122] D. Bogdanov, L. Kamm, S. Laur, and V. Sokk, “Implementation and evaluation of an algorithm for cryptographically private principal component analysis on genomic data,” IEEE/ACM transactions on computational biology and bioinformatics, vol. 15, no. 5, pp. 1427– 1432, 2018.  ",
        "[123] K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for privacy-preserving machine learning,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2017, pp. 1175–1191.  ",
        "[124] M. S. Hossain and G. Muhammad, “Emotion recognition using secure edge and cloud computing,” Information Sciences, vol. 504, pp. 589– 601, 2019.  ",
        "[125] O. Ohrimenko, F. Schuster, C. Fournet, A. Mehta, S. Nowozin, K. Vaswani, and M. Costa, “Oblivious multi-party machine learning on trusted processors,” in 25th USENIX Security Symposium (USENIX Security 16), 2016, pp. 619–636.  ",
        "[126] C. Dwork, “Differential privacy,” Encyclopedia of Cryptography and Security, pp. 338–340, 2011.  ",
        "[127] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang, “Deep learning with differential privacy,” in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2016, pp. 308–318.  ",
        "[128] M. McDermott, S. Wang, N. Marinsek, R. Ranganath, M. Ghassemi, and L. Foschini, “Reproducibility in machine learning for health,” Presented at the Internation Conference on Learning Representative (ICLR) 2019 Reproducibility in Machine Learning Workshop, 2019.  ",
        "[129] N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and ´U. Erlingsson, “Scalable private learning with pate,” International Conference on Learning Representations (ICLR), 2018.  ",
        "[130] Y.-X. Wang, B. Balle, and S. Kasiviswanathan, “Subsampled r\\’enyi differential privacy and analytical moments accountant,” arXiv preprint arXiv:1808.00087, 2018.  ",
        "[131] H. B. McMahan, G. Andrew, U. Erlingsson, S. Chien, I. Mironov, N. Papernot, and P. Kairouz, “A general approach to adding differential privacy to iterative training procedures,” NeurIPS 2018 workshop on Privacy Preserving Machine Learning, 2018.  ",
        "[132] N. Phan, X. Wu, H. Hu, and D. Dou, “Adaptive laplace mechanism: Differential privacy preservation in deep learning,” in 2017 IEEE International Conference on Data Mining (ICDM). IEEE, 2017, pp. 385–394.  ",
        "[133] F. McSherry and K. Talwar, “Mechanism design via differential privacy.” in FOCS, vol. 7, 2007, pp. 94–103.  ",
        "[134] C. Dwork and F. D. McSherry, “Exponential noise distribution to optimize database privacy and output utility,” Jul. 14 2009, uS Patent 7,562,071.  ",
        "[135] B. K. Beaulieu-Jones, W. Yuan, S. G. Finlayson, and Z. S. Wu, “Privacy-preserving distributed deep learning for clinical data,” Machine Learning for Health (ML4H) Workshop at NeurIPS, 2018.  ",
        "[136] H. B. McMahan, E. Moore, D. Ramage, S. Hampson et al., “Communication-efﬁcient learning of deep networks from decentralized data,” Proceedings of the 20 th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) JMLR: W&CP volume 54, 2017.  ",
        "[137] T. S. Brisimi, R. Chen, T. Mela, A. Olshevsky, I. C. Paschalidis, and W. Shi, “Federated learning of predictive models from federated electronic health records,” International journal of medical informatics, vol. 112, pp. 59–67, 2018.  ",
        "[138] P. Vepakomma, O. Gupta, T. Swedish, and R. Raskar, “Split learning for health: Distributed deep learning without sharing raw patient data,” Published as Workshop Paper at 32nd Conference on Neural Information Processing Systems (NIPS 2018), 2018.  ",
        "[139] D. Liu, T. Miller, R. Sayeed, and K. Mandl, “Fadl: Federatedautonomous deep learning for distributed electronic health record,” Machine Learning for Health (ML4H) Workshop at NeurIPS, 2018.  ",
        "[140] A. Qayyum, M. Usama, J. Qadir, and A. Al-Fuqaha, “Securing connected & autonomous vehicles: Challenges posed by adversarial machine learning and the way forward,” arXiv preprint arXiv:1905.12762, 2019.  ",
        "[141] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural network,” Deep Learning Workshop, NIPS, 2014.  ",
        "[142] N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillation as a defense to adversarial perturbations against deep neural networks,” in 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016, pp. 582–597.  ",
        "[143] N. Carlini and D. Wagner, “Adversarial examples are not easily detected: Bypassing ten detection methods,” in Proceedings of the 10th ACM Workshop on Artiﬁcial Intelligence and Security. ACM, 2017, pp. 3–14.  ",
        "[144] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer, “Reluplex: An efﬁcient SMT solver for verifying deep neural networks,” in International Conference on Computer Aided Veriﬁcation. Springer, 2017, pp. 97–117.  ",
        "[145] A. S. Ross and F. Doshi-Velez, “Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients,” in Thirty-second AAAI conference on artiﬁcial intelligence, 2018.  ",
        "[146] J. Bradshaw, A. G. d. G. Matthews, and Z. Ghahramani, “Adversarial examples, uncertainty, and transfer testing robustness in gaussian process hybrid deep networks,” arXiv preprint arXiv:1707.02476, 2017.  ",
        "[147] G. Tao, S. Ma, Y. Liu, and X. Zhang, “Attacks meet interpretability: Attribute-steered detection of adversarial samples,” in Advances in Neural Information Processing Systems (NeurIPS), 2018, pp. 7717– 7728.  ",
        "[148] N. Carlini, “Is ami (attacks meet interpretability) robust to adversarial examples?” arXiv preprint arXiv:1902.02322, 2019.  ",
        "[149] L. Nguyen, S. Wang, and A. Sinha, “A learning and masking approach to secure learning,” in International Conference on Decision and Game Theory for Security. Springer, 2018, pp. 453–464.  ",
        "[150] R. Huang, B. Xu, D. Schuurmans, and C. Szepesv´ari, “Learning with a strong adversary,” arXiv preprint arXiv:1511.03034, 2015.  ",
        "[151] A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” in Artiﬁcial Intelligence Safety and Security. Chapman and Hall/CRC, 2018, pp. 99–112.  ",
        "[152] S. Gu and L. Rigazio, “Towards deep neural network architectures robust to adversarial examples,” Published as a Workshop Paper at International Conference on Learning Representative (ICLR), 2015.  ",
        "[153] W. Xu, D. Evans, and Y. Qi, “Feature squeezing: Detecting adversarial examples in deep neural networks,” in 25th Annual Network and Distributed System Security Symposium, NDSS 2018, San Diego, California, USA, February 18-21, 2018, 2018. [Online]. Available: http://wp.internetsociety.org/ndss/wp-content/uploads/ sites/25/2018/02/ndss2018 03A-4 Xu paper.pdf  ",
        "[154] W. He, J. Wei, X. Chen, N. Carlini, and D. Song, “Adversarial example defense: Ensembles of weak defenses are not strong,” in 11th USENIX Workshop on Offensive Technologies (WOOT)’17), 2017.  ",
        "[155] J. Gao, B. Wang, Z. Lin, W. Xu, and Y. Qi, “Deepcloak: Masking deep neural network models for robustness against adversarial samples,” arXiv preprint arXiv:1702.06763, 2017.  ",
        "[156] S. Garg, V. Sharan, B. Zhang, and G. Valiant, “A spectral view of adversarially robust features,” in Advances in Neural Information Processing Systems (NeurlIPS), 2018, pp. 10 159–10 169.  ",
        "[157] Y. Song, T. Kim, S. Nowozin, S. Ermon, and N. Kushman, “Pixeldefend: Leveraging generative models to understand and defend against adversarial examples,” in International Conference on Learning Representations (ICLR), 2018. [Online]. Available: https://openreview. net/forum?id=rJUYGxbCW  ",
        "[158] G. Jin, S. Shen, D. Zhang, F. Dai, and Y. Zhang, “APE-GAN: adversarial perturbation elimination with GAN,” in ICASSP 20192019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 3842–3846.  ",
        "[159] J. Lu, T. Issaranon, and D. Forsyth, “Safetynet: Detecting and rejecting adversarial examples robustly,” in Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 446–454.  ",
        "[160] D. Gopinath, G. Katz, C. S. Pasareanu, and C. Barrett, “Deepsafe: A data-driven approach for checking adversarial robustness in neural networks,” arXiv preprint arXiv:1710.00486, 2017.  ",
        "[161] J. H. Metzen, T. Genewein, V. Fischer, and B. Bischoff, “On detecting adversarial perturbations,” International Conference on Learning Representations (ICLR), 2017.  ",
        "[162] F. Tramer, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel, “Ensemble adversarial training: Attacks and defenses,” in International Conference on Learning Representations (ICLR), 2018.  ",
        "[163] G. K. Santhanam and P. Grnarova, “Defending against adversarial attacks by leveraging an entire GAN,” arXiv preprint arXiv:1805.10652, 2018.  ",
        "[164] P. Samangouei, M. Kabkab, and R. Chellappa, “Defense-GAN: Protecting classiﬁers against adversarial attacks using generative models,” in International Conference on Learning Representations (ICLR), 2018.  ",
        "[165] P. Schulam and S. Saria, “What-if reasoning with counterfactual gaussian processes,” History, vol. 100, p. 120, 2017.  22  ",
        "[166] R. C. Sato and G. T. K. Sato, “Probabilistic graphic models applied to identiﬁcation of diseases,” Einstein (S˜ao Paulo), vol. 13, no. 2, pp. 330–333, 2015.  ",
        "[167] C. Glymour, K. Zhang, and P. Spirtes, “Review of causal discovery methods based on graphical models,” Frontiers in Genetics, vol. 10, 2019.  ",
        "[168] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are features in deep neural networks?” in Advances in neural information processing systems, 2014, pp. 3320–3328.  ",
        "[169] M. Ghafoorian, A. Mehrtash, T. Kapur, N. Karssemeijer, E. Marchiori, M. Pesteie, C. R. Guttmann, F.-E. de Leeuw, C. M. Tempany, B. van Ginneken et al., “Transfer learning for domain adaptation in mri: Application in brain lesion segmentation,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2017, pp. 516–524.  ",
        "[170] A. Madani, M. Moradi, A. Karargyris, and T. Syeda-Mahmood, “Semisupervised learning with generative adversarial networks for chest Xray classiﬁcation with ability of data domain adaptation,” in 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). IEEE, 2018, pp. 1038–1042.  ",
        "[171] C. Wachinger, M. Reuter, A. D. N. Initiative et al., “Domain adaptation for alzheimer’s disease diagnostics,” Neuroimage, vol. 139, pp. 470– 479, 2016.  ",
        "[172] G. Wilson and D. J. Cook, “A survey of unsupervised deep domain adaptation,” arXiv preprint arXiv:1812.02849, 2019.  ",
        "[173] F. Mahmood, R. Chen, and N. J. Durr, “Unsupervised reverse domain adaptation for synthetic medical images via adversarial training,” IEEE transactions on medical imaging, vol. 37, no. 12, pp. 2572–2581, 2018.  ",
        "[174] J. Xu, L. Xiao, and A. M. L´opez, “Self-supervised domain adaptation for computer vision tasks,” IEEE Access, vol. 7, pp. 156 694–156 706, 2019.  ",
        "[175] J. Wiens, S. Saria, M. Sendak, M. Ghassemi, V. X. Liu, F. Doshi-Velez, K. Jung, K. Heller, D. Kale, M. Saeed et al., “Do no harm: a roadmap for responsible machine learning for health care,” Nature medicine, vol. 25, no. 9, pp. 1337–1340, 2019.  ",
        "[176] S. Latif, A. Qayyum, M. Usama, J. Qadir, A. Zwitter, and M. Shahzad, “Caveat emptor: The risks of using big data for human development,” IEEE Technology and Society Magazine, vol. 38, no. 3, pp. 82–90, 2019.  ",
        "[177] X. Jia, L. Ren, and J. Cai, “Clinical implementation of ai technologies will require interpretable ai models,” Medical physics, 2019.  ",
        "[178] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. M¨uller, and W. Samek, “On pixel-wise explanations for non-linear classiﬁer decisions by layer-wise relevance propagation,” PloS one, vol. 10, no. 7, p. e0130140, 2015.  ",
        "[179] M. T. Ribeiro, S. Singh, and C. Guestrin, “Why should i trust you?: Explaining the predictions of any classiﬁer,” in Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 2016, pp. 1135–1144.  ",
        "[180] O. Lahav, N. Mastronarde, and M. van der Schaar, “What is interpretable? using machine learning to design interpretable decisionsupport systems,” Machine Learning for Health (ML4H) Workshop at NeurIPS, 2018.  ",
        "[181] Y. Halpern, S. Horng, Y. Choi, and D. Sontag, “Electronic medical record phenotyping using the anchor and learn framework,” Journal of the American Medical Informatics Association, vol. 23, no. 4, pp. 731–740, 2016.  ",
        "[182] R. L. Richesson, W. E. Hammond, M. Nahm, D. Wixted, G. E. Simon, J. G. Robinson, A. E. Bauck, D. Cifelli, M. M. Smerek, J. Dickerson et al., “Electronic health records based phenotyping in next-generation clinical trials: a perspective from the nih health care systems collaboratory,” Journal of the American Medical Informatics Association, vol. 20, no. e2, pp. e226–e231, 2013.  ",
        "[183] D. Belgrave, J. Henderson, A. Simpson, I. Buchan, C. Bishop, and A. Custovic, “Disaggregating asthma: big investigation versus big data,” Journal of Allergy and Clinical Immunology, vol. 139, no. 2, pp. 400–407, 2017. "
    ],
    "reference_content": [
        {
            "reference_num": "[1]",
            "reference_title": "How 5G Wireless (and Concomitant Technologies) Will Revolutionize Healthcare?",
            "reference_abstract": "The need to have equitable access to quality healthcare is enshrined in the United Nations (UN) Sustainable Development Goals (SDGs), which defines the developmental agenda of the UN for the next 15 years. In particular, the third SDG focuses on the need to “ensure healthy lives and promote well-being for all at all ages”. In this paper, we build the case that 5G wireless technology, along with concomitant emerging technologies (such as IoT, big data, artificial intelligence and machine learning), will transform global healthcare systems in the near future. Our optimism around 5G-enabled healthcare stems from a confluence of significant technical pushes that are already at play: apart from the availability of high-throughput low-latency wireless connectivity, other significant factors include the democratization of computing through cloud computing; the democratization of Artificial Intelligence (AI) and cognitive computing (e.g., IBM Watson); and the commoditization of data through crowdsourcing and digital exhaust. These technologies together can finally crack a dysfunctional healthcare system that has largely been impervious to technological innovations. We highlight the persistent deficiencies of the current healthcare system and then demonstrate how the 5G-enabled healthcare revolution can fix these deficiencies. We also highlight open technical research challenges, and potential pitfalls, that may hinder the development of such a 5G-enabled health revolution."
        },
        {
            "reference_num": "[2]",
            "reference_title": "Multi-Instance Deep Learning: Discover Discriminative Local Anatomies for Bodypart Recognition",
            "reference_abstract": "In general image recognition problems, discriminative information often lies in local image patches. For example, most human identity information exists in the image patches containing human faces. The same situation stays in medical images as well. \"Bodypart identity\" of a transversal slice-which bodypart the slice comes from-is often indicated by local image information, e.g., a cardiac slice and an aorta arch slice are only differentiated by the mediastinum region. In this work, we design a multi-stage deep learning framework for image classification and apply it on bodypart recognition. Specifically, the proposed framework aims at: 1) discover the local regions that are discriminative and non-informative to the image classification problem, and 2) learn a image-level classifier based on these local regions. We achieve these two tasks by the two stages of learning scheme, respectively. In the pre-train stage, a convolutional neural network (CNN) is learned in a multi-instance learning fashion to extract the most discriminative and and non-informative local patches from the training slices. In the boosting stage, the pre-learned CNN is further boosted by these local patches for image classification. The CNN learned by exploiting the discriminative local appearances becomes more accurate than those learned from global image context. The key hallmark of our method is that it automatically discovers the discriminative and non-informative local patches through multi-instance deep learning. Thus, no manual annotation is required. Our method is validated on a synthetic dataset and a large scale CT dataset. It achieves better performances than state-of-the-art approaches, including the standard deep CNN."
        },
        {
            "reference_num": "[3]",
            "reference_title": "Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network",
            "reference_abstract": "Automated tissue characterization is one of the most crucial components of a computer aided diagnosis (CAD) system for interstitial lung diseases (ILDs). Although much research has been conducted in this field, the problem remains challenging. Deep learning techniques have recently achieved impressive results in a variety of computer vision problems, raising expectations that they might be applied in other domains, such as medical image analysis. In this paper, we propose and evaluate a convolutional neural network (CNN), designed for the classification of ILD patterns. The proposed network consists of 5 convolutional layers with 2 × 2 kernels and LeakyReLU activations, followed by average pooling with size equal to the size of the final feature maps and three dense layers. The last dense layer has 7 outputs, equivalent to the classes considered: healthy, ground glass opacity (GGO), micronodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation. To train and evaluate the CNN, we used a dataset of 14696 image patches, derived by 120 CT scans from different scanners and hospitals. To the best of our knowledge, this is the first deep CNN designed for the specific problem. A comparative analysis proved the effectiveness of the proposed CNN against previous methods in a challenging dataset. The classification performance ( ~ 85.5%) demonstrated the potential of CNNs in analyzing lung patterns. Future work includes, extending the CNN to three-dimensional data provided by CT volume scans and integrating the proposed method into a CAD system that aims to provide differential diagnosis for ILDs as a supportive tool for radiologists."
        },
        {
            "reference_num": "[4]",
            "reference_title": "Multi-scale Convolutional Neural Networks for Lung Nodule Classification",
            "reference_abstract": "We investigate the problem of diagnostic lung nodule classification using thoracic Computed Tomography (CT) screening. Unlike traditional studies primarily relying on nodule segmentation for regional analysis, we tackle a more challenging problem on directly modelling raw nodule patches without any prior definition of nodule morphology. We propose a hierarchical learning framework--Multi-scale Convolutional Neural Networks (MCNN)--to capture nodule heterogeneity by extracting discriminative features from alternatingly stacked layers. In particular, to sufficiently quantify nodule characteristics, our framework utilizes multi-scale nodule patches to learn a set of class-specific features simultaneously by concatenating response neuron activations obtained at the last layer from each input scale. We evaluate the proposed method on CT images from Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI), where both lung nodule screening and nodule annotations are provided. Experimental results demonstrate the effectiveness of our method on classifying malignant and benign nodules without nodule segmentation."
        },
        {
            "reference_num": "[5]",
            "reference_title": "A Deep Cascade of Convolutional Neural Networks for MR Image Reconstruction",
            "reference_abstract": "The acquisition of Magnetic Resonance Imaging (MRI) is inherently slow. Inspired by recent advances in deep learning, we propose a framework for reconstructing MR images from undersampled data using a deep cascade of convolutional neural networks to accelerate the data acquisition process. We show that for Cartesian undersampling of 2D cardiac MR images, the proposed method outperforms the state-of-the-art compressed sensing approaches, such as dictionary learning-based MRI (DLMRI) reconstruction, in terms of reconstruction error, perceptual quality and reconstruction speed for both 3-fold and 6-fold undersampling. Compared to DLMRI, the error produced by the method proposed is approximately twice as small, allowing to preserve anatomical structures more faithfully. Using our method, each image can be reconstructed in 23 ms, which is fast enough to enable real-time applications."
        },
        {
            "reference_num": "[6]",
            "reference_title": "RODEO: Robust DE-aliasing autoencOder for real-time medical image reconstruction",
            "reference_abstract": "In this work we address the problem of real-time dynamic medical (MRI and X-Ray CT) image reconstruction from parsimonious samples (Fourier frequency space for MRI and sinogram/tomographic projections for CT). Today the de facto standard for such reconstruction is compressed sensing (CS). CS produces high quality images (with minimal perceptual loss); but such reconstructions are time consuming, requiring solving a complex optimization problem. In this work we propose to ‘learn’ the reconstruction from training samples using an autoencoder. Our work is based on the universal function approximation capacity of neural networks. The training time for the autoencoder is large, but is offline and hence does not affect performance during operation. During testing/operation, our method requires only a few matrix vector products and hence is significantly faster than CS based methods. In fact, for MRI it is fast enough for real-time reconstruction (the images are reconstructed as fast as they are acquired) with only slight degradation of image quality; for CT our reconstruction speed is slightly slower than required for real-time reconstruction. However, in order to make the autoencoder suitable for our problem, we depart from the standard Euclidean norm cost function of autoencoders and use a robust l1-norm instead. The ensuing problem is solved using the Split Bregman method."
        },
        {
            "reference_num": "[7]",
            "reference_title": "Brain tumor segmentation with Deep Neural Networks",
            "reference_abstract": "In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we’ve found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data. We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster."
        },
        {
            "reference_num": "[8]",
            "reference_title": "K. Bourzac, “The computer will see you now,” Nature, vol. 502, no. 3, pp. S92–S94, 2013.",
            "reference_abstract": "Bayesian evidence ratios give a very attractive way of comparing models, and\nbeing able to quote the odds on a particular model seems a very clear\nmotivation for making a choice. Jeffreys' scale of evidence is often used in\nthe interpretation of evidence ratios. A natural question is, how often will\nyou get it right when you choose on the basis of some threshold value of the\nevidence ratio? The evidence ratio will be different in different realizations\nof the data, and its utility can be examined in a Neyman-Pearson like way to\nsee what the trade-offs are between statistical power (the chance of ``getting\nit right'') versus the false alarm rate, picking the alternative hypothesis\nwhen the null is actually true. I will show some simple examples which show\nthat there can be a surprisingly large range for an evidence ratio under\ndifferent realizations of the data. It seems best not to simply rely on\nJeffrey's scale when decisions have to be taken, but also to examine the\nprobability of taking the ``wrong'' decision if some evidence ratio is taken to\nbe decisive. Interestingly, Turing knew this and applied it during WWII,\nalthough (like much else) he did not publish it."
        },
        {
            "reference_num": "[9]",
            "reference_title": "Artificial intelligence will soon change the landscape of medical physics research and practice",
            "reference_abstract": "Medical PhysicsVolume 45, Issue 5 p. 1791-1793 Point/Counterpoint Artificial intelligence will soon change the landscape of medical physics research and practice Lei Xing Ph.D., Lei Xing Ph.D. lei@stanford.edu Tel: 650-498-7896 Department of Radiation Oncology, Stanford University, Stanford, CA, 94305 USASearch for more papers by this authorElizabeth A. Krupinski Ph.D., Elizabeth A. Krupinski Ph.D. ekrupin@emory.edu Tel: 404-712-3868 Department of Radiology & Imaging Sciences, Emory University, Atlanta, GA, 30322 USASearch for more papers by this authorJing Cai Ph.D., Jing Cai Ph.D. ModeratorSearch for more papers by this author Lei Xing Ph.D., Lei Xing Ph.D. lei@stanford.edu Tel: 650-498-7896 Department of Radiation Oncology, Stanford University, Stanford, CA, 94305 USASearch for more papers by this authorElizabeth A. Krupinski Ph.D., Elizabeth A. Krupinski Ph.D. ekrupin@emory.edu Tel: 404-712-3868 Department of Radiology & Imaging Sciences, Emory University, Atlanta, GA, 30322 USASearch for more papers by this authorJing Cai Ph.D., Jing Cai Ph.D. ModeratorSearch for more papers by this author First published: 24 February 2018 https://doi.org/10.1002/mp.12831Citations: 45Read the full textAboutPDF ToolsRequest permissionExport citationAdd to favoritesTrack citation ShareShare Give accessShare full text accessShare full-text accessPlease review our Terms and Conditions of Use and check box below to share full-text version of article.I have read and accept the Wiley Online Library Terms and Conditions of UseShareable LinkUse the link below to share a full-text version of this article with your friends and colleagues. Learn more.Copy URL Share a linkShare onFacebookTwitterLinkedInRedditWechat No abstract is available for this article.Citing Literature Volume45, Issue5May 2018Pages 1791-1793 RelatedInformation"
        },
        {
            "reference_num": "[10]",
            "reference_title": "Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer",
            "reference_abstract": "<h3>Importance</h3> Application of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency. <h3>Objective</h3> Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin–stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists’ diagnoses in a diagnostic setting. <h3>Design, Setting, and Participants</h3> Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n = 110) and without (n = 160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). <h3>Exposures</h3> Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. <h3>Main Outcomes and Measures</h3> The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. <h3>Results</h3> The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4% [95% CI, 64.3%-80.4%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884];<i>P</i> &lt; .001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95% CI, 0.927-0.998] for the pathologist WOTC). <h3>Conclusions and Relevance</h3> In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting."
        },
        {
            "reference_num": "[11]",
            "reference_title": "P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, D. Ding, A. Bagul, C. Langlotz, K. Shpanskaya et al., “Chexnet: Radiologistlevel pneumonia detection on chest x-rays with deep learning,” arXiv preprint arXiv:1711.05225, 2017.",
            "reference_abstract": "We develop an algorithm that can detect pneumonia from chest X-rays at a\nlevel exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer\nconvolutional neural network trained on ChestX-ray14, currently the largest\npublicly available chest X-ray dataset, containing over 100,000 frontal-view\nX-ray images with 14 diseases. Four practicing academic radiologists annotate a\ntest set, on which we compare the performance of CheXNet to that of\nradiologists. We find that CheXNet exceeds average radiologist performance on\nthe F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and\nachieve state of the art results on all 14 diseases."
        },
        {
            "reference_num": "[12]",
            "reference_title": "Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs",
            "reference_abstract": "Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation.To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs.A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency.Deep learning-trained algorithm.The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity.The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2% women; prevalence of RDR, 683/8878 fully gradable images [7.8%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6% women; prevalence of RDR, 254/1745 fully gradable images [14.6%]). For detecting RDR, the algorithm had an area under the receiver operating curve of 0.991 (95% CI, 0.988-0.993) for EyePACS-1 and 0.990 (95% CI, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivity was 90.3% (95% CI, 87.5%-92.7%) and the specificity was 98.1% (95% CI, 97.8%-98.5%). For Messidor-2, the sensitivity was 87.0% (95% CI, 81.1%-91.0%) and the specificity was 98.5% (95% CI, 97.7%-99.1%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivity was 97.5% and specificity was 93.4% and for Messidor-2 the sensitivity was 96.1% and specificity was 93.9%.In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment."
        },
        {
            "reference_num": "[13]",
            "reference_title": "Dermatologist-level classification of skin cancer with deep neural networks",
            "reference_abstract": "An artificial intelligence trained to classify images of skin lesions as benign lesions or malignant skin cancers achieves the accuracy of board-certified dermatologists. Andre Esteva et al. used 129,450 clinical images of skin disease to train a deep convolutional neural network to classify skin lesions. The result is an algorithm that can classify lesions from photographic images similar to those taken with a mobile phone. The accuracy of the system in detecting malignant melanomas and carcinomas matched that of trained dermatologists. The authors suggest that the technique could be used outside the clinic as a visual screen for cancer. Skin cancer, the most common human malignancy1,2,3, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs)4,5 show potential for general and highly variable tasks across many fine-grained object categories6,7,8,9,10,11. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images—two orders of magnitude larger than previous datasets12—consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care."
        },
        {
            "reference_num": "[14]",
            "reference_title": "Automating Motion Correction in Multishot MRI Using Generative Adversarial Networks.",
            "reference_abstract": "Multishot Magnetic Resonance Imaging (MRI) has recently gained popularity as it accelerates the MRI data acquisition process without compromising the quality of final MR image. However, it suffers from motion artifacts caused by patient movements which may lead to misdiagnosis. Modern state-of-the-art motion correction techniques are able to counter small degree motion, however, their adoption is hindered by their time complexity. This paper proposes a Generative Adversarial Network (GAN) for reconstructing motion free high-fidelity images while reducing the image reconstruction time by an impressive two orders of magnitude."
        },
        {
            "reference_num": "[15]",
            "reference_title": "Big Data Deep Learning: Challenges and Perspectives",
            "reference_abstract": "Deep learning is currently an extremely active research area in machine learning and pattern recognition society. It has gained huge successes in a broad area of applications such as speech recognition, computer vision, and natural language processing. With the sheer size of data available today, big data brings big opportunities and transformative potential for various sectors; on the other hand, it also presents unprecedented challenges to harnessing data and information. As the data keeps getting bigger, deep learning is coming to play a key role in providing big data predictive analytics solutions. In this paper, we provide a brief overview of deep learning, and highlight current research efforts and the challenges to big data, as well as the future trends."
        },
        {
            "reference_num": "[16]",
            "reference_title": "Intriguing properties of neural networks",
            "reference_abstract": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input."
        },
        {
            "reference_num": "[17]",
            "reference_title": "Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks",
            "reference_abstract": "Data poisoning is an attack on machine learning models wherein the attacker adds examples to the training set to manipulate the behavior of the model at test time. This paper explores poisoning attacks on neural nets. The proposed attacks use \"clean-labels\"; they don't require the attacker to have any control over the labeling of training data. They are also targeted; they control the behavior of the classifier on a $\\textit{specific}$ test instance without degrading overall classifier performance. For example, an attacker could add a seemingly innocuous image (that is properly labeled) to a training set for a face recognition engine, and control the identity of a chosen person at test time. Because the attacker does not need to control the labeling function, poisons could be entered into the training set simply by leaving them on the web and waiting for them to be scraped by a data collection bot. We present an optimization-based method for crafting poisons, and show that just one single poison image can control classifier behavior when transfer learning is used. For full end-to-end training, we present a \"watermarking\" strategy that makes poisoning reliable using multiple ($\\approx$50) poisoned training instances. We demonstrate our method by generating poisoned frog images from the CIFAR dataset and using them to manipulate image classifiers."
        },
        {
            "reference_num": "[18]",
            "reference_title": "Adversarial Examples: Attacks and Defenses for Deep Learning",
            "reference_abstract": "With rapid progress and significant successes in a wide spectrum of applications, deep learning is being applied in many safety-critical environments. However, deep neural networks have been recently found vulnerable to well-designed input samples, called adversarial examples. Adversarial examples are imperceptible to human but can easily fool deep neural networks in the testing/deploying stage. The vulnerability to adversarial examples becomes one of the major risks for applying deep neural networks in safety-critical environments. Therefore, attacks and defenses on adversarial examples draw great attention. In this paper, we review recent findings on adversarial examples for deep neural networks, summarize the methods for generating adversarial examples, and propose a taxonomy of these methods. Under the taxonomy, applications for adversarial examples are investigated. We further elaborate on countermeasures for adversarial examples and explore the challenges and the potential solutions."
        },
        {
            "reference_num": "[19]",
            "reference_title": "Adversarial attacks on medical machine learning",
            "reference_abstract": "Emerging vulnerabilities demand new conversations"
        },
        {
            "reference_num": "[20]",
            "reference_title": "Toward an Understanding of Adversarial Examples in Clinical Trials",
            "reference_abstract": "Deep learning systems can be fooled by small, worst-case perturbations of their inputs, known as adversarial examples. This has been almost exclusively studied in supervised learning, on vision tasks. However, adversarial examples in counterfactual modelling, which sits outside the traditional supervised scenario, is an overlooked challenge. We introduce the concept of adversarial patients, in the context of counterfactual models for clinical trials—this turns out to introduce several new dimensions to the literature. We describe how there exist multiple types of adversarial example—and demonstrate different consequences, e.g. ethical, when they arise. The study of adversarial examples in this area is rich in challenges for accountability and trustworthiness in ML–we highlight future directions that may be of interest to the community."
        },
        {
            "reference_num": "[21]",
            "reference_title": "Anomaly Detection for Discrete Sequences: A Survey",
            "reference_abstract": "This survey attempts to provide a comprehensive and structured overview of the existing research for the problem of detecting anomalies in discrete/symbolic sequences. The objective is to provide a global understanding of the sequence anomaly detection problem and how existing techniques relate to each other. The key contribution of this survey is the classification of the existing research into three distinct categories, based on the problem formulation that they are trying to solve. These problem formulations are: 1) identifying anomalous sequences with respect to a database of normal sequences; 2) identifying an anomalous subsequence within a long sequence; and 3) identifying a pattern in a sequence whose frequency of occurrence is anomalous. We show how each of these problem formulations is characteristically distinct from each other and discuss their relevance in various application domains. We review techniques from many disparate and disconnected application domains that address each of these formulations. Within each problem formulation, we group techniques into categories based on the nature of the underlying algorithm. For each category, we provide a basic anomaly detection technique, and show how the existing techniques are variants of the basic technique. This approach shows how different techniques within a category are related or different from each other. Our categorization reveals new variants and combinations that have not been investigated before for anomaly detection. We also provide a discussion of relative strengths and weaknesses of different techniques. We show how techniques developed for one problem formulation can be adapted to solve a different formulation, thereby providing several novel adaptations to solve the different problem formulations. We also highlight the applicability of the techniques that handle discrete sequences to other related areas such as online anomaly detection and time series anomaly detection."
        },
        {
            "reference_num": "[22]",
            "reference_title": "DataMining Clustering Techniques in the Prediction of Heart Disease using Attribute Selection Method",
            "reference_abstract": "Heart disease is the leading cause of death in the world over the past 10 years. In this paper proposes the performance of clustering algorithm using heart disease data. We are evaluating the performance of clustering algorithms of EM, Cobweb, Farthest First, Make Density Based Clusters, Simple K-Means algorithms. The performance of clusters will be calculated using the mode of classes to clusters evaluation. The selected attributes after the Common Features Subset Evaluator (CFs) and Best-First Search (BFs) are cp, restecg, thalach, exang, oldpeak, ca, thal, and num. In the final result, Make Density Based Clusters shows the high performance algorithms for heart disease data after applying the Attribute selection Method and their Prediction Accuracy is 85.80%."
        },
        {
            "reference_num": "[23]",
            "reference_title": "Prediction of hepatitis disease based on principal component analysis and artificial immune recognition system",
            "reference_abstract": "In this study, prediction of hepatitis disease, which is a very common and important disease, was conducted with principal component analysis (PCA) and artificial immune recognition system (AIRS). The proposed approach consists of two stages. Firstly, the feature number of hepatitis disease dataset was reduced to 5 from 19 by principal component analysis (PCA). Secondly, hepatitis disease dataset is normalized in the range of [0, 1]. Normalized input values is classified by using AIRS classifier system. We took the dataset used in our study from the UCI Machine Learning Database. The obtained classification accuracy of our system was 94.12% using 10-fold cross-validation and it was very promising with regard to the other classification applications in Literature for this problem. Testing results were found to be compliant with the expected results that are derived from the physician’s direct diagnosis. The end benefit would be to assist the physician to make the final decision without hesitation. This result is for hepatitis disease but it states that this method can be used confidently for other medical diseases diagnosis problems, too."
        },
        {
            "reference_num": "[24]",
            "reference_title": "A Systematic Review on Supervised and Unsupervised Machine Learning Algorithms for Data Science",
            "reference_abstract": "Machine learning is as growing as fast as concepts such as Big data and the field of data science in general. The purpose of the systematic review was to analyze scholarly articles that were published between 2015 and 2018 addressing or implementing supervised and unsupervised machine learning techniques in different problem-solving paradigms. Using the elements of PRISMA, the review process identified 84 scholarly articles that had been published in different journals. Of the 84 articles, 6 were published before 2015 despite their metadata indicating that they were published in 2015. The existence of the six articles in the final papers was attributed to errors in indexing. Nonetheless, from the reviewed papers, decision tree, support vector machine, and Naïve Bayes algorithms appeared to be the most cited, discussed, and implemented supervised learners. Conversely, k-means, hierarchical clustering, and principal component analysis also emerged as the commonly used unsupervised learners. The review also revealed other commonly used algorithms that include ensembles and reinforce learners, and future systematic reviews can focus on them because of the developments that machine learning and data science is undergoing at the moment."
        },
        {
            "reference_num": "[25]",
            "reference_title": "A Euclidean Group Assessment on Semi-Supervised Clustering for Healthcare Clinical Implications Based on Real-Life Data",
            "reference_abstract": "The grouping of clusters is an important task to perform for the initial stage of clinical implication and diagnosis of a disease. The researchers performed evaluation work on instance distributions and cluster groups for epidemic classification, based on manual data extracted from various repositories, in order to evaluate Euclidean points. This study was carried out on Weka (3.9.2) using 281 real-life health records of diabetes mellitus patients including males and females of ages&gt;20 and &lt;87, who were simultaneously suffering from other chronic disease symptoms, in Nigeria from 2017 to 2018. Updated plugins of K-mean and self-organizing map(SOM) machine learning algorithms were used to cluster the data class of mellitus type for initial clinical implications. The results of the K-mean assessment were built in 0.21 seconds with nine iterations for “type” and eight for “class” attributes. Out of 281 instances, 87 (30.97%) were classified as negative and 194 (69.03%) as positive in the testing on the Euclidean space plot. By assessment for Euclidean points, SOM discovered the search space in a more effective way, but K-mean positioning potencies are impulsive in convergence. This study is important for epidemiological disease diagnosis in countries with a high epidemic risk and low socioeconomic status."
        },
        {
            "reference_num": "[26]",
            "reference_title": "Sensor-Based Human Activity Recognition for Smart Healthcare: A Semi-supervised Machine Learning",
            "reference_abstract": ""
        },
        {
            "reference_num": "[27]",
            "reference_title": "Semi-supervised learning and graph cuts for consensus based medical image segmentation",
            "reference_abstract": "Medical image segmentation requires consensus ground truth segmentations to be derived from multiple expert annotations. A novel approach is proposed that obtains consensus segmentations from experts using graph cuts (GC) and semi supervised learning (SSL). Popular approaches use iterative Expectation Maximization (EM) to estimate the final annotation and quantify annotator's performance. Such techniques pose the risk of getting trapped in local minima. We propose a self consistency (SC) score to quantify annotator consistency using low level image features. SSL is used to predict missing annotations by considering global features and local image consistency. The SC score also serves as the penalty cost in a second order Markov random field (MRF) cost function optimized using graph cuts to derive the final consensus label. Graph cut obtains a global maximum without an iterative procedure. Experimental results on synthetic images, real data of Crohn's disease patients and retinal images show our final segmentation to be accurate and more consistent than competing methods."
        },
        {
            "reference_num": "[28]",
            "reference_title": "W. Bai, O. Oktay, M. Sinclair, H. Suzuki, M. Rajchl, G. Tarroni, B. Glocker, A. King, P. M. Matthews, and D. Rueckert, “Semisupervised learning for network-based cardiac mr image segmentation,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2017, pp. 253–260.",
            "reference_abstract": "Cardiovascular magnetic resonance (CMR) imaging is a standard imaging\nmodality for assessing cardiovascular diseases (CVDs), the leading cause of\ndeath globally. CMR enables accurate quantification of the cardiac chamber\nvolume, ejection fraction and myocardial mass, providing information for\ndiagnosis and monitoring of CVDs. However, for years, clinicians have been\nrelying on manual approaches for CMR image analysis, which is time consuming\nand prone to subjective errors. It is a major clinical challenge to\nautomatically derive quantitative and clinically relevant information from CMR\nimages. Deep neural networks have shown a great potential in image pattern\nrecognition and segmentation for a variety of tasks. Here we demonstrate an\nautomated analysis method for CMR images, which is based on a fully\nconvolutional network (FCN). The network is trained and evaluated on a\nlarge-scale dataset from the UK Biobank, consisting of 4,875 subjects with\n93,500 pixelwise annotated images. The performance of the method has been\nevaluated using a number of technical metrics, including the Dice metric, mean\ncontour distance and Hausdorff distance, as well as clinically relevant\nmeasures, including left ventricle (LV) end-diastolic volume (LVEDV) and\nend-systolic volume (LVESV), LV mass (LVM); right ventricle (RV) end-diastolic\nvolume (RVEDV) and end-systolic volume (RVESV). By combining FCN with a\nlarge-scale annotated dataset, the proposed automated method achieves a high\nperformance on par with human experts in segmenting the LV and RV on short-axis\nCMR images and the left atrium (LA) and right atrium (RA) on long-axis CMR\nimages."
        },
        {
            "reference_num": "[29]",
            "reference_title": "Introduction to Reinforcement Learning",
            "reference_abstract": "From the Publisher:\r\nIn Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability."
        },
        {
            "reference_num": "[30]",
            "reference_title": "Context-Aware Symptom Checking for Disease Diagnosis Using Hierarchical Reinforcement Learning",
            "reference_abstract": "Online symptom checkers have been deployed by sites such as WebMD and Mayo Clinic to identify possible causes and treatments for diseases based on a patient’s symptoms. Symptom checking first assesses a patient by asking a series of questions about their symptoms, then attempts to predict potential diseases. The two design goals of a symptom checker are to achieve high accuracy and intuitive interactions. In this paper we present our context-aware hierarchical reinforcement learning scheme, which significantly improves accuracy of symptom checking over traditional systems while also making a limited number of inquiries."
        },
        {
            "reference_num": "[31]",
            "reference_title": "Mastering the game of Go with deep neural networks and tree search",
            "reference_abstract": ""
        },
        {
            "reference_num": "[32]",
            "reference_title": "Machine Learning Approaches: Data Integration for Disease Prediction and Prognosis",
            "reference_abstract": "Machine learning (ML) is an analytical approach that has been on increasing importance in this field. In this chapter, we would like to highlight the use of ML for disease risk prediction and prognosis to identify the scope of successful applications to date. Despite the enthusiasm, we feel that the evaluation of ML methods in real data sets has been limited thus far. We also feel that machine learning approaches can serve as methods of choice for the integration of the ever more complex data sets being generated in the era of next-generation sequencing."
        },
        {
            "reference_num": "[33]",
            "reference_title": "Brain Tumor Type Classification via Capsule Networks",
            "reference_abstract": "Brain tumor is considered as one of the deadliest and most common form of cancer both in children and in adults. Consequently, determining the correct type of brain tumor in early stages is of significant importance to devise a precise treatment plan and predict patient's response to the adopted treatment. In this regard, there has been a recent surge of interest in designing Convolutional Neural Networks (CNNs) for the problem of brain tumor type classification. However, CNNs typically require large amount of training data and can not properly handle input transformations. Capsule networks (referred to as CapsNets) are brand new machine learning architectures proposed very recently to overcome these shortcomings of CNNs, and posed to revolutionize deep learning solutions. Of particular interest to this work is that Capsule networks are robust to rotation and affine transformation, and require far less training data, which is the case for processing medical image datasets including brain Magnetic Resonance Imaging (MRI) images. In this paper, we focus to achieve the following four objectives: (i) Adopt and incorporate CapsNets for the problem of brain tumor classification to design an improved architecture which maximizes the accuracy of the classification problem at hand; (ii) Investigate the over-fitting problem of CapsNets based on a real set of MRI images; (iii) Explore whether or not CapsNets are capable of providing better fit for the whole brain images or just the segmented tumor, and; (iv) Develop a visualization paradigm for the output of the CapsNet to better explain the learned features. Our results show that the proposed approach can successfully overcome CNNs for the brain tumor classification problem."
        },
        {
            "reference_num": "[34]",
            "reference_title": "DeepLung: Deep 3D Dual Path Nets for Automated Pulmonary Nodule Detection and Classification",
            "reference_abstract": "In this work, we present a fully automated lung computed tomography (CT) cancer diagnosis system, DeepLung. DeepLung consists of two components, nodule detection (identifying the locations of candidate nodules) and classification (classifying candidate nodules into benign or malignant). Considering the 3D nature of lung CT data and the compactness of dual path networks (DPN), two deep 3D DPN are designed for nodule detection and classification respectively. Specifically, a 3D Faster Regions with Convolutional Neural Net (R-CNN) is designed for nodule detection with 3D dual path blocks and a U-net-like encoder-decoder structure to effectively learn nodule features. For nodule classification, gradient boosting machine (GBM) with 3D dual path network features is proposed. The nodule classification subnetwork was validated on a public dataset from LIDC-IDRI, on which it achieved better performance than state-of-the-art approaches and surpassed the performance of experienced doctors based on image modality. Within the DeepLung system, candidate nodules are detected first by the nodule detection subnetwork, and nodule diagnosis is conducted by the classification subnetwork. Extensive experimental results demonstrate that DeepLung has performance comparable to experienced doctors both for the nodule-level and patient-level diagnosis on the LIDC-IDRI dataset."
        },
        {
            "reference_num": "[35]",
            "reference_title": "Mining electronic health records: towards better research applications and clinical care",
            "reference_abstract": ""
        },
        {
            "reference_num": "[36]",
            "reference_title": "Extracting Diagnoses and Investigation Results from Unstructured Text in Electronic Health Records by Semi-Supervised Machine Learning",
            "reference_abstract": "Electronic health records are invaluable for medical research, but much of the information is recorded as unstructured free text which is time-consuming to review manually.To develop an algorithm to identify relevant free texts automatically based on labelled examples.We developed a novel machine learning algorithm, the 'Semi-supervised Set Covering Machine' (S3CM), and tested its ability to detect the presence of coronary angiogram results and ovarian cancer diagnoses in free text in the General Practice Research Database. For training the algorithm, we used texts classified as positive and negative according to their associated Read diagnostic codes, rather than by manual annotation. We evaluated the precision (positive predictive value) and recall (sensitivity) of S3CM in classifying unlabelled texts against the gold standard of manual review. We compared the performance of S3CM with the Transductive Vector Support Machine (TVSM), the original fully-supervised Set Covering Machine (SCM) and our 'Freetext Matching Algorithm' natural language processor.Only 60% of texts with Read codes for angiogram actually contained angiogram results. However, the S3CM algorithm achieved 87% recall with 64% precision on detecting coronary angiogram results, outperforming the fully-supervised SCM (recall 78%, precision 60%) and TSVM (recall 2%, precision 3%). For ovarian cancer diagnoses, S3CM had higher recall than the other algorithms tested (86%). The Freetext Matching Algorithm had better precision than S3CM (85% versus 74%) but lower recall (62%).Our novel S3CM machine learning algorithm effectively detected free texts in primary care records associated with angiogram results and ovarian cancer diagnoses, after training on pre-classified test sets. It should be easy to adapt to other disease areas as it does not rely on linguistic rules, but needs further testing in other electronic health record datasets."
        },
        {
            "reference_num": "[37]",
            "reference_title": "A machine learning-based framework to identify type 2 diabetes through electronic health records",
            "reference_abstract": "To discover diverse genotype-phenotype associations affiliated with Type 2 Diabetes Mellitus (T2DM) via genome-wide association study (GWAS) and phenome-wide association study (PheWAS), more cases (T2DM subjects) and controls (subjects without T2DM) are required to be identified (e.g., via Electronic Health Records (EHR)). However, existing expert based identification algorithms often suffer in a low recall rate and could miss a large number of valuable samples under conservative filtering standards. The goal of this work is to develop a semi-automated framework based on machine learning as a pilot study to liberalize filtering criteria to improve recall rate with a keeping of low false positive rate. We propose a data informed framework for identifying subjects with and without T2DM from EHR via feature engineering and machine learning. We evaluate and contrast the identification performance of widely-used machine learning models within our framework, including k-Nearest-Neighbors, Naïve Bayes, Decision Tree, Random Forest, Support Vector Machine and Logistic Regression. Our framework was conducted on 300 patient samples (161 cases, 60 controls and 79 unconfirmed subjects), randomly selected from 23,281 diabetes related cohort retrieved from a regional distributed EHR repository ranging from 2012 to 2014. We apply top-performing machine learning algorithms on the engineered features. We benchmark and contrast the accuracy, precision, AUC, sensitivity and specificity of classification models against the state-of-the-art expert algorithm for identification of T2DM subjects. Our results indicate that the framework achieved high identification performances (∼0.98 in average AUC), which are much higher than the state-of-the-art algorithm (0.71 in AUC). Expert algorithm-based identification of T2DM subjects from EHR is often hampered by the high missing rates due to their conservative selection criteria. Our framework leverages machine learning and feature engineering to loosen such selection criteria to achieve a high identification rate of cases and controls. Our proposed framework demonstrates a more accurate and efficient approach for identifying subjects with and without T2DM from EHR."
        },
        {
            "reference_num": "[38]",
            "reference_title": "Feature Robustness in Non-stationary Health Records: Caveats to Deployable Model Performance in Common Clinical Machine Learning Tasks",
            "reference_abstract": "When training clinical prediction models from electronic health records (EHRs), a key concern should be a model's ability to sustain performance over time when deployed, even as care practices, database systems, and population demographics evolve. Due to de-identification requirements, however, current experimental practices for public EHR benchmarks (such as the MIMIC-III critical care dataset) are time agnostic, assigning care records to train or test sets without regard for the actual dates of care. As a result, current benchmarks cannot assess how well models trained on one year generalise to another. In this work, we obtain a Limited Data Use Agreement to access year of care for each record in MIMIC and show that all tested state-of-the-art models decay in prediction quality when trained on historical data and tested on future data, particularly in response to a system-wide record-keeping change in 2008 (0.29 drop in AUROC for mortality prediction, 0.10 drop in AUROC for length-of-stay prediction with a random forest classifier). We further develop a simple yet effective mitigation strategy: by aggregating raw features into expert-defined clinical concepts, we see only a 0.06 drop in AUROC for mortality prediction and a 0.03 drop in AUROC for length-of-stay prediction. We demonstrate that this aggregation strategy outperforms other automatic feature preprocessing techniques aimed at increasing robustness to data drift. We release our aggregated representations and code to encourage more deployable clinical prediction models."
        },
        {
            "reference_num": "[39]",
            "reference_title": "Medical Image Analysis using Convolutional Neural Networks: A Review",
            "reference_abstract": "The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an effective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering has made medical image analysis one of the top research and development area. One of the reason for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This include application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted."
        },
        {
            "reference_num": "[40]",
            "reference_title": "M. Lustig, D. L. Donoho, J. M. Santos, and J. M. Pauly, “Compressed sensing mri,” IEEE signal processing magazine, vol. 25, no. 2, pp. 72–82, 2008.",
            "reference_abstract": "We propose and analyze an extremely fast, efficient, and simple method for\nsolving the problem:min{parallel to u parallel to(1) : Au = f, u is an element\nof R-n}.This method was first described in [J. Darbon and S. Osher, preprint,\n2007], with more details in [W. Yin, S. Osher, D. Goldfarb and J. Darbon, SIAM\nJ. Imaging Sciences, 1(1), 143-168, 2008] and rigorous theory given in [J. Cai,\nS. Osher and Z. Shen, Math. Comp., to appear, 2008, see also UCLA CAM Report\n08-06] and [J. Cai, S. Osher and Z. Shen, UCLA CAM Report, 08-52, 2008]. The\nmotivation was compressive sensing, which now has a vast and exciting history,\nwhich seems to have started with Candes, et. al. [E. Candes, J. Romberg and T.\nTao, 52(2), 489-509, 2006] and Donoho, [D. L. Donoho, IEEE Trans. Inform.\nTheory, 52, 1289-1306, 2006]. See [W. Yin, S. Osher, D. Goldfarb and J. Darbon,\nSIAM J. Imaging Sciences 1(1), 143-168, 2008] and [J. Cai, S. Osher and Z.\nShen, Math. Comp., to appear, 2008, see also UCLA CAM Report, 08-06] and [J.\nCai, S. Osher and Z. Shen, UCLA CAM Report, 08-52, 2008] for a large set of\nreferences. Our method introduces an improvement called \"kicking\" of the very\nefficient method of [J. Darbon and S. Osher, preprint, 2007] and [W. Yin, S.\nOsher, D. Goldfarb and J. Darbon, SIAM J. Imaging Sciences, 1(1), 143-168,\n2008] and also applies it to the problem of denoising of undersampled signals.\nThe use of Bregman iteration for denoising of images began in [S. Osher, M.\nBurger, D. Goldfarb, J. Xu and W. Yin, Multiscale Model. Simul, 4(2), 460-489,\n2005] and led to improved results for total variation based methods. Here we\napply it to denoise signals, especially essentially sparse signals, which might\neven be undersampled."
        },
        {
            "reference_num": "[41]",
            "reference_title": "L. Gondara, “Medical image denoising using convolutional denoising autoencoders,” in 2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW). IEEE, 2016, pp. 241–246.",
            "reference_abstract": "Image denoising is an important pre-processing step in medical image\nanalysis. Different algorithms have been proposed in past three decades with\nvarying denoising performances. More recently, having outperformed all\nconventional methods, deep learning based models have shown a great promise.\nThese methods are however limited for requirement of large training sample size\nand high computational costs. In this paper we show that using small sample\nsize, denoising autoencoders constructed using convolutional layers can be used\nfor efficient denoising of medical images. Heterogeneous images can be combined\nto boost sample size for increased denoising performance. Simplest of networks\ncan reconstruct images with corruption levels so high that noise and signal are\nnot differentiable to human eye."
        },
        {
            "reference_num": "[42]",
            "reference_title": "Y. Chen, Y. Xie, Z. Zhou, F. Shi, A. G. Christodoulou, and D. Li, “Brain mri super resolution using 3d deep densely connected neural networks,” in 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). IEEE, 2018, pp. 739–742.",
            "reference_abstract": "Magnetic resonance image (MRI) in high spatial resolution provides detailed\nanatomical information and is often necessary for accurate quantitative\nanalysis. However, high spatial resolution typically comes at the expense of\nlonger scan time, less spatial coverage, and lower signal to noise ratio (SNR).\nSingle Image Super-Resolution (SISR), a technique aimed to restore\nhigh-resolution (HR) details from one single low-resolution (LR) input image,\nhas been improved dramatically by recent breakthroughs in deep learning. In\nthis paper, we introduce a new neural network architecture, 3D Densely\nConnected Super-Resolution Networks (DCSRN) to restore HR features of\nstructural brain MR images. Through experiments on a dataset with 1,113\nsubjects, we demonstrate that our network outperforms bicubic interpolation as\nwell as other deep learning methods in restoring 4x resolution-reduced images."
        },
        {
            "reference_num": "[43]",
            "reference_title": "K. Sirinukunwattana, S. e Ahmed Raza, Y.-W. Tsang, D. R. Snead, I. A. Cree, and N. M. Rajpoot, “Locality sensitive deep learning for detection and classiﬁcation of nuclei in routine colon cancer histology images.” IEEE Trans. Med. Imaging, vol. 35, no. 5, pp. 1196–1206, 2016.",
            "reference_abstract": "The development of deep segmentation models for computational pathology\n(CPath) can help foster the investigation of interpretable morphological\nbiomarkers. Yet, there is a major bottleneck in the success of such approaches\nbecause supervised deep learning models require an abundance of accurately\nlabelled data. This issue is exacerbated in the field of CPath because the\ngeneration of detailed annotations usually demands the input of a pathologist\nto be able to distinguish between different tissue constructs and nuclei.\nManually labelling nuclei may not be a feasible approach for collecting\nlarge-scale annotated datasets, especially when a single image region can\ncontain thousands of different cells. However, solely relying on automatic\ngeneration of annotations will limit the accuracy and reliability of ground\ntruth. Therefore, to help overcome the above challenges, we propose a\nmulti-stage annotation pipeline to enable the collection of large-scale\ndatasets for histology image analysis, with pathologist-in-the-loop refinement\nsteps. Using this pipeline, we generate the largest known nuclear instance\nsegmentation and classification dataset, containing nearly half a million\nlabelled nuclei in H&amp;E stained colon tissue. We have released the dataset and\nencourage the research community to utilise it to drive forward the development\nof downstream cell-based models in CPath."
        },
        {
            "reference_num": "[44]",
            "reference_title": "H. Wang, A. C. Roa, A. N. Basavanhally, H. L. Gilmore, N. Shih, M. Feldman, J. Tomaszewski, F. Gonzalez, and A. Madabhushi, “Mitosis detection in breast cancer pathology images by combining handcrafted and convolutional neural network features,” Journal of Medical Imaging, vol. 1, no. 3, p. 034003, 2014.",
            "reference_abstract": "The proliferative activity of breast tumors, which is routinely estimated by\ncounting of mitotic figures in hematoxylin and eosin stained histology\nsections, is considered to be one of the most important prognostic markers.\nHowever, mitosis counting is laborious, subjective and may suffer from low\ninter-observer agreement. With the wider acceptance of whole slide images in\npathology labs, automatic image analysis has been proposed as a potential\nsolution for these issues. In this paper, the results from the Assessment of\nMitosis Detection Algorithms 2013 (AMIDA13) challenge are described. The\nchallenge was based on a data set consisting of 12 training and 11 testing\nsubjects, with more than one thousand annotated mitotic figures by multiple\nobservers. Short descriptions and results from the evaluation of eleven methods\nare presented. The top performing method has an error rate that is comparable\nto the inter-observer agreement among pathologists."
        },
        {
            "reference_num": "[45]",
            "reference_title": "Y. Yu, H. Lin, J. Meng, X. Wei, H. Guo, and Z. Zhao, “Deep transfer learning for modality classiﬁcation of medical images,” Information, vol. 8, no. 3, p. 91, 2017.",
            "reference_abstract": "By analyzing a data sample corresponding to an integrated luminosity of\n$2.93~\\mathrm{fb}^{-1}$ collected at a center-of-mass energy of 3.773 GeV with\nthe BESIII detector, we measure for the first time the absolute branching\nfraction of the $D^+\\to \\eta \\mu^+\\nu_\\mu$ decay to be ${\\mathcal B}_{D^+\\to\n\\eta \\mu^+\\nu_\\mu}=(10.4\\pm1.0_{\\rm stat}\\pm0.5_{\\rm syst})\\times 10^{-4}$.\nUsing the world averaged value of ${\\mathcal B}_{D^+\\to \\eta e^+\\nu_e}$, the\nratio of the two branching fractions is determined to be ${\\mathcal B}_{D^+\\to\n\\eta \\mu^+\\nu_\\mu}/{\\mathcal B}_{D^+\\to \\eta e^+\\nu_e}=0.91\\pm0.13$, which\nagrees with the theoretical expectation of lepton flavor universality within\nuncertainty. Here, the uncertainty is the sum in quadrature of the statistical\nand systematic uncertainties. By studying the differential decay rates in five\nfour-momentum transfer intervals, we obtain the product of the hadronic form\nfactor $f^{\\eta}_{+}(0)$ and the $c\\to d$ Cabibbo-Kobayashi-Maskawa matrix\nelement $|V_{cd}|$ to be $f_{+}^\\eta (0)|V_{cd}|=0.087\\pm0.008_{\\rm\nstat}\\pm0.002_{\\rm syst}$. Taking the input of $|V_{cd}|$ from the global fit\nin the standard model, we determine $f_{+}^\\eta (0)=0.39\\pm0.04_{\\rm\nstat}\\pm0.01_{\\rm syst}$. On the other hand, using the value of $f_+^{\\eta}(0)$\ncalculated in theory, we find $|V_{cd}|=0.242\\pm0.022_{\\rm stat}\\pm0.006_{\\rm\nsyst}\\pm0.033_{\\rm theory}$."
        },
        {
            "reference_num": "[46]",
            "reference_title": "J. Antony, K. McGuinness, N. E. O’Connor, and K. Moran, “Quantifying radiographic knee osteoarthritis severity using deep convolutional neural networks,” in 2016 23rd International Conference on Pattern Recognition (ICPR). IEEE, 2016, pp. 1195–1200.",
            "reference_abstract": "This paper proposes a new approach to automatically quantify the severity of\nknee osteoarthritis (OA) from radiographs using deep convolutional neural\nnetworks (CNN). Clinically, knee OA severity is assessed using Kellgren \\&amp;\nLawrence (KL) grades, a five point scale. Previous work on automatically\npredicting KL grades from radiograph images were based on training shallow\nclassifiers using a variety of hand engineered features. We demonstrate that\nclassification accuracy can be significantly improved using deep convolutional\nneural network models pre-trained on ImageNet and fine-tuned on knee OA images.\nFurthermore, we argue that it is more appropriate to assess the accuracy of\nautomatic knee OA severity predictions using a continuous distance-based\nevaluation metric like mean squared error than it is to use classification\naccuracy. This leads to the formulation of the prediction of KL grades as a\nregression problem and further improves accuracy. Results on a dataset of X-ray\nimages and KL grades from the Osteoarthritis Initiative (OAI) show a sizable\nimprovement over the current state-of-the-art."
        },
        {
            "reference_num": "[47]",
            "reference_title": "E. Kim, M. Corte-Real, and Z. Baloch, “A deep semantic mobile application for thyroid cytopathology,” in Medical Imaging 2016: PACS and Imaging Informatics: Next Generation and Innovations, vol. 9789. International Society for Optics and Photonics, 2016, p. 97890A.",
            "reference_abstract": "The incidence of thyroid nodule is very high and generally increases with the\nage. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid\nnodule can be completely cured if detected early. Fine needle aspiration\ncytology is a recognized early diagnosis method of thyroid nodule. There are\nstill some limitations in the fine needle aspiration cytology, and the\nultrasound diagnosis of thyroid nodule has become the first choice for\nauxiliary examination of thyroid nodular disease. If we could combine medical\nimaging technology and fine needle aspiration cytology, the diagnostic rate of\nthyroid nodule would be improved significantly. The properties of ultrasound\nwill degrade the image quality, which makes it difficult to recognize the edges\nfor physicians. Image segmentation technique based on graph theory has become a\nresearch hotspot at present. Normalized cut (Ncut) is a representative one,\nwhich is suitable for segmentation of feature parts of medical image. However,\nhow to solve the normalized cut has become a problem, which needs large memory\ncapacity and heavy calculation of weight matrix. It always generates over\nsegmentation or less segmentation which leads to inaccurate in the\nsegmentation. The speckle noise in B ultrasound image of thyroid tumor makes\nthe quality of the image deteriorate. In the light of this characteristic, we\ncombine the anisotropic diffusion model with the normalized cut in this paper.\nAfter the enhancement of anisotropic diffusion model, it removes the noise in\nthe B ultrasound image while preserves the important edges and local details.\nThis reduces the amount of computation in constructing the weight matrix of the\nimproved normalized cut and improves the accuracy of the final segmentation\nresults. The feasibility of the method is proved by the experimental results."
        },
        {
            "reference_num": "[48]",
            "reference_title": "M. F. Stollenga, W. Byeon, M. Liwicki, and J. Schmidhuber, “Parallel multi-dimensional lstm, with application to fast biomedical volumetric image segmentation,” in Advances in neural information processing systems, 2015, pp. 2998–3006.",
            "reference_abstract": "Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3D\nvideos to segment them. They have a fixed input size and typically perceive\nonly small local contexts of the pixels to be classified as foreground or\nbackground. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceive\nthe entire spatio-temporal context of each pixel in a few sweeps through all\npixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despite\nthese theoretical advantages, however, unlike CNNs, previous MD-LSTM variants\nwere hard to parallelize on GPUs. Here we re-arrange the traditional cuboid\norder of computations in MD-LSTM in pyramidal fashion. The resulting\nPyraMiD-LSTM is easy to parallelize, especially for 3D data such as stacks of\nbrain slice images. PyraMiD-LSTM achieved best known pixel-wise brain image\nsegmentation results on MRBrainS13 (and competitive results on EM-ISBI12)."
        },
        {
            "reference_num": "[49]",
            "reference_title": "O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference on Medical image computing and computer-assisted intervention. Springer, 2015, pp. 234–241.",
            "reference_abstract": "There is large consent that successful training of deep networks requires\nmany thousand annotated training samples. In this paper, we present a network\nand training strategy that relies on the strong use of data augmentation to use\nthe available annotated samples more efficiently. The architecture consists of\na contracting path to capture context and a symmetric expanding path that\nenables precise localization. We show that such a network can be trained\nend-to-end from very few images and outperforms the prior best method (a\nsliding-window convolutional network) on the ISBI challenge for segmentation of\nneuronal structures in electron microscopic stacks. Using the same network\ntrained on transmitted light microscopy images (phase contrast and DIC) we won\nthe ISBI cell tracking challenge 2015 in these categories by a large margin.\nMoreover, the network is fast. Segmentation of a 512x512 image takes less than\na second on a recent GPU. The full implementation (based on Caffe) and the\ntrained networks are available at\nhttp://lmb.informatik.uni-freiburg.de/people/ronneber/u-net ."
        },
        {
            "reference_num": "[50]",
            "reference_title": "F. Milletari, N. Navab, and S.-A. Ahmadi, “V-net: Fully convolutional neural networks for volumetric medical image segmentation,” in 2016 Fourth International Conference on 3D Vision (3DV). IEEE, 2016, pp. 565–571.",
            "reference_abstract": "Convolutional Neural Networks (CNNs) have been recently employed to solve\nproblems from both the computer vision and medical image analysis fields.\nDespite their popularity, most approaches are only able to process 2D images\nwhile most medical data used in clinical practice consists of 3D volumes. In\nthis work we propose an approach to 3D image segmentation based on a\nvolumetric, fully convolutional, neural network. Our CNN is trained end-to-end\non MRI volumes depicting prostate, and learns to predict segmentation for the\nwhole volume at once. We introduce a novel objective function, that we optimise\nduring training, based on Dice coefficient. In this way we can deal with\nsituations where there is a strong imbalance between the number of foreground\nand background voxels. To cope with the limited number of annotated volumes\navailable for training, we augment the data applying random non-linear\ntransformations and histogram matching. We show in our experimental evaluation\nthat our approach achieves good performances on challenging test data while\nrequiring only a fraction of the processing time needed by other previous\nmethods."
        },
        {
            "reference_num": "[51]",
            "reference_title": "M. H. Hesamian, W. Jia, X. He, and P. Kennedy, “Deep learning techniques for medical image segmentation: Achievements and challenges,” Journal of digital imaging, pp. 1–15, 2019.",
            "reference_abstract": "As a novel X-ray focusing technology, lobster eye micro-pore optics (MPO)\nfeature both a wide observing field of view and true imaging capability,\npromising sky monitoring with significantly improved sensitivity and spatial\nresolution in soft X-rays. Since first proposed by Angel (1979), the optics\nhave been extensively studied, developed and trialed over the past decades. In\nthis Letter, we report on the first-light results from a flight experiment of\nthe Lobster Eye Imager for Astronomy ($LEIA$), a pathfinder of the wide-field\nX-ray telescope of the Einstein Probe mission. The piggyback imager, launched\nin July 2022, has a mostly un-vignetted field of view of $18.6^\\circ \\times\n18.6^\\circ $. Its spatial resolution is in the range of 4$-$7 arcmin in FWHM\nand the focal spot effective area is 2$-$3 cm$^2$, both showing only mild\nfluctuations across the field of view. We present images of the Galactic center\nregion, Sco X-1 and the diffuse Cygnus Loop nebular taken in snapshot\nobservations over 0.5$-$4 keV. These are truly wide-field X-ray images of\ncelestial bodies observed, for the first time, by a focusing imaging telescope.\nInitial analyses of the in-flight data show excellent agreement between the\nobserved images and the on-ground calibration and simulations. The instrument\nand its characterization are briefly described, as well as the flight\nexperiment. The results provide a solid basis for the development of the\npresent and proposed wide-field X-ray missions using lobster eye MPO."
        },
        {
            "reference_num": "[52]",
            "reference_title": "H. Chen, Y. Zhang, M. K. Kalra, F. Lin, Y. Chen, P. Liao, J. Zhou, and G. Wang, “Low-dose ct with a residual encoder-decoder convolutional neural network,” IEEE transactions on medical imaging, vol. 36, no. 12, pp. 2524–2535, 2017.",
            "reference_abstract": "Given the potential X-ray radiation risk to the patient, low-dose CT has\nattracted a considerable interest in the medical imaging field. The current\nmain stream low-dose CT methods include vendor-specific sinogram domain\nfiltration and iterative reconstruction, but they need to access original raw\ndata whose formats are not transparent to most users. Due to the difficulty of\nmodeling the statistical characteristics in the image domain, the existing\nmethods for directly processing reconstructed images cannot eliminate image\nnoise very well while keeping structural details. Inspired by the idea of deep\nlearning, here we combine the autoencoder, the deconvolution network, and\nshortcut connections into the residual encoder-decoder convolutional neural\nnetwork (RED-CNN) for low-dose CT imaging. After patch-based training, the\nproposed RED-CNN achieves a competitive performance relative to\nthe-state-of-art methods in both simulated and clinical cases. Especially, our\nmethod has been favorably evaluated in terms of noise suppression, structural\npreservation and lesion detection."
        },
        {
            "reference_num": "[53]",
            "reference_title": "M. Usman, S. Latif, M. Asim, and J. Qadir, “Motion corrected multishot mri reconstruction using generative networks with sensitivity encoding,” arXiv preprint arXiv:1902.07430, 2019.",
            "reference_abstract": "Multishot Magnetic Resonance Imaging (MRI) is a promising imaging modality\nthat can produce a high-resolution image with relatively less data acquisition\ntime. The downside of multishot MRI is that it is very sensitive to subject\nmotion and even small amounts of motion during the scan can produce artifacts\nin the final MR image that may cause misdiagnosis. Numerous efforts have been\nmade to address this issue; however, all of these proposals are limited in\nterms of how much motion they can correct and the required computational time.\nIn this paper, we propose a novel generative networks based conjugate gradient\nSENSE (CG-SENSE) reconstruction framework for motion correction in multishot\nMRI. The proposed framework first employs CG-SENSE reconstruction to produce\nthe motion-corrupted image and then a generative adversarial network (GAN) is\nused to correct the motion artifacts. The proposed method has been rigorously\nevaluated on synthetically corrupted data on varying degrees of motion, numbers\nof shots, and encoding trajectories. Our analyses (both quantitative as well as\nqualitative/visual analysis) establishes that the proposed method significantly\nrobust and outperforms state-of-the-art motion correction techniques and also\nreduces severalfold of computational times."
        },
        {
            "reference_num": "[54]",
            "reference_title": "F. E.-Z. A. El-Gamal, M. Elmogy, and A. Atwan, “Current trends in medical image registration and fusion,” Egyptian Informatics Journal, vol. 17, no. 1, pp. 99–124, 2016.",
            "reference_abstract": "3D medical image registration is of great clinical importance. However,\nsupervised learning methods require a large amount of accurately annotated\ncorresponding control points (or morphing), which are very difficult to obtain.\nUnsupervised learning methods ease the burden of manual annotation by\nexploiting unlabeled data without supervision. In this paper, we propose a new\nunsupervised learning method using convolutional neural networks under an\nend-to-end framework, Volume Tweening Network (VTN), for 3D medical image\nregistration. We propose three innovative technical components: (1) An\nend-to-end cascading scheme that resolves large displacement; (2) An efficient\nintegration of affine registration network; and (3) An additional invertibility\nloss that encourages backward consistency. Experiments demonstrate that our\nalgorithm is 880x faster (or 3.3x faster without GPU acceleration) than\ntraditional optimization-based methods and achieves state-of-theart performance\nin medical image registration."
        },
        {
            "reference_num": "[55]",
            "reference_title": "J. Ker, L. Wang, J. Rao, and T. Lim, “Deep learning applications in medical image analysis,” Ieee Access, vol. 6, pp. 9375–9389, 2017.",
            "reference_abstract": "Deep learning algorithms have seen acute growth of interest in their\napplications throughout several fields of interest in the last decade, with\nmedical hyperspectral imaging being a particularly promising domain. So far, to\nthe best of our knowledge, there is no review paper that discusses the\nimplementation of deep learning for medical hyperspectral imaging, which is\nwhat this review paper aims to accomplish by examining publications that\ncurrently utilize deep learning to perform effective analysis of medical\nhyperspectral imagery. This paper discusses deep learning concepts that are\nrelevant and applicable to medical hyperspectral imaging analysis, several of\nwhich have been implemented since the boom in deep learning. This will comprise\nof reviewing the use of deep learning for classification, segmentation, and\ndetection in order to investigate the analysis of medical hyperspectral\nimaging. Lastly, we discuss the current and future challenges pertaining to\nthis discipline and the possible efforts to overcome such trials."
        },
        {
            "reference_num": "[56]",
            "reference_title": "X. Yang, R. Kwitt, M. Styner, and M. Niethammer, “Quicksilver: Fast predictive image registration–a deep learning approach,” NeuroImage, vol. 158, pp. 378–396, 2017.",
            "reference_abstract": "We introduce a deep encoder-decoder architecture for image deformation\nprediction from multimodal images. Specifically, we design an image-patch-based\ndeep network that jointly (i) learns an image similarity measure and (ii) the\nrelationship between image patches and deformation parameters. While our method\ncan be applied to general image registration formulations, we focus on the\nLarge Deformation Diffeomorphic Metric Mapping (LDDMM) registration model. By\npredicting the initial momentum of the shooting formulation of LDDMM, we\npreserve its mathematical properties and drastically reduce the computation\ntime, compared to optimization-based approaches. Furthermore, we create a\nBayesian probabilistic version of the network that allows evaluation of\nregistration uncertainty via sampling of the network at test time. We evaluate\nour method on a 3D brain MRI dataset using both T1- and T2-weighted images. Our\nexperiments show that our method generates accurate predictions and that\nlearning the similarity measure leads to more consistent registrations than\nrelying on generic multimodal image similarity measures, such as mutual\ninformation. Our approach is an order of magnitude faster than\noptimization-based LDDMM."
        },
        {
            "reference_num": "[57]",
            "reference_title": "S. Miao, Z. J. Wang, and R. Liao, “A cnn regression approach for real-time 2d/3d registration,” IEEE transactions on medical imaging, vol. 35, no. 5, pp. 1352–1363, 2016.",
            "reference_abstract": "In this paper, we present a Convolutional Neural Network (CNN) regression\napproach for real-time 2-D/3-D registration. Different from optimization-based\nmethods, which iteratively optimize the transformation parameters over a\nscalar-valued metric function representing the quality of the registration, the\nproposed method exploits the information embedded in the appearances of the\nDigitally Reconstructed Radiograph and X-ray images, and employs CNN regressors\nto directly estimate the transformation parameters. The CNN regressors are\ntrained for local zones and applied in a hierarchical manner to break down the\ncomplex regression task into simpler sub-tasks that can be learned separately.\nOur experiment results demonstrate the advantage of the proposed method in\ncomputational efficiency with negligible degradation of registration accuracy\ncompared to intensity-based methods."
        },
        {
            "reference_num": "[58]",
            "reference_title": "D. Shen, G. Wu, and H.-I. Suk, “Deep learning in medical image analysis,” Annual review of biomedical engineering, vol. 19, pp. 221– 248, 2017.",
            "reference_abstract": "(This paper was submitted as an invited paper to IEEE Reviews in Biomedical\nEngineering on April 6, 2020.) The pandemic of coronavirus disease 2019\n(COVID-19) is spreading all over the world. Medical imaging such as X-ray and\ncomputed tomography (CT) plays an essential role in the global fight against\nCOVID-19, whereas the recently emerging artificial intelligence (AI)\ntechnologies further strengthen the power of the imaging tools and help medical\nspecialists. We hereby review the rapid responses in the community of medical\nimaging (empowered by AI) toward COVID-19. For example, AI-empowered image\nacquisition can significantly help automate the scanning procedure and also\nreshape the workflow with minimal contact to patients, providing the best\nprotection to the imaging technicians. Also, AI can improve work efficiency by\naccurate delination of infections in X-ray and CT images, facilitating\nsubsequent quantification. Moreover, the computer-aided platforms help\nradiologists make clinical decisions, i.e., for disease diagnosis, tracking,\nand prognosis. In this review paper, we thus cover the entire pipeline of\nmedical imaging and analysis techniques involved with COVID-19, including image\nacquisition, segmentation, diagnosis, and follow-up. We particularly focus on\nthe integration of AI with X-ray and CT, both of which are widely used in the\nfrontline hospitals, in order to depict the latest progress of medical imaging\nand radiology fighting against COVID-19."
        },
        {
            "reference_num": "[59]",
            "reference_title": "A. Qayyum, S. M. Anwar, M. Awais, and M. Majid, “Medical image retrieval using deep convolutional neural network,” Neurocomputing, vol. 266, pp. 8–20, 2017.",
            "reference_abstract": "With a widespread use of digital imaging data in hospitals, the size of\nmedical image repositories is increasing rapidly. This causes difficulty in\nmanaging and querying these large databases leading to the need of content\nbased medical image retrieval (CBMIR) systems. A major challenge in CBMIR\nsystems is the semantic gap that exists between the low level visual\ninformation captured by imaging devices and high level semantic information\nperceived by human. The efficacy of such systems is more crucial in terms of\nfeature representations that can characterize the high-level information\ncompletely. In this paper, we propose a framework of deep learning for CBMIR\nsystem by using deep Convolutional Neural Network (CNN) that is trained for\nclassification of medical images. An intermodal dataset that contains twenty\nfour classes and five modalities is used to train the network. The learned\nfeatures and the classification results are used to retrieve medical images.\nFor retrieval, best results are achieved when class based predictions are used.\nAn average classification accuracy of 99.77% and a mean average precision of\n0.69 is achieved for retrieval task. The proposed method is best suited to\nretrieve multimodal medical images for different body organs."
        },
        {
            "reference_num": "[60]",
            "reference_title": "J. Zech, M. Pain, J. Titano, M. Badgeley, J. Schefﬂein, A. Su, A. Costa, J. Bederson, J. Lehar, and E. K. Oermann, “Natural language–based machine learning models for the annotation of clinical radiology reports,” Radiology, vol. 287, no. 2, pp. 570–580, 2018.",
            "reference_abstract": "Early results in using convolutional neural networks (CNNs) on x-rays to\ndiagnose disease have been promising, but it has not yet been shown that models\ntrained on x-rays from one hospital or one group of hospitals will work equally\nwell at different hospitals. Before these tools are used for computer-aided\ndiagnosis in real-world clinical settings, we must verify their ability to\ngeneralize across a variety of hospital systems. A cross-sectional design was\nused to train and evaluate pneumonia screening CNNs on 158,323 chest x-rays\nfrom NIH (n=112,120 from 30,805 patients), Mount Sinai (42,396 from 12,904\npatients), and Indiana (n=3,807 from 3,683 patients). In 3 / 5 natural\ncomparisons, performance on chest x-rays from outside hospitals was\nsignificantly lower than on held-out x-rays from the original hospital systems.\nCNNs were able to detect where an x-ray was acquired (hospital system, hospital\ndepartment) with extremely high accuracy and calibrate predictions accordingly.\nThe performance of CNNs in diagnosing diseases on x-rays may reflect not only\ntheir ability to identify disease-specific imaging findings on x-rays, but also\ntheir ability to exploit confounding information. Estimates of CNN performance\nbased on test data from hospital systems used for model training may overstate\ntheir likely real-world performance."
        },
        {
            "reference_num": "[61]",
            "reference_title": "B. Jing, P. Xie, and E. Xing, “On the automatic generation of medical imaging reports,” 56th Annual Meeting of the Association for Computational Linguistics (ACL), 2018.",
            "reference_abstract": "We present a semantic parser for Abstract Meaning Representations which\nlearns to parse strings into tree representations of the compositional\nstructure of an AMR graph. This allows us to use standard neural techniques for\nsupertagging and dependency tree parsing, constrained by a linguistically\nprincipled type system. We present two approximative decoding algorithms, which\nachieve state-of-the-art accuracy and outperform strong baselines."
        },
        {
            "reference_num": "[62]",
            "reference_title": "X. Wang, Y. Peng, L. Lu, Z. Lu, and R. M. Summers, “Tienet: Textimage embedding network for common thorax disease classiﬁcation and reporting in chest x-rays,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 9049–9058.",
            "reference_abstract": "Chest X-rays are one of the most common radiological examinations in daily\nclinical routines. Reporting thorax diseases using chest X-rays is often an\nentry-level task for radiologist trainees. Yet, reading a chest X-ray image\nremains a challenging job for learning-oriented machine intelligence, due to\n(1) shortage of large-scale machine-learnable medical image datasets, and (2)\nlack of techniques that can mimic the high-level reasoning of human\nradiologists that requires years of knowledge accumulation and professional\ntraining. In this paper, we show the clinical free-text radiological reports\ncan be utilized as a priori knowledge for tackling these two key problems. We\npropose a novel Text-Image Embedding network (TieNet) for extracting the\ndistinctive image and text representations. Multi-level attention models are\nintegrated into an end-to-end trainable CNN-RNN architecture for highlighting\nthe meaningful text words and image regions. We first apply TieNet to classify\nthe chest X-rays by using both image features and text embeddings extracted\nfrom associated reports. The proposed auto-annotation framework achieves high\naccuracy (over 0.9 on average in AUCs) in assigning disease labels for our\nhand-label evaluation dataset. Furthermore, we transform the TieNet into a\nchest X-ray reporting system. It simulates the reporting process and can output\ndisease classification and a preliminary report together. The classification\nresults are significantly improved (6% increase on average in AUCs) compared to\nthe state-of-the-art baseline on an unseen and hand-labeled dataset (OpenI)."
        },
        {
            "reference_num": "[63]",
            "reference_title": "Y. Xue, T. Xu, L. R. Long, Z. Xue, S. Antani, G. R. Thoma, and X. Huang, “Multimodal recurrent model with attention for automated radiology report generation,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2018, pp. 457–466.",
            "reference_abstract": "Supervised training of an automated medical image analysis system often\nrequires a large amount of expert annotations that are hard to collect.\nMoreover, the proportions of data available across different classes may be\nhighly imbalanced for rare diseases. To mitigate these issues, we investigate a\nnovel data augmentation pipeline that selectively adds new synthetic images\ngenerated by conditional Adversarial Networks (cGANs), rather than extending\ndirectly the training set with synthetic images. The selection mechanisms that\nwe introduce to the synthetic augmentation pipeline are motivated by the\nobservation that, although cGAN-generated images can be visually appealing,\nthey are not guaranteed to contain essential features for classification\nperformance improvement. By selecting synthetic images based on the confidence\nof their assigned labels and their feature similarity to real labeled images,\nour framework provides quality assurance to synthetic augmentation by ensuring\nthat adding the selected synthetic images to the training set will improve\nperformance. We evaluate our model on a medical histopathology dataset, and two\nnatural image classification benchmarks, CIFAR10 and SVHN. Results on these\ndatasets show significant and consistent improvements in classification\nperformance (with 6.8%, 3.9%, 1.6% higher accuracy, respectively) by leveraging\ncGAN generated images with selective augmentation."
        },
        {
            "reference_num": "[64]",
            "reference_title": "V. Jindal, “Integrating mobile and cloud for ppg signal selection to monitor heart rate during intensive physical exercise,” in Proceedings of the International Conference on Mobile Software Engineering and Systems. ACM, 2016, pp. 36–37.",
            "reference_abstract": "Goal: A new method for heart rate monitoring using photoplethysmography (PPG)\nduring physical activities is proposed. Methods: It jointly estimates spectra\nof PPG signals and simultaneous acceleration signals, utilizing the multiple\nmeasurement vector model in sparse signal recovery. Due to a common sparsity\nconstraint on spectral coefficients, the method can easily identify and remove\nspectral peaks of motion artifact (MA) in PPG spectra. Thus, it does not need\nany extra signal processing modular to remove MA as in some other algorithms.\nFurthermore, seeking spectral peaks associated with heart rate is simplified.\nResults: Experimental results on 12 PPG datasets sampled at 25 Hz and recorded\nduring subjects' fast running showed that it had high performance. The average\nabsolute estimation error was 1.28 beat per minute and the standard deviation\nwas 2.61 beat per minute. Conclusion and Significance: These results show that\nthe method has great potential to be used for PPG-based heart rate monitoring\nin wearable devices for fitness tracking and health monitoring."
        },
        {
            "reference_num": "[65]",
            "reference_title": "F. Attal, S. Mohammed, M. Dedabrishvili, F. Chamroukhi, L. Oukhellou, and Y. Amirat, “Physical human activity recognition using wearable sensors,” Sensors, vol. 15, no. 12, pp. 31 314–31 338, 2015.",
            "reference_abstract": "Using supervised machine learning approaches to recognize human activities\nfrom on-body wearable accelerometers generally requires a large amount of\nlabelled data. When ground truth information is not available, too expensive,\ntime consuming or difficult to collect, one has to rely on unsupervised\napproaches. This paper presents a new unsupervised approach for human activity\nrecognition from raw acceleration data measured using inertial wearable\nsensors. The proposed method is based upon joint segmentation of\nmultidimensional time series using a Hidden Markov Model (HMM) in a multiple\nregression context. The model is learned in an unsupervised framework using the\nExpectation-Maximization (EM) algorithm where no activity labels are needed.\nThe proposed method takes into account the sequential appearance of the data.\nIt is therefore adapted for the temporal acceleration data to accurately detect\nthe activities. It allows both segmentation and classification of the human\nactivities. Experimental results are provided to demonstrate the efficiency of\nthe proposed approach with respect to standard supervised and unsupervised\nclassification approaches"
        },
        {
            "reference_num": "[66]",
            "reference_title": "S. F. Weng, J. Reps, J. Kai, J. M. Garibaldi, and N. Qureshi, “Can machine-learning improve cardiovascular risk prediction using routine clinical data?” PloS one, vol. 12, no. 4, p. e0174944, 2017.",
            "reference_abstract": "We have measured the beam-normal single-spin asymmetry $A_n$ in the elastic\nscattering of 1-3 GeV transversely polarized electrons from $^1$H and for the\nfirst time from $^4$He, $^{12}$C, and $^{208}$Pb. For $^1$H, $^4$He and\n$^{12}$C, the measurements are in agreement with calculations that relate $A_n$\nto the imaginary part of the two-photon exchange amplitude including inelastic\nintermediate states. Surprisingly, the $^{208}$Pb result is significantly\nsmaller than the corresponding prediction using the same formalism. These\nresults suggest that a systematic set of new $A_n$ measurements might emerge as\na new and sensitive probe of the structure of heavy nuclei."
        },
        {
            "reference_num": "[67]",
            "reference_title": "M. Fatima and M. Pasha, “Survey of machine learning algorithms for disease diagnostic,” Journal of Intelligent Learning Systems and Applications, vol. 9, no. 01, p. 1, 2017.",
            "reference_abstract": "Lifelong learning - an agent's ability to learn throughout its lifetime - is\na hallmark of biological learning systems and a central challenge for\nartificial intelligence (AI). The development of lifelong learning algorithms\ncould lead to a range of novel AI applications, but this will also require the\ndevelopment of appropriate hardware accelerators, particularly if the models\nare to be deployed on edge platforms, which have strict size, weight, and power\nconstraints. Here, we explore the design of lifelong learning AI accelerators\nthat are intended for deployment in untethered environments. We identify key\ndesirable capabilities for lifelong learning accelerators and highlight metrics\nto evaluate such accelerators. We then discuss current edge AI accelerators and\nexplore the future design of lifelong learning accelerators, considering the\nrole that different emerging technologies could play."
        },
        {
            "reference_num": "[68]",
            "reference_title": "J. A. Cruz and D. S. Wishart, “Applications of machine learning in cancer prediction and prognosis,” Cancer informatics, vol. 2, p. 117693510600200030, 2006.",
            "reference_abstract": "High accuracy in cancer prediction is important to improve the quality of the\ntreatment and to improve the rate of survivability of patients. As the data\nvolume is increasing rapidly in the healthcare research, the analytical\nchallenge exists in double. The use of effective sampling technique in\nclassification algorithms always yields good prediction accuracy. The SEER\npublic use cancer database provides various prominent class labels for\nprognosis prediction. The main objective of this paper is to find the effect of\nsampling techniques in classifying the prognosis variable and propose an ideal\nsampling method based on the outcome of the experimentation. In the first phase\nof this work the traditional random sampling and stratified sampling techniques\nhave been used. At the next level the balanced stratified sampling with\nvariations as per the choice of the prognosis class labels have been tested.\nMuch of the initial time has been focused on performing the pre_processing of\nthe SEER data set. The classification model for experimentation has been built\nusing the breast cancer, respiratory cancer and mixed cancer data sets with\nthree traditional classifiers namely Decision Tree, Naive Bayes and K-Nearest\nNeighbor. The three prognosis factors survival, stage and metastasis have been\nused as class labels for experimental comparisons. The results shows a steady\nincrease in the prediction accuracy of balanced stratified model as the sample\nsize increases, but the traditional approach fluctuates before the optimum\nresults."
        },
        {
            "reference_num": "[69]",
            "reference_title": "H.-Y. Ma, Z. Zhou, S. Wu, Y.-L. Wan, and P.-H. Tsui, “A computeraided diagnosis scheme for detection of fatty liver in vivo based on ultrasound kurtosis imaging,” Journal of medical systems, vol. 40, no. 1, p. 33, 2016.",
            "reference_abstract": "With the success of deep learning-based methods applied in medical image\nanalysis, convolutional neural networks (CNNs) have been investigated for\nclassifying liver disease from ultrasound (US) data. However, the scarcity of\navailable large-scale labeled US data has hindered the success of CNNs for\nclassifying liver disease from US data. In this work, we propose a novel\ngenerative adversarial network (GAN) architecture for realistic diseased and\nhealthy liver US image synthesis. We adopt the concept of stacking to\nsynthesize realistic liver US data. Quantitative and qualitative evaluation is\nperformed on 550 in-vivo B-mode liver US images collected from 55 subjects. We\nalso show that the synthesized images, together with real in vivo data, can be\nused to significantly improve the performance of traditional CNN architectures\nfor Nonalcoholic fatty liver disease (NAFLD) classification."
        },
        {
            "reference_num": "[70]",
            "reference_title": "Z. Zhang et al., “Reinforcement learning in clinical medicine: a method to optimize dynamic treatment regime over time,” Annals of translational medicine, vol. 7, no. 14, 2019.",
            "reference_abstract": "Time-course high-throughput gene expression data are emerging in genomic and\ntranslational medicine. Extracting interesting time-course patterns from a\npatient cohort can provide biological insights for further clinical research\nand patient treatment. We propose principal trend analysis (PTA) to extract\nprincipal trends of time-course gene expression data from a group of patients,\nand identify genes that make dominant contributions to the principal trends.\nThrough simulations, we demonstrate the utility of PTA for dimension reduction,\ntime-course signal recovery and feature selection with high-dimensional data.\nMoreover, PTA derives new insights in real biological and clinical research. We\ndemonstrate the usefulness of PTA by applying it to longitudinal gene\nexpression data of a circadian regulation system and burn patients. These\napplications show that PTA can extract interesting time-course trends with\nbiological significance, which helps the understanding of biological mechanisms\nof circadian regulation systems as well as the recovery of burn patients.\nOverall, the proposed PTA approach will benefit the genomic medicine research.\nOur method is implemented into an R-package: PTA (Principal Trend Analysis)."
        },
        {
            "reference_num": "[71]",
            "reference_title": "A. Raghu, “Reinforcement learning for sepsis treatment: Baselines and analysis,” 2019.",
            "reference_abstract": "Sepsis is a dangerous condition that is a leading cause of patient mortality.\nTreating sepsis is highly challenging, because individual patients respond very\ndifferently to medical interventions and there is no universally agreed-upon\ntreatment for sepsis. In this work, we explore the use of continuous\nstate-space model-based reinforcement learning (RL) to discover high-quality\ntreatment policies for sepsis patients. Our quantitative evaluation reveals\nthat by blending the treatment strategy discovered with RL with what clinicians\nfollow, we can obtain improved policies, potentially allowing for better\nmedical treatment for sepsis."
        },
        {
            "reference_num": "[72]",
            "reference_title": "H. Suresh, “Clinical event prediction and understanding with deep neural networks,” Ph.D. dissertation, Massachusetts Institute of Technology, 2017.",
            "reference_abstract": "Limited-angle X-ray tomography reconstruction is an ill-conditioned inverse\nproblem in general. Especially when the projection angles are limited and the\nmeasurements are taken in a photon-limited condition, reconstructions from\nclassical algorithms such as filtered backprojection may lose fidelity and\nacquire artifacts due to the missing-cone problem. To obtain satisfactory\nreconstruction results, prior assumptions, such as total variation minimization\nand nonlocal image similarity, are usually incorporated within the\nreconstruction algorithm. In this work, we introduce deep neural networks to\ndetermine and apply a prior distribution in the reconstruction process. Our\nneural networks learn the prior directly from synthetic training samples. The\nneural nets thus obtain a prior distribution that is specific to the class of\nobjects we are interested in reconstructing. In particular, we used deep\ngenerative models with 3D convolutional layers and 3D attention layers which\nare trained on 3D synthetic integrated circuit (IC) data from a model dubbed\nCircuitFaker. We demonstrate that, when the projection angles and photon\nbudgets are limited, the priors from our deep generative models can\ndramatically improve the IC reconstruction quality on synthetic data compared\nwith maximum likelihood estimation. Training the deep generative models with\nsynthetic IC data from CircuitFaker illustrates the capabilities of the learned\nprior from machine learning. We expect that if the process were reproduced with\nexperimental data, the advantage of the machine learning would persist. The\nadvantages of machine learning in limited angle X-ray tomography may further\nenable applications in low-photon nanoscale imaging."
        },
        {
            "reference_num": "[73]",
            "reference_title": "C.-S. Rau, P.-J. Kuo, P.-C. Chien, C.-Y. Huang, H.-Y. Hsieh, and C.H. Hsieh, “Mortality prediction in patients with isolated moderate and severe traumatic brain injury using machine learning models,” PloS one, vol. 13, no. 11, p. e0207192, 2018.",
            "reference_abstract": "This report describes technical adaptations of a traumatic brain injury (TBI)\nmodel-largely inspired by Marmarou-in order to monitor microdialysis data and\nPtiO2 (brain tissue oxygen) before, during and after injury. We particularly\nfocalize on our model requirements which allows us to re-create some drastic\npathological characteristics experienced by severely head-injured patients:\nimpact on a closed skull, no ventilation immediately after impact, presence of\ndiffuse axonal injuries and secondary brain insults from systemic origin...We\nnotably give priority to minimize anaesthesia duration in order to tend to\nbanish any neuroprotection. Our new model will henceforth allow a better\nunderstanding of neurochemical and biochemical alterations resulting from\ntraumatic brain injury, using microdialysis and PtiO2 techniques already\nmonitored in our Intensive Care Unit. Studies on efficiency and therapeutic\nwindow of neuroprotective pharmacological molecules are now conceivable to\nameliorate severe head-injury treatment."
        },
        {
            "reference_num": "[74]",
            "reference_title": "H. Song, D. Rajan, J. J. Thiagarajan, and A. Spanias, “Attend and diagnose: Clinical time series analysis using attention models,” in Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.",
            "reference_abstract": "With widespread adoption of electronic health records, there is an increased\nemphasis for predictive models that can effectively deal with clinical\ntime-series data. Powered by Recurrent Neural Network (RNN) architectures with\nLong Short-Term Memory (LSTM) units, deep neural networks have achieved\nstate-of-the-art results in several clinical prediction tasks. Despite the\nsuccess of RNNs, its sequential nature prohibits parallelized computing, thus\nmaking it inefficient particularly when processing long sequences. Recently,\narchitectures which are based solely on attention mechanisms have shown\nremarkable success in transduction tasks in NLP, while being computationally\nsuperior. In this paper, for the first time, we utilize attention models for\nclinical time-series modeling, thereby dispensing recurrence entirely. We\ndevelop the \\textit{SAnD} (Simply Attend and Diagnose) architecture, which\nemploys a masked, self-attention mechanism, and uses positional encoding and\ndense interpolation strategies for incorporating temporal order. Furthermore,\nwe develop a multi-task variant of \\textit{SAnD} to jointly infer models with\nmultiple diagnosis tasks. Using the recent MIMIC-III benchmark datasets, we\ndemonstrate that the proposed approach achieves state-of-the-art performance in\nall tasks, outperforming LSTM models and classical baselines with\nhand-engineered features."
        },
        {
            "reference_num": "[75]",
            "reference_title": "O. Ren, A. E. Johnson, E. P. Lehman, M. Komorowski, J. Aboab, F. Tang, Z. Shahn, D. Sow, R. Mark, and L.-w. Lehman, “Predicting and understanding unexpected respiratory decompensation in critical care using sparse and heterogeneous clinical data,” in 2018 IEEE International Conference on Healthcare Informatics (ICHI). IEEE, 2018, pp. 144–151.",
            "reference_abstract": "Reliance on scanned documents and fax communication for healthcare referrals\nleads to high administrative costs and errors that may affect patient care. In\nthis work we propose a hybrid model leveraging LayoutLMv3 along with\ndomain-specific rules to identify key patient, physician, and exam-related\nentities in faxed referral documents. We explore some of the challenges in\napplying a document understanding model to referrals, which have formats\nvarying by medical practice, and evaluate model performance using MUC-5 metrics\nto obtain appropriate metrics for the practical use case. Our analysis shows\nthe addition of domain-specific rules to the transformer model yields greatly\nincreased precision and F1 scores, suggesting a hybrid model trained on a\ncurated dataset can increase efficiency in referral management."
        },
        {
            "reference_num": "[76]",
            "reference_title": "A. K. Jha, “The promise of electronic records: around the corner or down the road?” Jama, vol. 306, no. 8, pp. 880–881, 2011.",
            "reference_abstract": "We discuss an opportunity to achieve amplification without inversion in\nthree-level cascade scheme using an effective unidirectional pumping via\nbidirectional incoherent pump. Analytical solution to the population and the\ncoherence are obtained in the steady-state regime. With a proper choice of the\nparameters, obtained here, the possibility for amplification without inversion\nis presented."
        },
        {
            "reference_num": "[77]",
            "reference_title": "A. N´ev´eol, H. Dalianis, S. Velupillai, G. Savova, and P. Zweigenbaum, “Clinical natural language processing in languages other than english: opportunities and challenges,” Journal of biomedical semantics, vol. 9, no. 1, p. 12, 2018.",
            "reference_abstract": "In this paper we present a fundamental lexical semantics of Sinhala language\nand a Hidden Markov Model (HMM) based Part of Speech (POS) Tagger for Sinhala\nlanguage. In any Natural Language processing task, Part of Speech is a very\nvital topic, which involves analysing of the construction, behaviour and the\ndynamics of the language, which the knowledge could utilized in computational\nlinguistics analysis and automation applications. Though Sinhala is a\nmorphologically rich and agglutinative language, in which words are inflected\nwith various grammatical features, tagging is very essential for further\nanalysis of the language. Our research is based on statistical based approach,\nin which the tagging process is done by computing the tag sequence probability\nand the word-likelihood probability from the given corpus, where the linguistic\nknowledge is automatically extracted from the annotated corpus. The current\ntagger could reach more than 90% of accuracy for known words."
        },
        {
            "reference_num": "[78]",
            "reference_title": "E. Soysal, J. Wang, M. Jiang, Y. Wu, S. Pakhomov, H. Liu, and H. Xu, “Clamp–a toolkit for efﬁciently building customized clinical natural  20  language processing pipelines,” Journal of the American Medical Informatics Association, vol. 25, no. 3, pp. 331–336, 2017.",
            "reference_abstract": "The COVID-19 pandemic swept across the world rapidly, infecting millions of\npeople. An efficient tool that can accurately recognize important clinical\nconcepts of COVID-19 from free text in electronic health records (EHRs) will be\nvaluable to accelerate COVID-19 clinical research. To this end, this study aims\nat adapting the existing CLAMP natural language processing tool to quickly\nbuild COVID-19 SignSym, which can extract COVID-19 signs/symptoms and their 8\nattributes (body location, severity, temporal expression, subject, condition,\nuncertainty, negation, and course) from clinical text. The extracted\ninformation is also mapped to standard concepts in the Observational Medical\nOutcomes Partnership common data model. A hybrid approach of combining deep\nlearning-based models, curated lexicons, and pattern-based rules was applied to\nquickly build the COVID-19 SignSym from CLAMP, with optimized performance. Our\nextensive evaluation using 3 external sites with clinical notes of COVID-19\npatients, as well as the online medical dialogues of COVID-19, shows COVID-19\nSign-Sym can achieve high performance across data sources. The workflow used\nfor this study can be generalized to other use cases, where existing clinical\nnatural language processing tools need to be customized for specific\ninformation needs within a short time. COVID-19 SignSym is freely accessible to\nthe research community as a downloadable package\n(https://clamp.uth.edu/covid/nlp.php) and has been used by 16 healthcare\norganizations to support clinical research of COVID-19."
        },
        {
            "reference_num": "[80]",
            "reference_title": "M. Ghassemi, J. H. Van Stan, D. D. Mehta, M. Za˜nartu, H. A. Cheyne II, R. E. Hillman, and J. V. Guttag, “Learning to detect vocal hyperfunction from ambulatory neck-surface acceleration features: Initial results for vocal fold nodules,” IEEE Transactions on Biomedical Engineering, vol. 61, no. 6, pp. 1668–1675, 2014.",
            "reference_abstract": "Voice disorders affect an estimated 14 million working-aged Americans, and\nmany more worldwide. We present the first large scale study of vocal misuse\nbased on long-term ambulatory data collected by an accelerometer placed on the\nneck. We investigate an unsupervised data mining approach to uncovering latent\ninformation about voice misuse.\n  We segment signals from over 253 days of data from 22 subjects into over a\nhundred million single glottal pulses (closures of the vocal folds), cluster\nsegments into symbols, and use symbolic mismatch to uncover differences between\npatients and matched controls, and between patients pre- and post-treatment.\nOur results show significant behavioral differences between patients and\ncontrols, as well as between some pre- and post-treatment patients. Our\nproposed approach provides an objective basis for helping diagnose behavioral\nvoice disorders, and is a first step towards a more data-driven understanding\nof the impact of voice therapy."
        },
        {
            "reference_num": "[81]",
            "reference_title": "C. Pou-Prom and F. Rudzicz, “Learning multiview embeddings for assessing dementia,” in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018, pp. 2812–2817.",
            "reference_abstract": "Data sets for identifying Alzheimer's disease (AD) are often relatively\nsparse, which limits their ability to train generalizable models. Here, we\naugment such a data set, DementiaBank, with each of two normative data sets,\nthe Wisconsin Longitudinal Study and Talk2Me, each of which employs a\nspeech-based picture-description assessment. Through minority class\noversampling with ADASYN, we outperform state-of-the-art results in binary\nclassification of people with and without AD in DementiaBank. This work\nhighlights the effectiveness of combining sparse and difficult-to-acquire\npatient data with relatively large and easily accessible normative datasets."
        },
        {
            "reference_num": "[82]",
            "reference_title": "K. C. Fraser, J. A. Meltzer, and F. Rudzicz, “Linguistic features identify alzheimers disease in narrative speech,” Journal of Alzheimer’s Disease, vol. 49, no. 2, pp. 407–422, 2016.",
            "reference_abstract": "Alzheimer's disease is the most common form of dementia in the western world,\nhowever there is no cure available for this devastating neurodegenerative\ndisorder. Despite clinical and experimental evidence implicating the intestinal\nmicrobiota in a number of brain disorders, its impact on Alzheimer's disease is\nnot known. We generated a germ-free mouse model of Alzheimer's disease and\ndiscovered a drastic reduction of cerebral Ab amyloid pathology when compared\nto control Alzheimer's disease animals with intestinal microbiota. Sequencing\nbacterial 16S rRNA from fecal samples revealed a remarkable shift in the gut\nmicrobiota of conventionally-raised Alzheimer's disease mice as compared to\nhealthy, wild-type mice. Colonization of germ-free Alzheimer mice with\nharvested microbiota from conventionally-raised Alzheimer mice dramatically\nincreased cerebral Ab pathology. In contrast, colonization with microbiota from\ncontrol wild-type mice was ineffective in increasing cerebral Ab levels. Our\nresults indicate a microbial involvement in the development of Alzheimer's\ndisease pathology, and suggest that microbiota may contribute to the\ndevelopment of neurodegenerative diseases."
        },
        {
            "reference_num": "[83]",
            "reference_title": "J. B. Andre, B. W. Bresnahan, M. Mossa-Basha, M. N. Hoff, C. P. Smith, Y. Anzai, and W. A. Cohen, “Toward quantifying the prevalence, severity, and cost associated with patient motion during clinical mr examinations,” Journal of the American College of Radiology, vol. 12, no. 7, pp. 689–695, 2015.",
            "reference_abstract": "LUX-ZEPLIN (LZ) is a second-generation direct dark matter experiment with\nspin-independent WIMP-nucleon scattering sensitivity above $1.4 \\times\n10^{-48}$ cm$^{2}$ for a WIMP mass of 40 GeV/c$^{2}$ and a 1000 d exposure. LZ\nachieves this sensitivity through a combination of a large 5.6 t fiducial\nvolume, active inner and outer veto systems, and radio-pure construction using\nmaterials with inherently low radioactivity content. The LZ collaboration\nperformed an extensive radioassay campaign over a period of six years to inform\nmaterial selection for construction and provide an input to the experimental\nbackground model against which any possible signal excess may be evaluated. The\ncampaign and its results are described in this paper. We present assays of dust\nand radon daughters depositing on the surface of components as well as\ncleanliness controls necessary to maintain background expectations through\ndetector construction and assembly. Finally, examples from the campaign to\nhighlight fixed contaminant radioassays for the LZ photomultiplier tubes,\nquality control and quality assurance procedures through fabrication, radon\nemanation measurements of major sub-systems, and bespoke detector systems to\nassay scintillator are presented."
        },
        {
            "reference_num": "[84]",
            "reference_title": "A. K. Manrai, G. Bhatia, J. Strymish, I. S. Kohane, and S. H. Jain, “Medicines uncomfortable relationship with math: calculating positive predictive value,” JAMA internal medicine, vol. 174, no. 6, pp. 991– 993, 2014.",
            "reference_abstract": "The norm of the $m$th derivative of the map that takes an operator to its\n$k$th antisymmetric tensor power is evaluated. The case $m=1$ has been studied\nearlier by Bhatia and Friedland [R. Bhatia and S. Friedland, Variation of\nGrassman powers and spectra, Linear Algebra and its Applications, 40:1--18,\n1981]. For this purpose a multilinear version of a theorem of Russo and Dye is\nproved: it is shown that a positive $m$-linear map between $C^{\\ast}$-algebras\nattains its norm at the $m$-tuple $(I, \\, I, ..., I).$ Expressions for\nderivatives of the maps that take an operator to its $k$th tensor power and\n$k$th symmetric tensor power are also obtained. The norms of these derivatives\nare computed. Derivatives of the map taking a matrix to its permanent are also\nevaluated."
        },
        {
            "reference_num": "[85]",
            "reference_title": "R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, and N. Elhadad, “Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission,” in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015, pp. 1721–1730.",
            "reference_abstract": "As one of the leading platforms for creative content, Tumblr offers\nadvertisers a unique way of creating brand identity. Advertisers can tell their\nstory through images, animation, text, music, video, and more, and promote that\ncontent by sponsoring it to appear as an advertisement in the streams of Tumblr\nusers. In this paper we present a framework that enabled one of the key\ntargeted advertising components for Tumblr, specifically gender and interest\ntargeting. We describe the main challenges involved in development of the\nframework, which include creating the ground truth for training gender\nprediction models, as well as mapping Tumblr content to an interest taxonomy.\nFor purposes of inferring user interests we propose a novel semi-supervised\nneural language model for categorization of Tumblr content (i.e., post tags and\npost keywords). The model was trained on a large-scale data set consisting of\n6.8 billion user posts, with very limited amount of categorized keywords, and\nwas shown to have superior performance over the bag-of-words model. We\nsuccessfully deployed gender and interest targeting capability in Yahoo\nproduction systems, delivering inference for users that cover more than 90% of\ndaily activities at Tumblr. Online performance results indicate advantages of\nthe proposed approach, where we observed 20% lift in user engagement with\nsponsored posts as compared to untargeted campaigns."
        },
        {
            "reference_num": "[86]",
            "reference_title": "X. A. Li, A. Tai, D. W. Arthur, T. A. Buchholz, S. Macdonald, L. B. Marks, J. M. Moran, L. J. Pierce, R. Rabinovitch, A. Taghian et al., “Variability of target and normal structure delineation for breast cancer radiotherapy: an rtog multi-institutional and multiobserver study,” International Journal of Radiation Oncology* Biology* Physics, vol. 73, no. 3, pp. 944–951, 2009.",
            "reference_abstract": "Purpose: To determine whether alternative HDR prostate brachytherapy catheter\npatterns can result in improved dose distributions while providing better\naccess and reducing trauma.\n  Methods: Prostate HDR brachytherapy uses a grid of parallel needle positions\nto guide the catheter insertion. This geometry does not easily allow the\nphysician to avoid piercing the critical structures near the penile bulb nor\ndoes it provide position flexibility in the case of pubic arch interference. On\nCT data from ten previously-treated patients new catheters were digitized\nfollowing three catheter patterns: conical, bi-conical, and fireworks. The\nconical patterns were used to accommodate a robotic delivery using a single\nentry point. The bi-conical and fireworks patterns were specifically designed\nto avoid the critical structures near the penile bulb. For each catheter\ndistribution, a plan was optimized with the inverse planning algorithm, IPSA,\nand compared with the plan used for treatment. Irrelevant of catheter geometry,\na plan must fulfill the RTOG-0321 dose criteria for target dose coverage.\n  Results: Thirty plans from ten patients were optimized. All non-standard\npatterns fulfilled the RTOG criteria when the clinical plan did. In some cases,\nthe dose distribution was improved by better sparing the organs-at-risk.\n  Conclusion: Alternative catheter patterns can provide the physician with\nadditional ways to treat patients previously considered unsuited for\nbrachytherapy treatment (pubic arch interference) and facilitate robotic\nguidance of catheter insertion. In addition, alternative catheter patterns may\ndecrease toxicity by avoidance of the critical structures near the penile bulb\nwhile still fulfilling the RTOG criteria."
        },
        {
            "reference_num": "[87]",
            "reference_title": "F. Xia and M. Yetisgen-Yildiz, “Clinical corpus annotation: challenges and strategies,” in Proceedings of the Third Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM’2012) in conjunction with the International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey, 2012.",
            "reference_abstract": "Turkic languages exhibit extensive and diverse etymological relationships\namong lexical items. These relationships make the Turkic languages promising\nfor exploring automated translation lexicon induction by leveraging cognate and\nother etymological information. However, due to the extent and diversity of the\ntypes of relationships between words, it is not clear how to annotate such\ninformation. In this paper, we present a methodology for annotating cognates\nand etymological origin in Turkic languages. Our method strives to balance the\namount of research effort the annotator expends with the utility of the\nannotations for supporting research on improving automated translation lexicon\ninduction."
        },
        {
            "reference_num": "[88]",
            "reference_title": "B. Biggio, B. Nelson, and P. Laskov, “Poisoning attacks against support vector machines,” in 29th International Conference on Machine Learning, 2012, pp. 1807–1814.",
            "reference_abstract": "We investigate a family of poisoning attacks against Support Vector Machines\n(SVM). Such attacks inject specially crafted training data that increases the\nSVM's test error. Central to the motivation for these attacks is the fact that\nmost learning algorithms assume that their training data comes from a natural\nor well-behaved distribution. However, this assumption does not generally hold\nin security-sensitive settings. As we demonstrate, an intelligent adversary\ncan, to some extent, predict the change of the SVM's decision function due to\nmalicious input and use this ability to construct malicious data. The proposed\nattack uses a gradient ascent strategy in which the gradient is computed based\non properties of the SVM's optimal solution. This method can be kernelized and\nenables the attack to be constructed in the input space even for non-linear\nkernels. We experimentally demonstrate that our gradient ascent procedure\nreliably identifies good local maxima of the non-convex validation error\nsurface, which significantly increases the classifier's test error."
        },
        {
            "reference_num": "[89]",
            "reference_title": "S. Alfeld, X. Zhu, and P. Barford, “Data poisoning attacks against autoregressive models,” in Thirtieth AAAI Conference on Artiﬁcial Intelligence, 2016.",
            "reference_abstract": "Poisoning attacks can disproportionately influence model behaviour by making\nsmall changes to the training corpus. While defences against specific poisoning\nattacks do exist, they in general do not provide any guarantees, leaving them\npotentially countered by novel attacks. In contrast, by examining worst-case\nbehaviours Certified Defences make it possible to provide guarantees of the\nrobustness of a sample against adversarial attacks modifying a finite number of\ntraining samples, known as pointwise certification. We achieve this by\nexploiting both Differential Privacy and the Sampled Gaussian Mechanism to\nensure the invariance of prediction for each testing instance against finite\nnumbers of poisoned examples. In doing so, our model provides guarantees of\nadversarial robustness that are more than twice as large as those provided by\nprior certifications."
        },
        {
            "reference_num": "[90]",
            "reference_title": "N. Papernot, P. McDaniel, A. Sinha, and M. Wellman, “Towards the science of security and privacy in machine learning,” arXiv preprint arXiv:1611.03814, 2016.",
            "reference_abstract": "Advances in machine learning (ML) in recent years have enabled a dizzying\narray of applications such as data analytics, autonomous systems, and security\ndiagnostics. ML is now pervasive---new systems and models are being deployed in\nevery domain imaginable, leading to rapid and widespread deployment of software\nbased inference and decision making. There is growing recognition that ML\nexposes new vulnerabilities in software systems, yet the technical community's\nunderstanding of the nature and extent of these vulnerabilities remains\nlimited. We systematize recent findings on ML security and privacy, focusing on\nattacks identified on these systems and defenses crafted to date. We articulate\na comprehensive threat model for ML, and categorize attacks and defenses within\nan adversarial framework. Key insights resulting from works both in the ML and\nsecurity communities are identified and the effectiveness of approaches are\nrelated to structural elements of ML algorithms and the data used to train\nthem. We conclude by formally exploring the opposing relationship between model\naccuracy and resilience to adversarial manipulation. Through these\nexplorations, we show that there are (possibly unavoidable) tensions between\nmodel complexity, accuracy, and resilience that must be calibrated for the\nenvironments in which they will be used."
        },
        {
            "reference_num": "[91]",
            "reference_title": "T. J. Pollard, I. Chen, J. Wiens, S. Horng, D. Wong, M. Ghassemi, H. Mattie, E. Lindmeer, and T. Panch, “Turning the crank for machine learning: ease, at what expense?” The Lancet Digital Health, vol. 1, no. 5, pp. e198–e199, 2019.",
            "reference_abstract": "With the onset of COVID-19 pandemic, social media has rapidly become a\ncrucial communication tool for information generation, dissemination, and\nconsumption. In this scoping review, we selected and examined peer-reviewed\nempirical studies relating to COVID-19 and social media during the first\noutbreak starting in November 2019 until May 2020. From an analysis of 81\nstudies, we identified five overarching public health themes concerning the\nrole of online social platforms and COVID-19. These themes focused on: (i)\nsurveying public attitudes, (ii) identifying infodemics, (iii) assessing mental\nhealth, (iv) detecting or predicting COVID-19 cases, (v) analyzing government\nresponses to the pandemic, and (vi) evaluating quality of health information in\nprevention education videos. Furthermore, our review highlights the paucity of\nstudies on the application of machine learning on social media data related to\nCOVID-19 and a lack of studies documenting real-time surveillance developed\nwith social media data on COVID-19. For COVID-19, social media can play a\ncrucial role in disseminating health information as well as tackling infodemics\nand misinformation."
        },
        {
            "reference_num": "[92]",
            "reference_title": "M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that exploit conﬁdence information and basic countermeasures,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, 2015, pp. 1322–1333.",
            "reference_abstract": "Cryptographic algorithm agility is an important property for DNSSEC: it\nallows easy deployment of new algorithms if the existing ones are no longer\nsecure. In this work we show that the cryptographic agility in DNSSEC, although\ncritical for provisioning DNS with strong cryptography, also introduces a\nvulnerability. We find that under certain conditions, when new algorithms are\nlisted in signed DNS responses, the resolvers do not validate DNSSEC. As a\nresult, domains that deploy new ciphers may in fact cause the resolvers not to\nvalidate DNSSEC. We exploit this to develop DNSSEC-downgrade attacks and\nexperimentally and ethically evaluate them against popular DNS resolver\nimplementations, public DNS providers, and DNS services used by web clients\nworldwide. We find that major DNS providers as well as 45% of DNS resolvers\nused by web clients are vulnerable to our attacks."
        },
        {
            "reference_num": "[93]",
            "reference_title": "I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” arXiv preprint arXiv:1412.6572, 2014.",
            "reference_abstract": "Several machine learning models, including neural networks, consistently\nmisclassify adversarial examples---inputs formed by applying small but\nintentionally worst-case perturbations to examples from the dataset, such that\nthe perturbed input results in the model outputting an incorrect answer with\nhigh confidence. Early attempts at explaining this phenomenon focused on\nnonlinearity and overfitting. We argue instead that the primary cause of neural\nnetworks' vulnerability to adversarial perturbation is their linear nature.\nThis explanation is supported by new quantitative results while giving the\nfirst explanation of the most intriguing fact about them: their generalization\nacross architectures and training sets. Moreover, this view yields a simple and\nfast method of generating adversarial examples. Using this approach to provide\nexamples for adversarial training, we reduce the test set error of a maxout\nnetwork on the MNIST dataset."
        },
        {
            "reference_num": "[95]",
            "reference_title": "N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami, “Practical black-box attacks against machine learning,” in Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, 2017, pp. 506–519.",
            "reference_abstract": "Machine learning (ML) models, e.g., deep neural networks (DNNs), are\nvulnerable to adversarial examples: malicious inputs modified to yield\nerroneous model outputs, while appearing unmodified to human observers.\nPotential attacks include having malicious content like malware identified as\nlegitimate or controlling vehicle behavior. Yet, all existing adversarial\nexample attacks require knowledge of either the model internals or its training\ndata. We introduce the first practical demonstration of an attacker controlling\na remotely hosted DNN with no such knowledge. Indeed, the only capability of\nour black-box adversary is to observe labels given by the DNN to chosen inputs.\nOur attack strategy consists in training a local model to substitute for the\ntarget DNN, using inputs synthetically generated by an adversary and labeled by\nthe target DNN. We use the local substitute to craft adversarial examples, and\nfind that they are misclassified by the targeted DNN. To perform a real-world\nand properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online\ndeep learning API. We find that their DNN misclassifies 84.24% of the\nadversarial examples crafted with our substitute. We demonstrate the general\napplicability of our strategy to many ML techniques by conducting the same\nattack against models hosted by Amazon and Google, using logistic regression\nsubstitutes. They yield adversarial examples misclassified by Amazon and Google\nat rates of 96.19% and 88.94%. We also find that this black-box attack strategy\nis capable of evading defense strategies previously found to make adversarial\nexample crafting harder."
        },
        {
            "reference_num": "[96]",
            "reference_title": "M. Usama, J. Qadir, A. Al-Fuqaha, and M. Hamdi, “The adversarial machine learning conundrum: Can the insecurity of ml become the achilles’ heel of cognitive networks?” arXiv preprint arXiv:1906.00679, 2019.",
            "reference_abstract": "The holy grail of networking is to create \\textit{cognitive networks} that\norganize, manage, and drive themselves. Such a vision now seems attainable\nthanks in large part to the progress in the field of machine learning (ML),\nwhich has now already disrupted a number of industries and revolutionized\npractically all fields of research. But are the ML models foolproof and robust\nto security attacks to be in charge of managing the network? Unfortunately,\nmany modern ML models are easily misled by simple and easily-crafted\nadversarial perturbations, which does not bode well for the future of ML-based\ncognitive networks unless ML vulnerabilities for the cognitive networking\nenvironment are identified, addressed, and fixed. The purpose of this article\nis to highlight the problem of insecure ML and to sensitize the readers to the\ndanger of adversarial ML by showing how an easily-crafted adversarial ML\nexample can compromise the operations of the cognitive self-driving network. In\nthis paper, we demonstrate adversarial attacks on two simple yet representative\ncognitive networking applications (namely, intrusion detection and network\ntraffic classification). We also provide some guidelines to design secure ML\nmodels for cognitive networks that are robust to adversarial attacks on the ML\npipeline of cognitive networks."
        },
        {
            "reference_num": "[97]",
            "reference_title": "B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. ˇSrndi´c, P. Laskov, G. Giacinto, and F. Roli, “Evasion attacks against machine learning at test time,” in Joint European conference on machine learning and knowledge discovery in databases. Springer, 2013, pp. 387–402.",
            "reference_abstract": "In security-sensitive applications, the success of machine learning depends\non a thorough vetting of their resistance to adversarial data. In one\npertinent, well-motivated attack scenario, an adversary may attempt to evade a\ndeployed system at test time by carefully manipulating attack samples. In this\nwork, we present a simple but effective gradient-based approach that can be\nexploited to systematically assess the security of several, widely-used\nclassification algorithms against evasion attacks. Following a recently\nproposed framework for security evaluation, we simulate attack scenarios that\nexhibit different risk levels for the classifier by increasing the attacker's\nknowledge of the system and her ability to manipulate attack samples. This\ngives the classifier designer a better picture of the classifier performance\nunder evasion attacks, and allows him to perform a more informed model\nselection (or parameter setting). We evaluate our approach on the relevant\nsecurity task of malware detection in PDF files, and show that such systems can\nbe easily evaded. We also sketch some countermeasures suggested by our\nanalysis."
        },
        {
            "reference_num": "[98]",
            "reference_title": "M. Mozaffari-Kermani, S. Sur-Kolay, A. Raghunathan, and N. K. Jha, “Systematic poisoning attacks on and defenses for machine learning in healthcare,” IEEE journal of biomedical and health informatics, vol. 19, no. 6, pp. 1893–1905, 2014.",
            "reference_abstract": "Data poisoning attacks -- where an adversary can modify a small fraction of\ntraining data, with the goal of forcing the trained classifier to high loss --\nare an important threat for machine learning in many applications. While a body\nof prior work has developed attacks and defenses, there is not much general\nunderstanding on when various attacks and defenses are effective. In this work,\nwe undertake a rigorous study of defenses against data poisoning for online\nlearning. First, we study four standard defenses in a powerful threat model,\nand provide conditions under which they can allow or resist rapid poisoning. We\nthen consider a weaker and more realistic threat model, and show that the\nsuccess of the adversary in the presence of data poisoning defenses there\ndepends on the \"ease\" of the learning problem."
        },
        {
            "reference_num": "[99]",
            "reference_title": "S. G. Finlayson, H. W. Chung, I. S. Kohane, and A. L. Beam, “Adversarial attacks against medical deep learning systems,” arXiv preprint arXiv:1804.05296, 2018.",
            "reference_abstract": "The discovery of adversarial examples has raised concerns about the practical\ndeployment of deep learning systems. In this paper, we demonstrate that\nadversarial examples are capable of manipulating deep learning systems across\nthree clinical domains. For each of our representative medical deep learning\nclassifiers, both white and black box attacks were highly successful. Our\nmodels are representative of the current state of the art in medical computer\nvision and, in some cases, directly reflect architectures already seeing\ndeployment in real world clinical settings. In addition to the technical\ncontribution of our paper, we synthesize a large body of knowledge about the\nhealthcare system to argue that medicine may be uniquely susceptible to\nadversarial attacks, both in terms of monetary incentives and technical\nvulnerability. To this end, we outline the healthcare economy and the\nincentives it creates for fraud and provide concrete examples of how and why\nsuch attacks could be realistically carried out. We urge practitioners to be\naware of current vulnerabilities when deploying deep learning systems in\nclinical settings, and encourage the machine learning community to further\ninvestigate the domain-specific characteristics of medical learning systems."
        },
        {
            "reference_num": "[100]",
            "reference_title": "M. Al-Rubaie and J. M. Chang, “Privacy-preserving machine learning: Threats and solutions,” IEEE Security & Privacy, vol. 17, no. 2, pp. 49–58, 2019.",
            "reference_abstract": "For privacy concerns to be addressed adequately in current machine learning\nsystems, the knowledge gap between the machine learning and privacy communities\nmust be bridged. This article aims to provide an introduction to the\nintersection of both fields with special emphasis on the techniques used to\nprotect the data."
        },
        {
            "reference_num": "[101]",
            "reference_title": "J. Zhang and E. Bareinboim, “Fairness in decision-makingthe causal explanation formula,” in Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.",
            "reference_abstract": "Assessing the magnitude of cause-and-effect relations is one of the central\nchallenges found throughout the empirical sciences. The problem of\nidentification of causal effects is concerned with determining whether a causal\neffect can be computed from a combination of observational data and substantive\nknowledge about the domain under investigation, which is formally expressed in\nthe form of a causal graph. In many practical settings, however, the knowledge\navailable for the researcher is not strong enough so as to specify a unique\ncausal graph. Another line of investigation attempts to use observational data\nto learn a qualitative description of the domain called a Markov equivalence\nclass, which is the collection of causal graphs that share the same set of\nobserved features. In this paper, we marry both approaches and study the\nproblem of causal identification from an equivalence class, represented by a\npartial ancestral graph (PAG). We start by deriving a set of graphical\nproperties of PAGs that are carried over to its induced subgraphs. We then\ndevelop an algorithm to compute the effect of an arbitrary set of variables on\nan arbitrary outcome set. We show that the algorithm is strictly more powerful\nthan the current state of the art found in the literature."
        },
        {
            "reference_num": "[102]",
            "reference_title": "P. Schulam and S. Saria, “Reliable decision support using counterfactual models,” in Advances in Neural Information Processing Systems, 2017, pp. 1697–1708.",
            "reference_abstract": "Decision-makers are faced with the challenge of estimating what is likely to\nhappen when they take an action. For instance, if I choose not to treat this\npatient, are they likely to die? Practitioners commonly use supervised learning\nalgorithms to fit predictive models that help decision-makers reason about\nlikely future outcomes, but we show that this approach is unreliable, and\nsometimes even dangerous. The key issue is that supervised learning algorithms\nare highly sensitive to the policy used to choose actions in the training data,\nwhich causes the model to capture relationships that do not generalize. We\npropose using a different learning objective that predicts counterfactuals\ninstead of predicting outcomes under an existing action policy as in supervised\nlearning. To support decision-making in temporal settings, we introduce the\nCounterfactual Gaussian Process (CGP) to predict the counterfactual future\nprogression of continuous-time trajectories under sequences of future actions.\nWe demonstrate the benefits of the CGP on two important decision-support tasks:\nrisk prediction and \"what if?\" reasoning for individualized treatment planning."
        },
        {
            "reference_num": "[103]",
            "reference_title": "M. Ghassemi, T. Naumann, P. Schulam, A. L. Beam, and R. Ranganath, “Opportunities in machine learning for healthcare,” arXiv preprint arXiv:1806.00388, 2018.",
            "reference_abstract": "Modern electronic health records (EHRs) provide data to answer clinically\nmeaningful questions. The growing data in EHRs makes healthcare ripe for the\nuse of machine learning. However, learning in a clinical setting presents\nunique challenges that complicate the use of common machine learning\nmethodologies. For example, diseases in EHRs are poorly labeled, conditions can\nencompass multiple underlying endotypes, and healthy individuals are\nunderrepresented. This article serves as a primer to illuminate these\nchallenges and highlights opportunities for members of the machine learning\ncommunity to contribute to healthcare."
        },
        {
            "reference_num": "[104]",
            "reference_title": "E. Begoli, T. Bhattacharya, and D. Kusnezov, “The need for uncertainty quantiﬁcation in machine-assisted medical decision making,” Nature Machine Intelligence, vol. 1, no. 1, p. 20, 2019.",
            "reference_abstract": "In the past several years, we have taken advantage of a number of\nopportunities to advance the intersection of next generation high-performance\ncomputing AI and big data technologies through partnerships in precision\nmedicine. Today we are in the throes of piecing together what is likely the\nmost unique convergence of medical data and computer technologies. But more\ndeeply, we observe that the traditional paradigm of computer simulation and\nprediction needs fundamental revision. This is the time for a number of\nreasons. We will review what the drivers are, why now, how this has been\napproached over the past several years, and where we are heading."
        },
        {
            "reference_num": "[105]",
            "reference_title": "A. Khademi, S. Lee, D. Foley, and V. Honavar, “Fairness in algorithmic decision making: An excursion through the lens of causality,” in The World Wide Web Conference. ACM, 2019, pp. 2907–2914.",
            "reference_abstract": "As virtually all aspects of our lives are increasingly impacted by\nalgorithmic decision making systems, it is incumbent upon us as a society to\nensure such systems do not become instruments of unfair discrimination on the\nbasis of gender, race, ethnicity, religion, etc. We consider the problem of\ndetermining whether the decisions made by such systems are discriminatory,\nthrough the lens of causal models. We introduce two definitions of group\nfairness grounded in causality: fair on average causal effect (FACE), and fair\non average causal effect on the treated (FACT). We use the Rubin-Neyman\npotential outcomes framework for the analysis of cause-effect relationships to\nrobustly estimate FACE and FACT. We demonstrate the effectiveness of our\nproposed approach on synthetic data. Our analyses of two real-world data sets,\nthe Adult income data set from the UCI repository (with gender as the protected\nattribute), and the NYC Stop and Frisk data set (with race as the protected\nattribute), show that the evidence of discrimination obtained by FACE and FACT,\nor lack thereof, is often in agreement with the findings from other studies. We\nfurther show that FACT, being somewhat more nuanced compared to FACE, can yield\nfindings of discrimination that differ from those obtained using FACE."
        },
        {
            "reference_num": "[106]",
            "reference_title": "N. Kilbertus, M. R. Carulla, G. Parascandolo, M. Hardt, D. Janzing, and B. Sch¨olkopf, “Avoiding discrimination through causal reasoning,” in Advances in Neural Information Processing Systems, 2017, pp. 656– 666.",
            "reference_abstract": "Recent work on fairness in machine learning has focused on various\nstatistical discrimination criteria and how they trade off. Most of these\ncriteria are observational: They depend only on the joint distribution of\npredictor, protected attribute, features, and outcome. While convenient to work\nwith, observational criteria have severe inherent limitations that prevent them\nfrom resolving matters of fairness conclusively.\n  Going beyond observational criteria, we frame the problem of discrimination\nbased on protected attributes in the language of causal reasoning. This\nviewpoint shifts attention from \"What is the right fairness criterion?\" to\n\"What do we want to assume about the causal data generating process?\" Through\nthe lens of causality, we make several contributions. First, we crisply\narticulate why and when observational criteria fail, thus formalizing what was\nbefore a matter of opinion. Second, our approach exposes previously ignored\nsubtleties and why they are fundamental to the problem. Finally, we put forward\nnatural causal non-discrimination criteria and develop algorithms that satisfy\nthem."
        },
        {
            "reference_num": "[107]",
            "reference_title": "L. Faes, S. K. Wagner, D. J. Fu, X. Liu, E. Korot, J. R. Ledsam, T. Back, R. Chopra, N. Pontikos, C. Kern et al., “Automated deep learning design for medical image classiﬁcation by health-care professionals with no coding experience: a feasibility study,” The Lancet Digital Health, vol. 1, no. 5, pp. e232–e242, 2019.",
            "reference_abstract": "Using an $e^+e^-$ annihilation data sample corresponding to an integrated\nluminosity of $2.93\\,\\rm fb^{-1}$ collected at the center-of-mass energy of\n3.773\\,GeV with the BESIII detector, we measure the absolute branching\nfractions of $D^+\\to\\eta\\eta\\pi^+$, $D^+\\to\\eta\\pi^+\\pi^0$, and\n$D^0\\to\\eta\\pi^+\\pi^-$ to be $(2.96 \\pm 0.24 \\pm 0.13)\\times 10^{-3}$, $(2.23\n\\pm 0.15 \\pm 0.11)\\times 10^{-3}$, and $(1.20 \\pm 0.07 \\pm 0.04)\\times\n10^{-3}$, respectively, where the first uncertainties are statistical and the\nsecond ones systematic. The $D^+\\to\\eta\\eta\\pi^+$ decay is observed for the\nfirst time and the branching fractions of $D^{+(0)}\\to\\eta\\pi^+\\pi^{0(-)}$ are\nmeasured with much improved precision. In addition we test for $CP$ asymmetries\nin the separated charge-conjugate branching fractions; no evidence of $CP$\nviolation is found."
        },
        {
            "reference_num": "[108]",
            "reference_title": "N. u. . h. OReilly, “Challenges to AI in healthcare accessed online: 16 oct 2019.”",
            "reference_abstract": "We are facing a global healthcare crisis today as the healthcare cost is ever\nclimbing, but with the aging population, government fiscal revenue is ever\ndropping. To create a more efficient and effective healthcare system, three\ntechnical challenges immediately present themselves: healthcare access,\nhealthcare equity, and healthcare efficiency. An autonomous mobile clinic\nsolves the healthcare access problem by bringing healthcare services to the\npatient by the order of the patient's fingertips. Nevertheless, to enable a\nuniversal autonomous mobile clinic network, a three-stage technical roadmap\nneeds to be achieved: In stage one, we focus on solving the inequity challenge\nin the existing healthcare system by combining autonomous mobility and\ntelemedicine. In stage two, we develop an AI doctor for primary care, which we\nfoster from infancy to adulthood with clean healthcare data. With the AI\ndoctor, we can solve the inefficiency problem. In stage three, after we have\nproven that the autonomous mobile clinic network can truly solve the target\nclinical use cases, we shall open up the platform for all medical verticals,\nthus enabling universal healthcare through this whole new system."
        },
        {
            "reference_num": "[109]",
            "reference_title": "B. David, R. Dowsley, R. Katti, and A. C. Nascimento, “Efﬁcient unconditionally secure comparison and privacy preserving machine learning classiﬁcation protocols,” in International Conference on Provable Security. Springer, 2015, pp. 354–367.",
            "reference_abstract": "Classification of personal text messages has many useful applications in\nsurveillance, e-commerce, and mental health care, to name a few. Giving\napplications access to personal texts can easily lead to (un)intentional\nprivacy violations. We propose the first privacy-preserving solution for text\nclassification that is provably secure. Our method, which is based on Secure\nMultiparty Computation (SMC), encompasses both feature extraction from texts,\nand subsequent classification with logistic regression and tree ensembles. We\nprove that when using our secure text classification method, the application\ndoes not learn anything about the text, and the author of the text does not\nlearn anything about the text classification model used by the application\nbeyond what is given by the classification result itself. We perform end-to-end\nexperiments with an application for detecting hate speech against women and\nimmigrants, demonstrating excellent runtime results without loss of accuracy."
        },
        {
            "reference_num": "[110]",
            "reference_title": "M. Jagielski, A. Oprea, B. Biggio, C. Liu, C. Nita-Rotaru, and B. Li, “Manipulating machine learning: Poisoning attacks and countermeasures for regression learning,” in 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 2018, pp. 19–35.",
            "reference_abstract": "As machine learning becomes widely used for automated decisions, attackers\nhave strong incentives to manipulate the results and models generated by\nmachine learning algorithms. In this paper, we perform the first systematic\nstudy of poisoning attacks and their countermeasures for linear regression\nmodels. In poisoning attacks, attackers deliberately influence the training\ndata to manipulate the results of a predictive model. We propose a\ntheoretically-grounded optimization framework specifically designed for linear\nregression and demonstrate its effectiveness on a range of datasets and models.\nWe also introduce a fast statistical attack that requires limited knowledge of\nthe training process. Finally, we design a new principled defense method that\nis highly resilient against all poisoning attacks. We provide formal guarantees\nabout its convergence and an upper bound on the effect of poisoning attacks\nwhen the defense is deployed. We evaluate extensively our attacks and defenses\non three realistic datasets from health care, loan assessment, and real estate\ndomains."
        },
        {
            "reference_num": "[111]",
            "reference_title": "M. Liu, H. Jiang, J. Chen, A. Badokhon, X. Wei, and M.-C. Huang, “A collaborative privacy-preserving deep learning system in distributed mobile environment,” in 2016 International Conference on Computational Science and Computational Intelligence (CSCI). IEEE, 2016, pp. 192–197.",
            "reference_abstract": "We present a measurement of the azimuthal asymmetries of two charged pions in\nthe inclusive process $e^+e^-\\rightarrow \\pi\\pi X$ based on a data set of 62\n$\\rm{pb}^{-1}$ at the center-of-mass energy $\\sqrt{s}=3.65$ GeV collected with\nthe BESIII detector. These asymmetries can be attributed to the Collins\nfragmentation function. We observe a nonzero asymmetry, which increases with\nincreasing pion momentum. As our energy scale is close to that of the existing\nsemi-inclusive deep inelastic scattering experimental data, the measured\nasymmetries are important inputs for the global analysis of extracting the\nquark transversity distribution inside the nucleon and are valuable to explore\nthe energy evolution of the spin-dependent fragmentation function."
        },
        {
            "reference_num": "[112]",
            "reference_title": "D. Malathi, R. Logesh, V. Subramaniyaswamy, V. Vijayakumar, and A. K. Sangaiah, “Hybrid reasoning-based privacy-aware disease prediction support system,” Computers & Electrical Engineering, vol. 73, pp. 114–127, 2019.",
            "reference_abstract": "A radio labeling of a graph $G$ is a mapping $\\vp : V(G) \\rightarrow \\{0, 1,\n2,...\\}$ such that $|\\vp(u)-\\vp(v)|\\geq \\diam(G) + 1 - d(u,v)$ for every pair\nof distinct vertices $u,v$ of $G$, where $\\diam(G)$ and $d(u,v)$ are the\ndiameter of $G$ and distance between $u$ and $v$ in $G$, respectively. The\nradio number $\\rn(G)$ of $G$ is the smallest number $k$ such that $G$ has radio\nlabeling with $\\max\\{\\vp(v):v \\in V(G)\\}$ = $k$. In this paper, we slightly\nimprove the lower bound for the radio number of graphs given by Das \\emph{et\nal.} in [5] and, give necessary and sufficient condition to achieve the lower\nbound. Using this result, we determine the radio number for cartesian product\nof paths $P_{n}$ and the Peterson graph $P$. We give a short proof for the\nradio number of cartesian product of paths $P_{n}$ and complete graphs $K_{m}$\ngiven by Kim \\emph{et al.} in [6]."
        },
        {
            "reference_num": "[113]",
            "reference_title": "H. Takabi, E. Hesamifard, and M. Ghasemi, “Privacy preserving multiparty machine learning with homomorphic encryption,” in 29th Annual Conference on Neural Information Processing Systems (NIPS), 2016.",
            "reference_abstract": "Machine learning algorithms based on deep neural networks have achieved\nremarkable results and are being extensively used in different domains.\nHowever, the machine learning algorithms requires access to raw data which is\noften privacy sensitive. To address this issue, we develop new techniques to\nprovide solutions for running deep neural networks over encrypted data. In this\npaper, we develop new techniques to adopt deep neural networks within the\npractical limitation of current homomorphic encryption schemes. More\nspecifically, we focus on classification of the well-known convolutional neural\nnetworks (CNN). First, we design methods for approximation of the activation\nfunctions commonly used in CNNs (i.e. ReLU, Sigmoid, and Tanh) with low degree\npolynomials which is essential for efficient homomorphic encryption schemes.\nThen, we train convolutional neural networks with the approximation polynomials\ninstead of original activation functions and analyze the performance of the\nmodels. Finally, we implement convolutional neural networks over encrypted data\nand measure performance of the models. Our experimental results validate the\nsoundness of our approach with several convolutional neural networks with\nvarying number of layers and structures. When applied to the MNIST optical\ncharacter recognition tasks, our approach achieves 99.52\\% accuracy which\nsignificantly outperforms the state-of-the-art solutions and is very close to\nthe accuracy of the best non-private version, 99.77\\%. Also, it can make close\nto 164000 predictions per hour. We also applied our approach to CIFAR-10, which\nis much more complex compared to MNIST, and were able to achieve 91.5\\%\naccuracy with approximation polynomials used as activation functions. These\nresults show that CryptoDL provides efficient, accurate and scalable\nprivacy-preserving predictions."
        },
        {
            "reference_num": "[114]",
            "reference_title": "M. Kim, Y. Song, S. Wang, Y. Xia, and X. Jiang, “Secure logistic regression based on homomorphic encryption: Design and evaluation,” JMIR medical informatics, vol. 6, no. 2, p. e19, 2018.",
            "reference_abstract": "Using an $e^+e^-$ annihilation data sample corresponding to an integrated\nluminosity of $2.93\\,\\rm fb^{-1}$ collected at the center-of-mass energy of\n3.773\\,GeV with the BESIII detector, we measure the absolute branching\nfractions of $D^+\\to\\eta\\eta\\pi^+$, $D^+\\to\\eta\\pi^+\\pi^0$, and\n$D^0\\to\\eta\\pi^+\\pi^-$ to be $(2.96 \\pm 0.24 \\pm 0.13)\\times 10^{-3}$, $(2.23\n\\pm 0.15 \\pm 0.11)\\times 10^{-3}$, and $(1.20 \\pm 0.07 \\pm 0.04)\\times\n10^{-3}$, respectively, where the first uncertainties are statistical and the\nsecond ones systematic. The $D^+\\to\\eta\\eta\\pi^+$ decay is observed for the\nfirst time and the branching fractions of $D^{+(0)}\\to\\eta\\pi^+\\pi^{0(-)}$ are\nmeasured with much improved precision. In addition we test for $CP$ asymmetries\nin the separated charge-conjugate branching fractions; no evidence of $CP$\nviolation is found."
        },
        {
            "reference_num": "[115]",
            "reference_title": "I. Chen, F. D. Johansson, and D. Sontag, “Why is my classiﬁer discriminatory?” in Advances in Neural Information Processing Systems, 2018, pp. 3539–3550.",
            "reference_abstract": "Recent attempts to achieve fairness in predictive models focus on the balance\nbetween fairness and accuracy. In sensitive applications such as healthcare or\ncriminal justice, this trade-off is often undesirable as any increase in\nprediction error could have devastating consequences. In this work, we argue\nthat the fairness of predictions should be evaluated in context of the data,\nand that unfairness induced by inadequate samples sizes or unmeasured\npredictive variables should be addressed through data collection, rather than\nby constraining the model. We decompose cost-based metrics of discrimination\ninto bias, variance, and noise, and propose actions aimed at estimating and\nreducing each term. Finally, we perform case-studies on prediction of income,\nmortality, and review ratings, confirming the value of this analysis. We find\nthat data collection is often a means to reduce discrimination without\nsacrificing accuracy."
        },
        {
            "reference_num": "[116]",
            "reference_title": "M. Ghassemi, T. Naumann, P. Schulam, A. L. Beam, I. Y. Chen, and R. Ranganath, “Practical guidance on artiﬁcial intelligence for healthcare data,” The Lancet Digital Health, vol. 1, no. 4, pp. e157–e159, 2019.",
            "reference_abstract": "Modern electronic health records (EHRs) provide data to answer clinically\nmeaningful questions. The growing data in EHRs makes healthcare ripe for the\nuse of machine learning. However, learning in a clinical setting presents\nunique challenges that complicate the use of common machine learning\nmethodologies. For example, diseases in EHRs are poorly labeled, conditions can\nencompass multiple underlying endotypes, and healthy individuals are\nunderrepresented. This article serves as a primer to illuminate these\nchallenges and highlights opportunities for members of the machine learning\ncommunity to contribute to healthcare."
        },
        {
            "reference_num": "[117]",
            "reference_title": "T. Panch, H. Mattie, and L. A. Celi, “The inconvenient truth about ai in healthcare,” Npj Digital Medicine, vol. 2, no. 1, pp. 1–3, 2019.",
            "reference_abstract": "We review the Lieb-Schultz-Mattis theorem and its variants, which are no-go\ntheorems that state that a quantum many-body system with certain conditions\ncannot have a locally-unique gapped ground state. We restrict ourselves to\none-dimensional quantum spin systems and discuss both the generalized\nLieb-Schultz-Mattis theorem for models with U(1) symmetry and the extended\nLieb-Schultz-Mattis theorem for models with discrete symmetry. We also discuss\nthe implication of the same arguments to systems on the infinite cylinder, both\nwith the periodic boundary conditions and with the spiral boundary conditions.\n  For models with U(1) symmetry, we here present a rearranged version of the\noriginal proof of Lieb, Schultz, and Mattis based on the twist operator. As the\ntitle suggests we take a modern topological point of view and prove the\ngeneralized Lieb-Schultz-Mattis theorem by making use of a topological index\n(which coincides with the filling factor). By a topological index, we mean an\nindex that characterizes a locally-unique gapped ground state and is invariant\nunder continuous (or smooth) modification of the ground state.\n  For models with discrete symmetry, we describe the basic idea of the most\ngeneral proof based on the topological index introduced in the context of\nsymmetry-protected topological phases. We start from background materials such\nas the classification of projective representations of the symmetry group.\n  We also review the notion that we call a locally-unique gapped ground state\nof a quantum spin system on an infinite lattice and present basic theorems.\nThis notion turns out to be natural and useful from the physicists' point of\nview.\n  We have tried to make the present article readable and almost self-contained.\nWe only assume basic knowledge about quantum spin systems."
        },
        {
            "reference_num": "[118]",
            "reference_title": "C. S. Perone, P. Ballester, R. C. Barros, and J. Cohen-Adad, “Unsupervised domain adaptation for medical imaging segmentation with self-ensembling,” NeuroImage, vol. 194, pp. 1–11, 2019.",
            "reference_abstract": "Recent advances in deep learning methods have come to define the\nstate-of-the-art for many medical imaging applications, surpassing even human\njudgment in several tasks. Those models, however, when trained to reduce the\nempirical risk on a single domain, fail to generalize when applied to other\ndomains, a very common scenario in medical imaging due to the variability of\nimages and anatomical structures, even across the same imaging modality. In\nthis work, we extend the method of unsupervised domain adaptation using\nself-ensembling for the semantic segmentation task and explore multiple facets\nof the method on a small and realistic publicly-available magnetic resonance\n(MRI) dataset. Through an extensive evaluation, we show that self-ensembling\ncan indeed improve the generalization of the models even when using a small\namount of unlabelled data."
        },
        {
            "reference_num": "[119]",
            "reference_title": "A. Narayanan and V. Shmatikov, “Robust de-anonymization of large datasets (how to break anonymity of the netﬂix prize dataset),” University of Texas at Austin, 2008.",
            "reference_abstract": "We present a new class of statistical de-anonymization attacks against\nhigh-dimensional micro-data, such as individual preferences, recommendations,\ntransaction records and so on. Our techniques are robust to perturbation in the\ndata and tolerate some mistakes in the adversary's background knowledge.\n  We apply our de-anonymization methodology to the Netflix Prize dataset, which\ncontains anonymous movie ratings of 500,000 subscribers of Netflix, the world's\nlargest online movie rental service. We demonstrate that an adversary who knows\nonly a little bit about an individual subscriber can easily identify this\nsubscriber's record in the dataset. Using the Internet Movie Database as the\nsource of background knowledge, we successfully identified the Netflix records\nof known users, uncovering their apparent political preferences and other\npotentially sensitive information."
        },
        {
            "reference_num": "[120]",
            "reference_title": "P. Mohassel and Y. Zhang, “Secureml: A system for scalable privacypreserving machine learning,” in 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 2017, pp. 19–38.  21",
            "reference_abstract": "The recent, remarkable growth of machine learning has led to intense interest\nin the privacy of the data on which machine learning relies, and to new\ntechniques for preserving privacy. However, older ideas about privacy may well\nremain valid and useful. This note reviews two recent works on privacy in the\nlight of the wisdom of some of the early literature, in particular the\nprinciples distilled by Saltzer and Schroeder in the 1970s."
        },
        {
            "reference_num": "[121]",
            "reference_title": "R. Bost, R. A. Popa, S. Tu, and S. Goldwasser, “Machine learning classiﬁcation over encrypted data.” in NDSS, vol. 4324, 2015, p. 4325.",
            "reference_abstract": "We study the clustering of galaxies detected at $i&lt;22.5$ in the Science\nVerification observations of the Dark Energy Survey (DES). Two-point\ncorrelation functions are measured using $2.3\\times 10^6$ galaxies over a\ncontiguous 116 deg$^2$ region in five bins of photometric redshift width\n$\\Delta z = 0.2$ in the range $0.2 &lt; z &lt; 1.2.$ The impact of photometric\nredshift errors are assessed by comparing results using a template-based\nphoto-$z$ algorithm (BPZ) to a machine-learning algorithm (TPZ). A companion\npaper (Leistedt et al 2015) presents maps of several observational variables\n(e.g. seeing, sky brightness) which could modulate the galaxy density. Here we\ncharacterize and mitigate systematic errors on the measured clustering which\narise from these observational variables, in addition to others such as\nGalactic dust and stellar contamination. After correcting for systematic\neffects we measure galaxy bias over a broad range of linear scales relative to\nmass clustering predicted from the Planck $\\Lambda$CDM model, finding agreement\nwith CFHTLS measurements with $\\chi^2$ of 4.0 (8.7) with 5 degrees of freedom\nfor the TPZ (BPZ) redshifts. We test a \"linear bias\" model, in which the galaxy\nclustering is a fixed multiple of the predicted non-linear dark-matter\nclustering. The precision of the data allow us to determine that the linear\nbias model describes the observed galaxy clustering to $2.5\\%$ accuracy down to\nscales at least $4$ to $10$ times smaller than those on which linear theory is\nexpected to be sufficient."
        },
        {
            "reference_num": "[122]",
            "reference_title": "D. Bogdanov, L. Kamm, S. Laur, and V. Sokk, “Implementation and evaluation of an algorithm for cryptographically private principal component analysis on genomic data,” IEEE/ACM transactions on computational biology and bioinformatics, vol. 15, no. 5, pp. 1427– 1432, 2018.",
            "reference_abstract": "Most phylogenetic analyses result in a sample of trees, but summarizing and\nvisualizing these samples can be challenging. Consensus trees often provide\nlimited information about a sample, and so methods such as consensus networks,\nclustering and multidimensional scaling have been developed and applied to tree\nsamples. This paper describes a stochastic algorithm for constructing a\nprincipal geodesic or line through treespace which is analogous to the first\nprincipal component in standard Principal Components Analysis. A principal\ngeodesic summarizes the most variable features of a sample of trees, in terms\nof both tree topology and branch lengths, and it can be visualized as an\nanimation of smoothly changing trees. The algorithm performs a stochastic\nsearch through parameter space for a geodesic which minimises the sum of\nsquared projected distances of the data points. This procedure aims to identify\nthe globally optimal principal geodesic, though convergence to locally optimal\ngeodesics is possible. The methodology is illustrated by constructing principal\ngeodesics for experimental and simulated data sets, demonstrating the insight\ninto samples of trees that can be gained and how the method improves on a\npreviously published approach. A java package called GeoPhytter for\nconstructing and visualising principal geodesics is freely available from\nwww.ncl.ac.uk/~ntmwn/geophytter."
        },
        {
            "reference_num": "[123]",
            "reference_title": "K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for privacy-preserving machine learning,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2017, pp. 1175–1191.",
            "reference_abstract": "Secure Aggregation protocols allow a collection of mutually distrust parties,\neach holding a private value, to collaboratively compute the sum of those\nvalues without revealing the values themselves. We consider training a deep\nneural network in the Federated Learning model, using distributed stochastic\ngradient descent across user-held training data on mobile devices, wherein\nSecure Aggregation protects each user's model gradient. We design a novel,\ncommunication-efficient Secure Aggregation protocol for high-dimensional data\nthat tolerates up to 1/3 users failing to complete the protocol. For 16-bit\ninput values, our protocol offers 1.73x communication expansion for $2^{10}$\nusers and $2^{20}$-dimensional vectors, and 1.98x expansion for $2^{14}$ users\nand $2^{24}$ dimensional vectors."
        },
        {
            "reference_num": "[124]",
            "reference_title": "M. S. Hossain and G. Muhammad, “Emotion recognition using secure edge and cloud computing,” Information Sciences, vol. 504, pp. 589– 601, 2019.",
            "reference_abstract": "The development of mobile communication technology, hardware, distributed\ncomputing, and artificial intelligence (AI) technology has promoted the\napplication of edge computing in the field of heterogeneous Internet of Things\n(IoT). In order to overcome the defects of the traditional cloud computing\nmodel in the era of big data. In this article, we first propose a new AIenabled\nsmart edge with heterogeneous IoT architecture which combines edge computing,\ncaching, and communication. Then, we propose the Smart-Edge-CoCaCo algorithm.\nTo minimize total delay and confirm the computation offloading decision,\nSmart-Edge-CoCaCo uses joint optimization of the wireless communication model,\nthe collaborative filter caching model in edge cloud, and the computation\noffloading model. Finally, we built an emotion interaction testbed to perform\ncomputational delay experiments in real environments. The experiment results\nshowed that the computation delay of the Smart-Edge-CoCaCo algorithm is lower\nthan that of traditional cloud computing model with the increase of computing\ntask data and the number of concurrent users."
        },
        {
            "reference_num": "[125]",
            "reference_title": "O. Ohrimenko, F. Schuster, C. Fournet, A. Mehta, S. Nowozin, K. Vaswani, and M. Costa, “Oblivious multi-party machine learning on trusted processors,” in 25th USENIX Security Symposium (USENIX Security 16), 2016, pp. 619–636.",
            "reference_abstract": "We propose a hybrid model of differential privacy that considers a\ncombination of regular and opt-in users who desire the differential privacy\nguarantees of the local privacy model and the trusted curator model,\nrespectively. We demonstrate that within this model, it is possible to design a\nnew type of blended algorithm for the task of privately computing the head of a\nsearch log. This blended approach provides significant improvements in the\nutility of obtained data compared to related work while providing users with\ntheir desired privacy guarantees. Specifically, on two large search click data\nsets, comprising 1.75 and 16 GB respectively, our approach attains NDCG values\nexceeding 95% across a range of privacy budget values."
        },
        {
            "reference_num": "[126]",
            "reference_title": "C. Dwork, “Differential privacy,” Encyclopedia of Cryptography and Security, pp. 338–340, 2011.",
            "reference_abstract": "Cybersecurity awareness can be viewed as the level of appreciation,\nunderstanding or knowledge of cybersecurity or information security aspects.\nSuch aspects include cognizance of cyber risks and threats, but also\nappropriate protection measures."
        },
        {
            "reference_num": "[127]",
            "reference_title": "M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang, “Deep learning with differential privacy,” in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2016, pp. 308–318.",
            "reference_abstract": "Machine learning techniques based on neural networks are achieving remarkable\nresults in a wide variety of domains. Often, the training of models requires\nlarge, representative datasets, which may be crowdsourced and contain sensitive\ninformation. The models should not expose private information in these\ndatasets. Addressing this goal, we develop new algorithmic techniques for\nlearning and a refined analysis of privacy costs within the framework of\ndifferential privacy. Our implementation and experiments demonstrate that we\ncan train deep neural networks with non-convex objectives, under a modest\nprivacy budget, and at a manageable cost in software complexity, training\nefficiency, and model quality."
        },
        {
            "reference_num": "[128]",
            "reference_title": "M. McDermott, S. Wang, N. Marinsek, R. Ranganath, M. Ghassemi, and L. Foschini, “Reproducibility in machine learning for health,” Presented at the Internation Conference on Learning Representative (ICLR) 2019 Reproducibility in Machine Learning Workshop, 2019.",
            "reference_abstract": "Machine learning algorithms designed to characterize, monitor, and intervene\non human health (ML4H) are expected to perform safely and reliably when\noperating at scale, potentially outside strict human supervision. This\nrequirement warrants a stricter attention to issues of reproducibility than\nother fields of machine learning.\n  In this work, we conduct a systematic evaluation of over 100 recently\npublished ML4H research papers along several dimensions related to\nreproducibility. We find that the field of ML4H compares poorly to more\nestablished machine learning fields, particularly concerning data and code\naccessibility. Finally, drawing from success in other fields of science, we\npropose recommendations to data providers, academic publishers, and the ML4H\nresearch community in order to promote reproducible research moving forward."
        },
        {
            "reference_num": "[129]",
            "reference_title": "N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and ´U. Erlingsson, “Scalable private learning with pate,” International Conference on Learning Representations (ICLR), 2018.",
            "reference_abstract": "The rapid adoption of machine learning has increased concerns about the\nprivacy implications of machine learning models trained on sensitive data, such\nas medical records or other personal information. To address those concerns,\none promising approach is Private Aggregation of Teacher Ensembles, or PATE,\nwhich transfers to a \"student\" model the knowledge of an ensemble of \"teacher\"\nmodels, with intuitive privacy provided by training teachers on disjoint data\nand strong privacy guaranteed by noisy aggregation of teachers' answers.\nHowever, PATE has so far been evaluated only on simple classification tasks\nlike MNIST, leaving unclear its utility when applied to larger-scale learning\ntasks and real-world datasets.\n  In this work, we show how PATE can scale to learning tasks with large numbers\nof output classes and uncurated, imbalanced training data with errors. For\nthis, we introduce new noisy aggregation mechanisms for teacher ensembles that\nare more selective and add less noise, and prove their tighter\ndifferential-privacy guarantees. Our new mechanisms build on two insights: the\nchance of teacher consensus is increased by using more concentrated noise and,\nlacking consensus, no answer need be given to a student. The consensus answers\nused are more likely to be correct, offer better intuitive privacy, and incur\nlower-differential privacy cost. Our evaluation shows our mechanisms improve on\nthe original PATE on all measures, and scale to larger tasks with both high\nutility and very strong privacy ($\\varepsilon$ &lt; 1.0)."
        },
        {
            "reference_num": "[130]",
            "reference_title": "Y.-X. Wang, B. Balle, and S. Kasiviswanathan, “Subsampled r\\’enyi differential privacy and analytical moments accountant,” arXiv preprint arXiv:1808.00087, 2018.",
            "reference_abstract": "We study the problem of subsampling in differential privacy (DP), a question\nthat is the centerpiece behind many successful differentially private machine\nlearning algorithms. Specifically, we provide a tight upper bound on the\nR\\'enyi Differential Privacy (RDP) (Mironov, 2017) parameters for algorithms\nthat: (1) subsample the dataset, and then (2) applies a randomized mechanism M\nto the subsample, in terms of the RDP parameters of M and the subsampling\nprobability parameter. Our results generalize the moments accounting technique,\ndeveloped by Abadi et al. (2016) for the Gaussian mechanism, to any subsampled\nRDP mechanism."
        },
        {
            "reference_num": "[131]",
            "reference_title": "H. B. McMahan, G. Andrew, U. Erlingsson, S. Chien, I. Mironov, N. Papernot, and P. Kairouz, “A general approach to adding differential privacy to iterative training procedures,” NeurIPS 2018 workshop on Privacy Preserving Machine Learning, 2018.",
            "reference_abstract": "In this work we address the practical challenges of training machine learning\nmodels on privacy-sensitive datasets by introducing a modular approach that\nminimizes changes to training algorithms, provides a variety of configuration\nstrategies for the privacy mechanism, and then isolates and simplifies the\ncritical logic that computes the final privacy guarantees. A key challenge is\nthat training algorithms often require estimating many different quantities\n(vectors) from the same set of examples --- for example, gradients of different\nlayers in a deep learning architecture, as well as metrics and batch\nnormalization parameters. Each of these may have different properties like\ndimensionality, magnitude, and tolerance to noise. By extending previous work\non the Moments Accountant for the subsampled Gaussian mechanism, we can provide\nprivacy for such heterogeneous sets of vectors, while also structuring the\napproach to minimize software engineering challenges."
        },
        {
            "reference_num": "[132]",
            "reference_title": "N. Phan, X. Wu, H. Hu, and D. Dou, “Adaptive laplace mechanism: Differential privacy preservation in deep learning,” in 2017 IEEE International Conference on Data Mining (ICDM). IEEE, 2017, pp. 385–394.",
            "reference_abstract": "In this paper, we focus on developing a novel mechanism to preserve\ndifferential privacy in deep neural networks, such that: (1) The privacy budget\nconsumption is totally independent of the number of training steps; (2) It has\nthe ability to adaptively inject noise into features based on the contribution\nof each to the output; and (3) It could be applied in a variety of different\ndeep neural networks. To achieve this, we figure out a way to perturb affine\ntransformations of neurons, and loss functions used in deep neural networks. In\naddition, our mechanism intentionally adds \"more noise\" into features which are\n\"less relevant\" to the model output, and vice-versa. Our theoretical analysis\nfurther derives the sensitivities and error bounds of our mechanism. Rigorous\nexperiments conducted on MNIST and CIFAR-10 datasets show that our mechanism is\nhighly effective and outperforms existing solutions."
        },
        {
            "reference_num": "[133]",
            "reference_title": "F. McSherry and K. Talwar, “Mechanism design via differential privacy.” in FOCS, vol. 7, 2007, pp. 94–103.",
            "reference_abstract": "One goal of statistical privacy research is to construct a data release\nmechanism that protects individual privacy while preserving information\ncontent. An example is a {\\em random mechanism} that takes an input database\n$X$ and outputs a random database $Z$ according to a distribution\n$Q_n(\\cdot|X)$. {\\em Differential privacy} is a particular privacy requirement\ndeveloped by computer scientists in which $Q_n(\\cdot |X)$ is required to be\ninsensitive to changes in one data point in $X$. This makes it difficult to\ninfer from $Z$ whether a given individual is in the original database $X$. We\nconsider differential privacy from a statistical perspective. We consider\nseveral data release mechanisms that satisfy the differential privacy\nrequirement. We show that it is useful to compare these schemes by computing\nthe rate of convergence of distributions and densities constructed from the\nreleased data. We study a general privacy method, called the exponential\nmechanism, introduced by McSherry and Talwar (2007). We show that the accuracy\nof this method is intimately linked to the rate at which the probability that\nthe empirical distribution concentrates in a small ball around the true\ndistribution."
        },
        {
            "reference_num": "[134]",
            "reference_title": "C. Dwork and F. D. McSherry, “Exponential noise distribution to optimize database privacy and output utility,” Jul. 14 2009, uS Patent 7,562,071.",
            "reference_abstract": "We advance the approach initiated by Chawla et al. for sanitizing (census)\ndata so as to preserve the privacy of respondents while simultaneously\nextracting \"useful\" statistical information. First, we extend the scope of\ntheir techniques to a broad and rich class of distributions, specifically,\nmixtures of highdimensional balls, spheres, Gaussians, and other \"nice\"\ndistributions. Second, we randomize the histogram constructions to preserve\nspatial characteristics of the data, allowing us to approximate various\nquantities of interest, e.g., cost of the minimum spanning tree on the data, in\na privacy-preserving fashion."
        },
        {
            "reference_num": "[135]",
            "reference_title": "B. K. Beaulieu-Jones, W. Yuan, S. G. Finlayson, and Z. S. Wu, “Privacy-preserving distributed deep learning for clinical data,” Machine Learning for Health (ML4H) Workshop at NeurIPS, 2018.",
            "reference_abstract": "Deep learning with medical data often requires larger samples sizes than are\navailable at single providers. While data sharing among institutions is\ndesirable to train more accurate and sophisticated models, it can lead to\nsevere privacy concerns due the sensitive nature of the data. This problem has\nmotivated a number of studies on distributed training of neural networks that\ndo not require direct sharing of the training data. However, simple distributed\ntraining does not offer provable privacy guarantees to satisfy technical safe\nstandards and may reveal information about the underlying patients. We present\na method to train neural networks for clinical data in a distributed fashion\nunder differential privacy. We demonstrate these methods on two datasets that\ninclude information from multiple independent sites, the eICU collaborative\nResearch Database and The Cancer Genome Atlas."
        },
        {
            "reference_num": "[136]",
            "reference_title": "H. B. McMahan, E. Moore, D. Ramage, S. Hampson et al., “Communication-efﬁcient learning of deep networks from decentralized data,” Proceedings of the 20 th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) JMLR: W&CP volume 54, 2017.",
            "reference_abstract": "Modern mobile devices have access to a wealth of data suitable for learning\nmodels, which in turn can greatly improve the user experience on the device.\nFor example, language models can improve speech recognition and text entry, and\nimage models can automatically select good photos. However, this rich data is\noften privacy sensitive, large in quantity, or both, which may preclude logging\nto the data center and training there using conventional approaches. We\nadvocate an alternative that leaves the training data distributed on the mobile\ndevices, and learns a shared model by aggregating locally-computed updates. We\nterm this decentralized approach Federated Learning.\n  We present a practical method for the federated learning of deep networks\nbased on iterative model averaging, and conduct an extensive empirical\nevaluation, considering five different model architectures and four datasets.\nThese experiments demonstrate the approach is robust to the unbalanced and\nnon-IID data distributions that are a defining characteristic of this setting.\nCommunication costs are the principal constraint, and we show a reduction in\nrequired communication rounds by 10-100x as compared to synchronized stochastic\ngradient descent."
        },
        {
            "reference_num": "[137]",
            "reference_title": "T. S. Brisimi, R. Chen, T. Mela, A. Olshevsky, I. C. Paschalidis, and W. Shi, “Federated learning of predictive models from federated electronic health records,” International journal of medical informatics, vol. 112, pp. 59–67, 2018.",
            "reference_abstract": "Urban living in modern large cities has significant adverse effects on\nhealth, increasing the risk of several chronic diseases. We focus on the two\nleading clusters of chronic disease, heart disease and diabetes, and develop\ndata-driven methods to predict hospitalizations due to these conditions. We\nbase these predictions on the patients' medical history, recent and more\ndistant, as described in their Electronic Health Records (EHR). We formulate\nthe prediction problem as a binary classification problem and consider a\nvariety of machine learning methods, including kernelized and sparse Support\nVector Machines (SVM), sparse logistic regression, and random forests. To\nstrike a balance between accuracy and interpretability of the prediction, which\nis important in a medical setting, we propose two novel methods: K-LRT, a\nlikelihood ratio test-based method, and a Joint Clustering and Classification\n(JCC) method which identifies hidden patient clusters and adapts classifiers to\neach cluster. We develop theoretical out-of-sample guarantees for the latter\nmethod. We validate our algorithms on large datasets from the Boston Medical\nCenter, the largest safety-net hospital system in New England."
        },
        {
            "reference_num": "[138]",
            "reference_title": "P. Vepakomma, O. Gupta, T. Swedish, and R. Raskar, “Split learning for health: Distributed deep learning without sharing raw patient data,” Published as Workshop Paper at 32nd Conference on Neural Information Processing Systems (NIPS 2018), 2018.",
            "reference_abstract": "Can health entities collaboratively train deep learning models without\nsharing sensitive raw data? This paper proposes several configurations of a\ndistributed deep learning method called SplitNN to facilitate such\ncollaborations. SplitNN does not share raw data or model details with\ncollaborating institutions. The proposed configurations of splitNN cater to\npractical settings of i) entities holding different modalities of patient data,\nii) centralized and local health entities collaborating on multiple tasks and\niii) learning without sharing labels. We compare performance and resource\nefficiency trade-offs of splitNN and other distributed deep learning methods\nlike federated learning, large batch synchronous stochastic gradient descent\nand show highly encouraging results for splitNN."
        },
        {
            "reference_num": "[139]",
            "reference_title": "D. Liu, T. Miller, R. Sayeed, and K. Mandl, “Fadl: Federatedautonomous deep learning for distributed electronic health record,” Machine Learning for Health (ML4H) Workshop at NeurIPS, 2018.",
            "reference_abstract": "Electronic health record (EHR) data is collected by individual institutions\nand often stored across locations in silos. Getting access to these data is\ndifficult and slow due to security, privacy, regulatory, and operational\nissues. We show, using ICU data from 58 different hospitals, that machine\nlearning models to predict patient mortality can be trained efficiently without\nmoving health data out of their silos using a distributed machine learning\nstrategy. We propose a new method, called Federated-Autonomous Deep Learning\n(FADL) that trains part of the model using all data sources in a distributed\nmanner and other parts using data from specific data sources. We observed that\nFADL outperforms traditional federated learning strategy and conclude that\nbalance between global and local training is an important factor to consider\nwhen design distributed machine learning methods , especially in healthcare."
        },
        {
            "reference_num": "[140]",
            "reference_title": "A. Qayyum, M. Usama, J. Qadir, and A. Al-Fuqaha, “Securing connected & autonomous vehicles: Challenges posed by adversarial machine learning and the way forward,” arXiv preprint arXiv:1905.12762, 2019.",
            "reference_abstract": "Connected and autonomous vehicles (CAVs) will form the backbone of future\nnext-generation intelligent transportation systems (ITS) providing travel\ncomfort, road safety, along with a number of value-added services. Such a\ntransformation---which will be fuelled by concomitant advances in technologies\nfor machine learning (ML) and wireless communications---will enable a future\nvehicular ecosystem that is better featured and more efficient. However, there\nare lurking security problems related to the use of ML in such a critical\nsetting where an incorrect ML decision may not only be a nuisance but can lead\nto loss of precious lives. In this paper, we present an in-depth overview of\nthe various challenges associated with the application of ML in vehicular\nnetworks. In addition, we formulate the ML pipeline of CAVs and present various\npotential security issues associated with the adoption of ML methods. In\nparticular, we focus on the perspective of adversarial ML attacks on CAVs and\noutline a solution to defend against adversarial attacks in multiple settings."
        },
        {
            "reference_num": "[141]",
            "reference_title": "G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural network,” Deep Learning Workshop, NIPS, 2014.",
            "reference_abstract": "A very simple way to improve the performance of almost any machine learning\nalgorithm is to train many different models on the same data and then to\naverage their predictions. Unfortunately, making predictions using a whole\nensemble of models is cumbersome and may be too computationally expensive to\nallow deployment to a large number of users, especially if the individual\nmodels are large neural nets. Caruana and his collaborators have shown that it\nis possible to compress the knowledge in an ensemble into a single model which\nis much easier to deploy and we develop this approach further using a different\ncompression technique. We achieve some surprising results on MNIST and we show\nthat we can significantly improve the acoustic model of a heavily used\ncommercial system by distilling the knowledge in an ensemble of models into a\nsingle model. We also introduce a new type of ensemble composed of one or more\nfull models and many specialist models which learn to distinguish fine-grained\nclasses that the full models confuse. Unlike a mixture of experts, these\nspecialist models can be trained rapidly and in parallel."
        },
        {
            "reference_num": "[142]",
            "reference_title": "N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillation as a defense to adversarial perturbations against deep neural networks,” in 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016, pp. 582–597.",
            "reference_abstract": "Deep learning takes advantage of large datasets and computationally efficient\ntraining algorithms to outperform other approaches at various machine learning\ntasks. However, imperfections in the training phase of deep neural networks\nmake them vulnerable to adversarial samples: inputs crafted by adversaries with\nthe intent of causing deep neural networks to misclassify. In this work, we\nformalize the space of adversaries against deep neural networks (DNNs) and\nintroduce a novel class of algorithms to craft adversarial samples based on a\nprecise understanding of the mapping between inputs and outputs of DNNs. In an\napplication to computer vision, we show that our algorithms can reliably\nproduce samples correctly classified by human subjects but misclassified in\nspecific targets by a DNN with a 97% adversarial success rate while only\nmodifying on average 4.02% of the input features per sample. We then evaluate\nthe vulnerability of different sample classes to adversarial perturbations by\ndefining a hardness measure. Finally, we describe preliminary work outlining\ndefenses against adversarial samples by defining a predictive measure of\ndistance between a benign input and a target classification."
        },
        {
            "reference_num": "[143]",
            "reference_title": "N. Carlini and D. Wagner, “Adversarial examples are not easily detected: Bypassing ten detection methods,” in Proceedings of the 10th ACM Workshop on Artiﬁcial Intelligence and Security. ACM, 2017, pp. 3–14.",
            "reference_abstract": "Neural networks are known to be vulnerable to adversarial examples: inputs\nthat are close to natural inputs but classified incorrectly. In order to better\nunderstand the space of adversarial examples, we survey ten recent proposals\nthat are designed for detection and compare their efficacy. We show that all\ncan be defeated by constructing new loss functions. We conclude that\nadversarial examples are significantly harder to detect than previously\nappreciated, and the properties believed to be intrinsic to adversarial\nexamples are in fact not. Finally, we propose several simple guidelines for\nevaluating future proposed defenses."
        },
        {
            "reference_num": "[144]",
            "reference_title": "G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer, “Reluplex: An efﬁcient SMT solver for verifying deep neural networks,” in International Conference on Computer Aided Veriﬁcation. Springer, 2017, pp. 97–117.",
            "reference_abstract": "Deep neural networks have emerged as a widely used and effective means for\ntackling complex, real-world problems. However, a major obstacle in applying\nthem to safety-critical systems is the great difficulty in providing formal\nguarantees about their behavior. We present a novel, scalable, and efficient\ntechnique for verifying properties of deep neural networks (or providing\ncounter-examples). The technique is based on the simplex method, extended to\nhandle the non-convex Rectified Linear Unit (ReLU) activation function, which\nis a crucial ingredient in many modern neural networks. The verification\nprocedure tackles neural networks as a whole, without making any simplifying\nassumptions. We evaluated our technique on a prototype deep neural network\nimplementation of the next-generation airborne collision avoidance system for\nunmanned aircraft (ACAS Xu). Results show that our technique can successfully\nprove properties of networks that are an order of magnitude larger than the\nlargest networks verified using existing methods."
        },
        {
            "reference_num": "[145]",
            "reference_title": "A. S. Ross and F. Doshi-Velez, “Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients,” in Thirty-second AAAI conference on artiﬁcial intelligence, 2018.",
            "reference_abstract": "Deep neural networks have proven remarkably effective at solving many\nclassification problems, but have been criticized recently for two major\nweaknesses: the reasons behind their predictions are uninterpretable, and the\npredictions themselves can often be fooled by small adversarial perturbations.\nThese problems pose major obstacles for the adoption of neural networks in\ndomains that require security or transparency. In this work, we evaluate the\neffectiveness of defenses that differentiably penalize the degree to which\nsmall changes in inputs can alter model predictions. Across multiple attacks,\narchitectures, defenses, and datasets, we find that neural networks trained\nwith this input gradient regularization exhibit robustness to transferred\nadversarial examples generated to fool all of the other models. We also find\nthat adversarial examples generated to fool gradient-regularized models fool\nall other models equally well, and actually lead to more \"legitimate,\"\ninterpretable misclassifications as rated by people (which we confirm in a\nhuman subject experiment). Finally, we demonstrate that regularizing input\ngradients makes them more naturally interpretable as rationales for model\npredictions. We conclude by discussing this relationship between\ninterpretability and robustness in deep neural networks."
        },
        {
            "reference_num": "[146]",
            "reference_title": "J. Bradshaw, A. G. d. G. Matthews, and Z. Ghahramani, “Adversarial examples, uncertainty, and transfer testing robustness in gaussian process hybrid deep networks,” arXiv preprint arXiv:1707.02476, 2017.",
            "reference_abstract": "Deep neural networks (DNNs) have excellent representative power and are state\nof the art classifiers on many tasks. However, they often do not capture their\nown uncertainties well making them less robust in the real world as they\noverconfidently extrapolate and do not notice domain shift. Gaussian processes\n(GPs) with RBF kernels on the other hand have better calibrated uncertainties\nand do not overconfidently extrapolate far from data in their training set.\nHowever, GPs have poor representational power and do not perform as well as\nDNNs on complex domains. In this paper we show that GP hybrid deep networks,\nGPDNNs, (GPs on top of DNNs and trained end-to-end) inherit the nice properties\nof both GPs and DNNs and are much more robust to adversarial examples. When\nextrapolating to adversarial examples and testing in domain shift settings,\nGPDNNs frequently output high entropy class probabilities corresponding to\nessentially \"don't know\". GPDNNs are therefore promising as deep architectures\nthat know when they don't know."
        },
        {
            "reference_num": "[147]",
            "reference_title": "G. Tao, S. Ma, Y. Liu, and X. Zhang, “Attacks meet interpretability: Attribute-steered detection of adversarial samples,” in Advances in Neural Information Processing Systems (NeurIPS), 2018, pp. 7717– 7728.",
            "reference_abstract": "A narrow structure in the $p\\bar{\\Lambda}$ system near the mass threshold,\nnamed as $X(2085)$, is observed in the process $e^+e^- \\to p K^-\\bar{\\Lambda}$\nwith a statistical significance greater than $20\\sigma$. Its spin and parity\nare determined for the first time to be $J^P=1^+$ in an amplitude analysis,\nwith statistical significance greater than $5\\sigma$ over other quantum\nnumbers. The pole positions of $X(2085)$ are measured to be $M_{\\rm\npole}=(2086\\pm4\\pm6)$~MeV and $\\Gamma_{\\rm pole}=(56\\pm5\\pm16)$ MeV, where the\nfirst uncertainties are statistical and the second ones are systematic. The\nanalysis is based on the study of the process $e^+e^-\\to pK^-\\bar{\\Lambda}$ and\nuses the data samples collected with the BESIII detector at the center-of-mass\nenergies $\\sqrt{s}=4.008$, $4.178$, $4.226$, $4.258$, $4.416$, and $4.682$ GeV\nwith a total integrated luminosity of $8.35~\\text{fb}^{-1}$."
        },
        {
            "reference_num": "[148]",
            "reference_title": "N. Carlini, “Is ami (attacks meet interpretability) robust to adversarial examples?” arXiv preprint arXiv:1902.02322, 2019.",
            "reference_abstract": "No."
        },
        {
            "reference_num": "[149]",
            "reference_title": "L. Nguyen, S. Wang, and A. Sinha, “A learning and masking approach to secure learning,” in International Conference on Decision and Game Theory for Security. Springer, 2018, pp. 453–464.",
            "reference_abstract": "Deep Neural Networks (DNNs) have been shown to be vulnerable against\nadversarial examples, which are data points cleverly constructed to fool the\nclassifier. Such attacks can be devastating in practice, especially as DNNs are\nbeing applied to ever increasing critical tasks like image recognition in\nautonomous driving. In this paper, we introduce a new perspective on the\nproblem. We do so by first defining robustness of a classifier to adversarial\nexploitation. Next, we show that the problem of adversarial example generation\ncan be posed as learning problem. We also categorize attacks in literature into\nhigh and low perturbation attacks; well-known attacks like fast-gradient sign\nmethod (FGSM) and our attack produce higher perturbation adversarial examples\nwhile the more potent but computationally inefficient Carlini-Wagner (CW)\nattack is low perturbation. Next, we show that the dual approach of the attack\nlearning problem can be used as a defensive technique that is effective against\nhigh perturbation attacks. Finally, we show that a classifier masking method\nachieved by adding noise to the a neural network's logit output protects\nagainst low distortion attacks such as the CW attack. We also show that both\nour learning and masking defense can work simultaneously to protect against\nmultiple attacks. We demonstrate the efficacy of our techniques by\nexperimenting with the MNIST and CIFAR-10 datasets."
        },
        {
            "reference_num": "[150]",
            "reference_title": "R. Huang, B. Xu, D. Schuurmans, and C. Szepesv´ari, “Learning with a strong adversary,” arXiv preprint arXiv:1511.03034, 2015.",
            "reference_abstract": "The robustness of neural networks to intended perturbations has recently\nattracted significant attention. In this paper, we propose a new method,\n\\emph{learning with a strong adversary}, that learns robust classifiers from\nsupervised data. The proposed method takes finding adversarial examples as an\nintermediate step. A new and simple way of finding adversarial examples is\npresented and experimentally shown to be efficient. Experimental results\ndemonstrate that resulting learning method greatly improves the robustness of\nthe classification models produced."
        },
        {
            "reference_num": "[151]",
            "reference_title": "A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” in Artiﬁcial Intelligence Safety and Security. Chapman and Hall/CRC, 2018, pp. 99–112.",
            "reference_abstract": "A chapter contribution to book: \"Handbook of Spin Transport and Magnetism\",\ned. by Evegeny Y. Tsymbal and Igor Zutic (Chapman &amp; Hall/CRC, 2011)\nhttp://www.crcpress.com/product/isbn/9781439803776 ."
        },
        {
            "reference_num": "[152]",
            "reference_title": "S. Gu and L. Rigazio, “Towards deep neural network architectures robust to adversarial examples,” Published as a Workshop Paper at International Conference on Learning Representative (ICLR), 2015.",
            "reference_abstract": "Recent work has shown deep neural networks (DNNs) to be highly susceptible to\nwell-designed, small perturbations at the input layer, or so-called adversarial\nexamples. Taking images as an example, such distortions are often\nimperceptible, but can result in 100% mis-classification for a state of the art\nDNN. We study the structure of adversarial examples and explore network\ntopology, pre-processing and training strategies to improve the robustness of\nDNNs. We perform various experiments to assess the removability of adversarial\nexamples by corrupting with additional noise and pre-processing with denoising\nautoencoders (DAEs). We find that DAEs can remove substantial amounts of the\nadversarial noise. How- ever, when stacking the DAE with the original DNN, the\nresulting network can again be attacked by new adversarial examples with even\nsmaller distortion. As a solution, we propose Deep Contractive Network, a model\nwith a new end-to-end training procedure that includes a smoothness penalty\ninspired by the contractive autoencoder (CAE). This increases the network\nrobustness to adversarial examples, without a significant performance penalty."
        },
        {
            "reference_num": "[155]",
            "reference_title": "J. Gao, B. Wang, Z. Lin, W. Xu, and Y. Qi, “Deepcloak: Masking deep neural network models for robustness against adversarial samples,” arXiv preprint arXiv:1702.06763, 2017.",
            "reference_abstract": "Recent studies have shown that deep neural networks (DNN) are vulnerable to\nadversarial samples: maliciously-perturbed samples crafted to yield incorrect\nmodel outputs. Such attacks can severely undermine DNN systems, particularly in\nsecurity-sensitive settings. It was observed that an adversary could easily\ngenerate adversarial samples by making a small perturbation on irrelevant\nfeature dimensions that are unnecessary for the current classification task. To\novercome this problem, we introduce a defensive mechanism called DeepCloak. By\nidentifying and removing unnecessary features in a DNN model, DeepCloak limits\nthe capacity an attacker can use generating adversarial samples and therefore\nincrease the robustness against such inputs. Comparing with other defensive\napproaches, DeepCloak is easy to implement and computationally efficient.\nExperimental results show that DeepCloak can increase the performance of\nstate-of-the-art DNN models against adversarial samples."
        },
        {
            "reference_num": "[156]",
            "reference_title": "S. Garg, V. Sharan, B. Zhang, and G. Valiant, “A spectral view of adversarially robust features,” in Advances in Neural Information Processing Systems (NeurlIPS), 2018, pp. 10 159–10 169.",
            "reference_abstract": "Given the apparent difficulty of learning models that are robust to\nadversarial perturbations, we propose tackling the simpler problem of\ndeveloping adversarially robust features. Specifically, given a dataset and\nmetric of interest, the goal is to return a function (or multiple functions)\nthat 1) is robust to adversarial perturbations, and 2) has significant\nvariation across the datapoints. We establish strong connections between\nadversarially robust features and a natural spectral property of the geometry\nof the dataset and metric of interest. This connection can be leveraged to\nprovide both robust features, and a lower bound on the robustness of any\nfunction that has significant variance across the dataset. Finally, we provide\nempirical evidence that the adversarially robust features given by this\nspectral approach can be fruitfully leveraged to learn a robust (and accurate)\nmodel."
        },
        {
            "reference_num": "[158]",
            "reference_title": "G. Jin, S. Shen, D. Zhang, F. Dai, and Y. Zhang, “APE-GAN: adversarial perturbation elimination with GAN,” in ICASSP 20192019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 3842–3846.",
            "reference_abstract": "This paper summarizes our acoustic modeling efforts in the Johns Hopkins\nUniversity speech recognition system for the CHiME-5 challenge to recognize\nhighly-overlapped dinner party speech recorded by multiple microphone arrays.\nWe explore data augmentation approaches, neural network architectures,\nfront-end speech dereverberation, beamforming and robust i-vector extraction\nwith comparisons of our in-house implementations and publicly available tools.\nWe finally achieved a word error rate of 69.4% on the development set, which is\na 11.7% absolute improvement over the previous baseline of 81.1%, and release\nthis improved baseline with refined techniques/tools as an advanced CHiME-5\nrecipe."
        },
        {
            "reference_num": "[159]",
            "reference_title": "J. Lu, T. Issaranon, and D. Forsyth, “Safetynet: Detecting and rejecting adversarial examples robustly,” in Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 446–454.",
            "reference_abstract": "We describe a method to produce a network where current methods such as\nDeepFool have great difficulty producing adversarial samples. Our construction\nsuggests some insights into how deep networks work. We provide a reasonable\nanalyses that our construction is difficult to defeat, and show experimentally\nthat our method is hard to defeat with both Type I and Type II attacks using\nseveral standard networks and datasets. This SafetyNet architecture is used to\nan important and novel application SceneProof, which can reliably detect\nwhether an image is a picture of a real scene or not. SceneProof applies to\nimages captured with depth maps (RGBD images) and checks if a pair of image and\ndepth map is consistent. It relies on the relative difficulty of producing\nnaturalistic depth maps for images in post processing. We demonstrate that our\nSafetyNet is robust to adversarial examples built from currently known\nattacking approaches."
        },
        {
            "reference_num": "[160]",
            "reference_title": "D. Gopinath, G. Katz, C. S. Pasareanu, and C. Barrett, “Deepsafe: A data-driven approach for checking adversarial robustness in neural networks,” arXiv preprint arXiv:1710.00486, 2017.",
            "reference_abstract": "Deep neural networks have become widely used, obtaining remarkable results in\ndomains such as computer vision, speech recognition, natural language\nprocessing, audio recognition, social network filtering, machine translation,\nand bio-informatics, where they have produced results comparable to human\nexperts. However, these networks can be easily fooled by adversarial\nperturbations: minimal changes to correctly-classified inputs, that cause the\nnetwork to mis-classify them. This phenomenon represents a concern for both\nsafety and security, but it is currently unclear how to measure a network's\nrobustness against such perturbations. Existing techniques are limited to\nchecking robustness around a few individual input points, providing only very\nlimited guarantees. We propose a novel approach for automatically identifying\nsafe regions of the input space, within which the network is robust against\nadversarial perturbations. The approach is data-guided, relying on clustering\nto identify well-defined geometric regions as candidate safe regions. We then\nutilize verification techniques to confirm that these regions are safe or to\nprovide counter-examples showing that they are not safe. We also introduce the\nnotion of targeted robustness which, for a given target label and region,\nensures that a NN does not map any input in the region to the target label. We\nevaluated our technique on the MNIST dataset and on a neural network\nimplementation of a controller for the next-generation Airborne Collision\nAvoidance System for unmanned aircraft (ACAS Xu). For these networks, our\napproach identified multiple regions which were completely safe as well as some\nwhich were only safe for specific labels. It also discovered several\nadversarial perturbations of interest."
        },
        {
            "reference_num": "[161]",
            "reference_title": "J. H. Metzen, T. Genewein, V. Fischer, and B. Bischoff, “On detecting adversarial perturbations,” International Conference on Learning Representations (ICLR), 2017.",
            "reference_abstract": "Machine learning and deep learning in particular has advanced tremendously on\nperceptual tasks in recent years. However, it remains vulnerable against\nadversarial perturbations of the input that have been crafted specifically to\nfool the system while being quasi-imperceptible to a human. In this work, we\npropose to augment deep neural networks with a small \"detector\" subnetwork\nwhich is trained on the binary classification task of distinguishing genuine\ndata from data containing adversarial perturbations. Our method is orthogonal\nto prior work on addressing adversarial perturbations, which has mostly focused\non making the classification network itself more robust. We show empirically\nthat adversarial perturbations can be detected surprisingly well even though\nthey are quasi-imperceptible to humans. Moreover, while the detectors have been\ntrained to detect only a specific adversary, they generalize to similar and\nweaker adversaries. In addition, we propose an adversarial attack that fools\nboth the classifier and the detector and a novel training procedure for the\ndetector that counteracts this attack."
        },
        {
            "reference_num": "[162]",
            "reference_title": "F. Tramer, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel, “Ensemble adversarial training: Attacks and defenses,” in International Conference on Learning Representations (ICLR), 2018.",
            "reference_abstract": "Adversarial examples are perturbed inputs designed to fool machine learning\nmodels. Adversarial training injects such examples into training data to\nincrease robustness. To scale this technique to large datasets, perturbations\nare crafted using fast single-step methods that maximize a linear approximation\nof the model's loss. We show that this form of adversarial training converges\nto a degenerate global minimum, wherein small curvature artifacts near the data\npoints obfuscate a linear approximation of the loss. The model thus learns to\ngenerate weak perturbations, rather than defend against strong ones. As a\nresult, we find that adversarial training remains vulnerable to black-box\nattacks, where we transfer perturbations computed on undefended models, as well\nas to a powerful novel single-step attack that escapes the non-smooth vicinity\nof the input data via a small random step. We further introduce Ensemble\nAdversarial Training, a technique that augments training data with\nperturbations transferred from other models. On ImageNet, Ensemble Adversarial\nTraining yields models with strong robustness to black-box attacks. In\nparticular, our most robust model won the first round of the NIPS 2017\ncompetition on Defenses against Adversarial Attacks. However, subsequent work\nfound that more elaborate black-box attacks could significantly enhance\ntransferability and reduce the accuracy of our models."
        },
        {
            "reference_num": "[163]",
            "reference_title": "G. K. Santhanam and P. Grnarova, “Defending against adversarial attacks by leveraging an entire GAN,” arXiv preprint arXiv:1805.10652, 2018.",
            "reference_abstract": "Recent work has shown that state-of-the-art models are highly vulnerable to\nadversarial perturbations of the input. We propose cowboy, an approach to\ndetecting and defending against adversarial attacks by using both the\ndiscriminator and generator of a GAN trained on the same dataset. We show that\nthe discriminator consistently scores the adversarial samples lower than the\nreal samples across multiple attacks and datasets. We provide empirical\nevidence that adversarial samples lie outside of the data manifold learned by\nthe GAN. Based on this, we propose a cleaning method which uses both the\ndiscriminator and generator of the GAN to project the samples back onto the\ndata manifold. This cleaning procedure is independent of the classifier and\ntype of attack and thus can be deployed in existing systems."
        },
        {
            "reference_num": "[164]",
            "reference_title": "P. Samangouei, M. Kabkab, and R. Chellappa, “Defense-GAN: Protecting classiﬁers against adversarial attacks using generative models,” in International Conference on Learning Representations (ICLR), 2018.",
            "reference_abstract": "In recent years, deep neural network approaches have been widely adopted for\nmachine learning tasks, including classification. However, they were shown to\nbe vulnerable to adversarial perturbations: carefully crafted small\nperturbations can cause misclassification of legitimate images. We propose\nDefense-GAN, a new framework leveraging the expressive capability of generative\nmodels to defend deep neural networks against such attacks. Defense-GAN is\ntrained to model the distribution of unperturbed images. At inference time, it\nfinds a close output to a given image which does not contain the adversarial\nchanges. This output is then fed to the classifier. Our proposed method can be\nused with any classification model and does not modify the classifier structure\nor training procedure. It can also be used as a defense against any attack as\nit does not assume knowledge of the process for generating the adversarial\nexamples. We empirically show that Defense-GAN is consistently effective\nagainst different attack methods and improves on existing defense strategies.\nOur code has been made publicly available at\nhttps://github.com/kabkabm/defensegan"
        },
        {
            "reference_num": "[165]",
            "reference_title": "P. Schulam and S. Saria, “What-if reasoning with counterfactual gaussian processes,” History, vol. 100, p. 120, 2017.  22",
            "reference_abstract": "Decision-makers are faced with the challenge of estimating what is likely to\nhappen when they take an action. For instance, if I choose not to treat this\npatient, are they likely to die? Practitioners commonly use supervised learning\nalgorithms to fit predictive models that help decision-makers reason about\nlikely future outcomes, but we show that this approach is unreliable, and\nsometimes even dangerous. The key issue is that supervised learning algorithms\nare highly sensitive to the policy used to choose actions in the training data,\nwhich causes the model to capture relationships that do not generalize. We\npropose using a different learning objective that predicts counterfactuals\ninstead of predicting outcomes under an existing action policy as in supervised\nlearning. To support decision-making in temporal settings, we introduce the\nCounterfactual Gaussian Process (CGP) to predict the counterfactual future\nprogression of continuous-time trajectories under sequences of future actions.\nWe demonstrate the benefits of the CGP on two important decision-support tasks:\nrisk prediction and \"what if?\" reasoning for individualized treatment planning."
        },
        {
            "reference_num": "[166]",
            "reference_title": "R. C. Sato and G. T. K. Sato, “Probabilistic graphic models applied to identiﬁcation of diseases,” Einstein (S˜ao Paulo), vol. 13, no. 2, pp. 330–333, 2015.",
            "reference_abstract": "We show that the time dependent version of Sato's equation, when applied to\ncapacitative rf sheaths is no longer independent of the electric field of the\nspace charge, and discuss the use of the equation for a specific sheath model."
        },
        {
            "reference_num": "[167]",
            "reference_title": "C. Glymour, K. Zhang, and P. Spirtes, “Review of causal discovery methods based on graphical models,” Frontiers in Genetics, vol. 10, 2019.",
            "reference_abstract": "Measurement error in the observed values of the variables can greatly change\nthe output of various causal discovery methods. This problem has received much\nattention in multiple fields, but it is not clear to what extent the causal\nmodel for the measurement-error-free variables can be identified in the\npresence of measurement error with unknown variance. In this paper, we study\nprecise sufficient identifiability conditions for the measurement-error-free\ncausal model and show what information of the causal model can be recovered\nfrom observed data. In particular, we present two different sets of\nidentifiability conditions, based on the second-order statistics and\nhigher-order statistics of the data, respectively. The former was inspired by\nthe relationship between the generating model of the\nmeasurement-error-contaminated data and the factor analysis model, and the\nlatter makes use of the identifiability result of the over-complete independent\ncomponent analysis problem."
        },
        {
            "reference_num": "[168]",
            "reference_title": "J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are features in deep neural networks?” in Advances in neural information processing systems, 2014, pp. 3320–3328.",
            "reference_abstract": "Many deep neural networks trained on natural images exhibit a curious\nphenomenon in common: on the first layer they learn features similar to Gabor\nfilters and color blobs. Such first-layer features appear not to be specific to\na particular dataset or task, but general in that they are applicable to many\ndatasets and tasks. Features must eventually transition from general to\nspecific by the last layer of the network, but this transition has not been\nstudied extensively. In this paper we experimentally quantify the generality\nversus specificity of neurons in each layer of a deep convolutional neural\nnetwork and report a few surprising results. Transferability is negatively\naffected by two distinct issues: (1) the specialization of higher layer neurons\nto their original task at the expense of performance on the target task, which\nwas expected, and (2) optimization difficulties related to splitting networks\nbetween co-adapted neurons, which was not expected. In an example network\ntrained on ImageNet, we demonstrate that either of these two issues may\ndominate, depending on whether features are transferred from the bottom,\nmiddle, or top of the network. We also document that the transferability of\nfeatures decreases as the distance between the base task and target task\nincreases, but that transferring features even from distant tasks can be better\nthan using random features. A final surprising result is that initializing a\nnetwork with transferred features from almost any number of layers can produce\na boost to generalization that lingers even after fine-tuning to the target\ndataset."
        },
        {
            "reference_num": "[169]",
            "reference_title": "M. Ghafoorian, A. Mehrtash, T. Kapur, N. Karssemeijer, E. Marchiori, M. Pesteie, C. R. Guttmann, F.-E. de Leeuw, C. M. Tempany, B. van Ginneken et al., “Transfer learning for domain adaptation in mri: Application in brain lesion segmentation,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2017, pp. 516–524.",
            "reference_abstract": "Magnetic Resonance Imaging (MRI) is widely used in routine clinical diagnosis\nand treatment. However, variations in MRI acquisition protocols result in\ndifferent appearances of normal and diseased tissue in the images.\nConvolutional neural networks (CNNs), which have shown to be successful in many\nmedical image analysis tasks, are typically sensitive to the variations in\nimaging protocols. Therefore, in many cases, networks trained on data acquired\nwith one MRI protocol, do not perform satisfactorily on data acquired with\ndifferent protocols. This limits the use of models trained with large annotated\nlegacy datasets on a new dataset with a different domain which is often a\nrecurring situation in clinical settings. In this study, we aim to answer the\nfollowing central questions regarding domain adaptation in medical image\nanalysis: Given a fitted legacy model, 1) How much data from the new domain is\nrequired for a decent adaptation of the original network?; and, 2) What portion\nof the pre-trained model parameters should be retrained given a certain number\nof the new domain training samples? To address these questions, we conducted\nextensive experiments in white matter hyperintensity segmentation task. We\ntrained a CNN on legacy MR images of brain and evaluated the performance of the\ndomain-adapted network on the same task with images from a different domain. We\nthen compared the performance of the model to the surrogate scenarios where\neither the same trained network is used or a new network is trained from\nscratch on the new dataset.The domain-adapted network tuned only by two\ntraining examples achieved a Dice score of 0.63 substantially outperforming a\nsimilar network trained on the same set of examples from scratch."
        },
        {
            "reference_num": "[170]",
            "reference_title": "A. Madani, M. Moradi, A. Karargyris, and T. Syeda-Mahmood, “Semisupervised learning with generative adversarial networks for chest Xray classiﬁcation with ability of data domain adaptation,” in 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). IEEE, 2018, pp. 1038–1042.",
            "reference_abstract": "Chest X-rays are the most common diagnostic exams in emergency rooms and\nhospitals. There has been a surge of work on automatic interpretation of chest\nX-rays using deep learning approaches after the availability of large open\nsource chest X-ray dataset from NIH. However, the labels are not sufficiently\nrich and descriptive for training classification tools. Further, it does not\nadequately address the findings seen in Chest X-rays taken in\nanterior-posterior (AP) view which also depict the placement of devices such as\ncentral vascular lines and tubes. In this paper, we present a new chest X-ray\nbenchmark database of 73 rich sentence-level descriptors of findings seen in AP\nchest X-rays. We describe our method of obtaining these findings through a\nsemi-automated ground truth generation process from crowdsourcing of clinician\nannotations. We also present results of building classifiers for these findings\nthat show that such higher granularity labels can also be learned through the\nframework of deep learning classifiers."
        },
        {
            "reference_num": "[171]",
            "reference_title": "C. Wachinger, M. Reuter, A. D. N. Initiative et al., “Domain adaptation for alzheimer’s disease diagnostics,” Neuroimage, vol. 139, pp. 470– 479, 2016.",
            "reference_abstract": "We introduce DeepNAT, a 3D Deep convolutional neural network for the\nautomatic segmentation of NeuroAnaTomy in T1-weighted magnetic resonance\nimages. DeepNAT is an end-to-end learning-based approach to brain segmentation\nthat jointly learns an abstract feature representation and a multi-class\nclassification. We propose a 3D patch-based approach, where we do not only\npredict the center voxel of the patch but also neighbors, which is formulated\nas multi-task learning. To address a class imbalance problem, we arrange two\nnetworks hierarchically, where the first one separates foreground from\nbackground, and the second one identifies 25 brain structures on the\nforeground. Since patches lack spatial context, we augment them with\ncoordinates. To this end, we introduce a novel intrinsic parameterization of\nthe brain volume, formed by eigenfunctions of the Laplace-Beltrami operator. As\nnetwork architecture, we use three convolutional layers with pooling, batch\nnormalization, and non-linearities, followed by fully connected layers with\ndropout. The final segmentation is inferred from the probabilistic output of\nthe network with a 3D fully connected conditional random field, which ensures\nlabel agreement between close voxels. The roughly 2.7 million parameters in the\nnetwork are learned with stochastic gradient descent. Our results show that\nDeepNAT compares favorably to state-of-the-art methods. Finally, the purely\nlearning-based method may have a high potential for the adaptation to young,\nold, or diseased brains by fine-tuning the pre-trained network with a small\ntraining sample on the target application, where the availability of larger\ndatasets with manual annotations may boost the overall segmentation accuracy in\nthe future."
        },
        {
            "reference_num": "[172]",
            "reference_title": "G. Wilson and D. J. Cook, “A survey of unsupervised deep domain adaptation,” arXiv preprint arXiv:1812.02849, 2019.",
            "reference_abstract": "Deep learning has produced state-of-the-art results for a variety of tasks.\nWhile such approaches for supervised learning have performed well, they assume\nthat training and testing data are drawn from the same distribution, which may\nnot always be the case. As a complement to this challenge, single-source\nunsupervised domain adaptation can handle situations where a network is trained\non labeled data from a source domain and unlabeled data from a related but\ndifferent target domain with the goal of performing well at test-time on the\ntarget domain. Many single-source and typically homogeneous unsupervised deep\ndomain adaptation approaches have thus been developed, combining the powerful,\nhierarchical representations from deep learning with domain adaptation to\nreduce reliance on potentially-costly target data labels. This survey will\ncompare these approaches by examining alternative methods, the unique and\ncommon elements, results, and theoretical insights. We follow this with a look\nat application areas and open research directions."
        },
        {
            "reference_num": "[173]",
            "reference_title": "F. Mahmood, R. Chen, and N. J. Durr, “Unsupervised reverse domain adaptation for synthetic medical images via adversarial training,” IEEE transactions on medical imaging, vol. 37, no. 12, pp. 2572–2581, 2018.",
            "reference_abstract": "To realize the full potential of deep learning for medical imaging, large\nannotated datasets are required for training. Such datasets are difficult to\nacquire because labeled medical images are not usually available due to privacy\nissues, lack of experts available for annotation, underrepresentation of rare\nconditions and poor standardization. Lack of annotated data has been addressed\nin conventional vision applications using synthetic images refined via\nunsupervised adversarial training to look like real images. However, this\napproach is difficult to extend to general medical imaging because of the\ncomplex and diverse set of features found in real human tissues. We propose an\nalternative framework that uses a reverse flow, where adversarial training is\nused to make real medical images more like synthetic images, and hypothesize\nthat clinically-relevant features can be preserved via self-regularization.\nThese domain-adapted images can then be accurately interpreted by networks\ntrained on large datasets of synthetic medical images. We test this approach\nfor the notoriously difficult task of depth-estimation from endoscopy. We train\na depth estimator on a large dataset of synthetic images generated using an\naccurate forward model of an endoscope and an anatomically-realistic colon.\nThis network predicts significantly better depths when using synthetic-like\ndomain-adapted images compared to the real images, confirming that the\nclinically-relevant features of depth are preserved."
        },
        {
            "reference_num": "[174]",
            "reference_title": "J. Xu, L. Xiao, and A. M. L´opez, “Self-supervised domain adaptation for computer vision tasks,” IEEE Access, vol. 7, pp. 156 694–156 706, 2019.",
            "reference_abstract": "Recent progress of self-supervised visual representation learning has\nachieved remarkable success on many challenging computer vision benchmarks.\nHowever, whether these techniques can be used for domain adaptation has not\nbeen explored. In this work, we propose a generic method for self-supervised\ndomain adaptation, using object recognition and semantic segmentation of urban\nscenes as use cases. Focusing on simple pretext/auxiliary tasks (e.g. image\nrotation prediction), we assess different learning strategies to improve domain\nadaptation effectiveness by self-supervision. Additionally, we propose two\ncomplementary strategies to further boost the domain adaptation accuracy on\nsemantic segmentation within our method, consisting of prediction layer\nalignment and batch normalization calibration. The experimental results show\nadaptation levels comparable to most studied domain adaptation methods, thus,\nbringing self-supervision as a new alternative for reaching domain adaptation.\nThe code is available at https://github.com/Jiaolong/self-supervised-da."
        },
        {
            "reference_num": "[175]",
            "reference_title": "J. Wiens, S. Saria, M. Sendak, M. Ghassemi, V. X. Liu, F. Doshi-Velez, K. Jung, K. Heller, D. Kale, M. Saeed et al., “Do no harm: a roadmap for responsible machine learning for health care,” Nature medicine, vol. 25, no. 9, pp. 1337–1340, 2019.",
            "reference_abstract": "Human space exploration beyond low Earth orbit will involve missions of\nsignificant distance and duration. To effectively mitigate myriad space health\nhazards, paradigm shifts in data and space health systems are necessary to\nenable Earth-independence, rather than Earth-reliance. Promising developments\nin the fields of artificial intelligence and machine learning for biology and\nhealth can address these needs. We propose an appropriately autonomous and\nintelligent Precision Space Health system that will monitor, aggregate, and\nassess biomedical statuses; analyze and predict personalized adverse health\noutcomes; adapt and respond to newly accumulated data; and provide preventive,\nactionable, and timely insights to individual deep space crew members and\niterative decision support to their crew medical officer. Here we present a\nsummary of recommendations from a workshop organized by the National\nAeronautics and Space Administration, on future applications of artificial\nintelligence in space biology and health. In the next decade, biomonitoring\ntechnology, biomarker science, spacecraft hardware, intelligent software, and\nstreamlined data management must mature and be woven together into a Precision\nSpace Health system to enable humanity to thrive in deep space."
        },
        {
            "reference_num": "[176]",
            "reference_title": "S. Latif, A. Qayyum, M. Usama, J. Qadir, A. Zwitter, and M. Shahzad, “Caveat emptor: The risks of using big data for human development,” IEEE Technology and Society Magazine, vol. 38, no. 3, pp. 82–90, 2019.",
            "reference_abstract": "Big data revolution promises to be instrumental in facilitating sustainable\ndevelopment in many sectors of life such as education, health, agriculture, and\nin combating humanitarian crises and violent conflicts. However, lurking\nbeneath the immense promises of big data are some significant risks such as (1)\nthe potential use of big data for unethical ends; (2) its ability to mislead\nthrough reliance on unrepresentative and biased data; and (3) the various\nprivacy and security challenges associated with data (including the danger of\nan adversary tampering with the data to harm people). These risks can have\nsevere consequences and a better understanding of these risks is the first step\ntowards mitigation of these risks. In this paper, we highlight the potential\ndangers associated with using big data, particularly for human development."
        },
        {
            "reference_num": "[177]",
            "reference_title": "X. Jia, L. Ren, and J. Cai, “Clinical implementation of ai technologies will require interpretable ai models,” Medical physics, 2019.",
            "reference_abstract": "In December 2023, the European Parliament provisionally agreed on the EU AI\nAct. This unprecedented regulatory framework for AI systems lays out guidelines\nto ensure the safety, legality, and trustworthiness of AI products. This paper\npresents a methodology for interpreting the EU AI Act requirements for\nhigh-risk AI systems by leveraging product quality models. We first propose an\nextended product quality model for AI systems, incorporating attributes\nrelevant to the Act not covered by current quality models. We map the Act\nrequirements to relevant quality attributes with the goal of refining them into\nmeasurable characteristics. We then propose a contract-based approach to derive\ntechnical requirements at the stakeholder level. This facilitates the\ndevelopment and assessment of AI systems that not only adhere to established\nquality standards, but also comply with the regulatory requirements outlined in\nthe Act for high-risk (including safety-critical) AI systems. We demonstrate\nthe applicability of this methodology on an exemplary automotive supply chain\nuse case, where several stakeholders interact to achieve EU AI Act compliance."
        },
        {
            "reference_num": "[178]",
            "reference_title": "S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. M¨uller, and W. Samek, “On pixel-wise explanations for non-linear classiﬁer decisions by layer-wise relevance propagation,” PloS one, vol. 10, no. 7, p. e0130140, 2015.",
            "reference_abstract": "Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard\nfor various challenging machine learning problems, e.g., image classification,\nnatural language processing or human action recognition. Although these methods\nperform impressively well, they have a significant disadvantage, the lack of\ntransparency, limiting the interpretability of the solution and thus the scope\nof application in practice. Especially DNNs act as black boxes due to their\nmultilayer nonlinear structure. In this paper we introduce a novel methodology\nfor interpreting generic multilayer neural networks by decomposing the network\nclassification decision into contributions of its input elements. Although our\nfocus is on image classification, the method is applicable to a broad set of\ninput data, learning tasks and network architectures. Our method is based on\ndeep Taylor decomposition and efficiently utilizes the structure of the network\nby backpropagating the explanations from the output to the input layer. We\nevaluate the proposed method empirically on the MNIST and ILSVRC data sets."
        },
        {
            "reference_num": "[180]",
            "reference_title": "O. Lahav, N. Mastronarde, and M. van der Schaar, “What is interpretable? using machine learning to design interpretable decisionsupport systems,” Machine Learning for Health (ML4H) Workshop at NeurIPS, 2018.",
            "reference_abstract": "Recent efforts in Machine Learning (ML) interpretability have focused on\ncreating methods for explaining black-box ML models. However, these methods\nrely on the assumption that simple approximations, such as linear models or\ndecision-trees, are inherently human-interpretable, which has not been\nempirically tested. Additionally, past efforts have focused exclusively on\ncomprehension, neglecting to explore the trust component necessary to convince\nnon-technical experts, such as clinicians, to utilize ML models in practice. In\nthis paper, we posit that reinforcement learning (RL) can be used to learn what\nis interpretable to different users and, consequently, build their trust in ML\nmodels. To validate this idea, we first train a neural network to provide risk\nassessments for heart failure patients. We then design a RL-based clinical\ndecision-support system (DSS) around the neural network model, which can learn\nfrom its interactions with users. We conduct an experiment involving a diverse\nset of clinicians from multiple institutions in three different countries. Our\nresults demonstrate that ML experts cannot accurately predict which system\noutputs will maximize clinicians' confidence in the underlying neural network\nmodel, and suggest additional findings that have broad implications to the\nfuture of research into ML interpretability and the use of ML in medicine."
        },
        {
            "reference_num": "[181]",
            "reference_title": "Y. Halpern, S. Horng, Y. Choi, and D. Sontag, “Electronic medical record phenotyping using the anchor and learn framework,” Journal of the American Medical Informatics Association, vol. 23, no. 4, pp. 731–740, 2016.",
            "reference_abstract": "We describe a method for parameter estimation in bipartite probabilistic\ngraphical models for joint prediction of clinical conditions from the\nelectronic medical record. The method does not rely on the availability of\ngold-standard labels, but rather uses noisy labels, called anchors, for\nlearning. We provide a likelihood-based objective and a moments-based\ninitialization that are effective at learning the model parameters. The learned\nmodel is evaluated in a task of assigning a heldout clinical condition to\npatients based on retrospective analysis of the records, and outperforms\nbaselines which do not account for the noisiness in the labels or do not model\nthe conditions jointly."
        },
        {
            "reference_num": "[182]",
            "reference_title": "R. L. Richesson, W. E. Hammond, M. Nahm, D. Wixted, G. E. Simon, J. G. Robinson, A. E. Bauck, D. Cifelli, M. M. Smerek, J. Dickerson et al., “Electronic health records based phenotyping in next-generation clinical trials: a perspective from the nih health care systems collaboratory,” Journal of the American Medical Informatics Association, vol. 20, no. e2, pp. e226–e231, 2013.",
            "reference_abstract": "Background: Common data models solve many challenges of standardizing\nelectronic health record (EHR) data, but are unable to semantically integrate\nall the resources needed for deep phenotyping. Open Biological and Biomedical\nOntology (OBO) Foundry ontologies provide computable representations of\nbiological knowledge and enable the integration of heterogeneous data. However,\nmapping EHR data to OBO ontologies requires significant manual curation and\ndomain expertise. Objective: We introduce OMOP2OBO, an algorithm for mapping\nObservational Medical Outcomes Partnership (OMOP) vocabularies to OBO\nontologies. Results: Using OMOP2OBO, we produced mappings for 92,367\nconditions, 8611 drug ingredients, and 10,673 measurement results, which\ncovered 68-99% of concepts used in clinical practice when examined across 24\nhospitals. When used to phenotype rare disease patients, the mappings helped\nsystematically identify undiagnosed patients who might benefit from genetic\ntesting. Conclusions: By aligning OMOP vocabularies to OBO ontologies our\nalgorithm presents new opportunities to advance EHR-based deep phenotyping."
        },
        {
            "reference_num": "[183]",
            "reference_title": "D. Belgrave, J. Henderson, A. Simpson, I. Buchan, C. Bishop, and A. Custovic, “Disaggregating asthma: big investigation versus big data,” Journal of Allergy and Clinical Immunology, vol. 139, no. 2, pp. 400–407, 2017.",
            "reference_abstract": "The replacement of the JET carbon wall (C-wall) by a Be/W ITER-like wall\n(ILW) has affected the plasma energy confinement. To investigate this,\nexperiments have been performed with both the C-wall and ILW to vary the\nheating power over a wide range for plasmas with different shapes."
        }
    ]
}